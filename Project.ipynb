{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b501857-78ba-481b-ab7a-3f5b4bc144a4",
      "metadata": {
        "id": "5b501857-78ba-481b-ab7a-3f5b4bc144a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a73f1dd-2fc0-45cb-a11c-1c0cc532a9a0",
      "metadata": {
        "id": "3a73f1dd-2fc0-45cb-a11c-1c0cc532a9a0"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5b801c40-5114-4193-8892-16c62225204f",
      "metadata": {
        "id": "5b801c40-5114-4193-8892-16c62225204f"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self, basemodel, output, train_loader, val_loader, test_loader, unfreeze=0, parameters=None):\n",
        "        # Init model\n",
        "        self.model = copy.deepcopy(basemodel)\n",
        "        # changing the fully connected layer\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, output)\n",
        "        # Unfreeze the L last layers and fully connected last layer\n",
        "        self.unfreeze_layers(unfreeze)\n",
        "        self.model = self.model.to(device)\n",
        "\n",
        "        self.optimizer = optim.Adam([{\"params\": self.model.fc.parameters(),\"lr\": 1e-3, \"weight_decay\": 1e-4},])\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        self.parameters = parameters if parameters is not None else {}\n",
        "\n",
        "\n",
        "    def unfreeze_layers(self, L):\n",
        "      # freezing all layers\n",
        "      for p in self.model.parameters():\n",
        "          p.requires_grad = False\n",
        "\n",
        "      layer = 0\n",
        "      # unfreeze last L layers and fully connected layer\n",
        "      for name, p in reversed(list(self.model.named_parameters())):\n",
        "        if layer < L+1:\n",
        "          if not name.endswith(\"bias\"):\n",
        "            layer += 1\n",
        "          p.requires_grad = True\n",
        "\n",
        "    def check_trainable_layers(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(f\"{name} requires grad\")\n",
        "            else:\n",
        "                print(f\"{name} does NOT require grad\")\n",
        "\n",
        "\n",
        "    def run_epoch(self, loader, train=True):\n",
        "        self.model.train() if train else self.model.eval()\n",
        "        total_loss, correct, total = 0.0, 0, 0\n",
        "        for imgs, labs in loader:\n",
        "            imgs, labs = imgs.to(device), labs.to(device)\n",
        "            if train:\n",
        "                self.optimizer.zero_grad()\n",
        "            logits = self.model(imgs)\n",
        "            loss   = self.criterion(logits, labs)\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds      = logits.argmax(dim=1)\n",
        "            correct   += (preds == labs).sum().item()\n",
        "            total     += imgs.size(0)\n",
        "        return total_loss/total, correct/total*100\n",
        "\n",
        "\n",
        "    def test_model(self):\n",
        "      test_loss, test_acc = self.run_epoch(self.test_loader, train=False)\n",
        "      print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "      return test_acc\n",
        "\n",
        "    def train(self, epochs, path=\"model.pth\"):\n",
        "      best_val_acc = 0.0\n",
        "      for epoch in range(1,epochs+1):\n",
        "\n",
        "        # gradually unfreeze layers for strategy 2 according to rate parameter\n",
        "        if 'gradual_unfreezing' in self.parameters:\n",
        "            uf_rate = 1 if not 'unfreezing_rate' in self.parameters else parameters['unfreezing_rate']\n",
        "            L = np.floor(uf_rate*(1+epoch)) # allow for rates < 1\n",
        "            if L < 1:\n",
        "                L = 1\n",
        "            self.unfreeze_layers(L)\n",
        "\n",
        "        tr_loss, tr_acc = self.run_epoch(self.train_loader, train=True)\n",
        "        val_loss, val_acc = self.run_epoch(self.val_loader, train=False)\n",
        "        print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(self.model.state_dict(), path)\n",
        "\n",
        "      test_acc = self.test_model()\n",
        "      return test_acc\n",
        "\n",
        "    def train2(self, epochs, path=\"model.pth\"):\n",
        "        best_val_acc = 0.0\n",
        "        for epoch in range(1, epochs+1):\n",
        "            # Gradual unfreezing\n",
        "            if self.parameters.get('gradual_unfreezing', False):\n",
        "                uf_rate = self.parameters.get('unfreezing_rate', 1)\n",
        "                L = int(np.floor(uf_rate * (epoch + 1)))\n",
        "                if L < 1:\n",
        "                    L = 1\n",
        "                self.unfreeze_layers(L)\n",
        "\n",
        "            tr_loss, tr_acc = self.run_epoch(self.train_loader, train=True)\n",
        "            val_loss, val_acc = self.run_epoch(self.val_loader, train=False)\n",
        "            print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "\n",
        "            # Save best\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(self.model.state_dict(), path)\n",
        "\n",
        "            # Step scheduler if present\n",
        "            if hasattr(self, 'scheduler') and self.scheduler is not None:\n",
        "                self.scheduler.step()\n",
        "\n",
        "        return self.test_model()\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Track per-class accuracy\n",
        "        class_correct = [0] * len(breed_names)\n",
        "        class_total = [0] * len(breed_names)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in self.test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                # Overall accuracy\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                for i in range(len(targets)):\n",
        "                    label = targets[i].item()\n",
        "                    class_total[label] += 1\n",
        "                    if predicted[i] == targets[i]:\n",
        "                        class_correct[label] += 1\n",
        "\n",
        "        overall_acc = 100.0 * correct / total\n",
        "        per_class_acc = [(100.0 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0.0)\n",
        "                          for i in range(len(breed_names))]\n",
        "\n",
        "        return overall_acc, per_class_acc, class_total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7479cf3f-4699-4cb4-ab82-010e8ddb2635",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7479cf3f-4699-4cb4-ab82-010e8ddb2635",
        "outputId": "b7918d90-91f9-40b1-ece1-d8c31a612b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:34<00:00, 22.8MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 11.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset OxfordIIITPet\n",
              "    Number of datapoints: 3680\n",
              "    Root location: data"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "OxfordIIITPet(root=\"data\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6d431898-55ce-49dc-91f9-7dceed1fec13",
      "metadata": {
        "id": "6d431898-55ce-49dc-91f9-7dceed1fec13"
      },
      "outputs": [],
      "source": [
        "annnotations_dir = os.path.join(\"data\", \"oxford-iiit-pet\", \"annotations\")\n",
        "lines_for_files = open(os.path.join(annnotations_dir, \"list.txt\")).read().splitlines()[6:]\n",
        "species_map = {l.split()[0]: int(l.split()[2]) for l in lines_for_files}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "66c852e4-7055-4c82-97c9-3e99e736d052",
      "metadata": {
        "id": "66c852e4-7055-4c82-97c9-3e99e736d052"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(annnotations_dir, \"trainval.txt\")) as f:\n",
        "    trainval_names = [l.split()[0] for l in f if l.strip()]\n",
        "with open(os.path.join(annnotations_dir, \"test.txt\")) as f:\n",
        "    test_names = [l.split()[0] for l in f if l.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "145827fc-38aa-4e39-8049-e5640ed7cbe0",
      "metadata": {
        "id": "145827fc-38aa-4e39-8049-e5640ed7cbe0"
      },
      "outputs": [],
      "source": [
        "class BinaryPet(Dataset):\n",
        "    def __init__(self, root, names, species_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.species_map = species_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        img_path = os.path.join(\n",
        "            self.root, \"oxford-iiit-pet\", \"images\", name + \".jpg\"\n",
        "        )\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.species_map[name] - 1  # 1→cat→0, 2→dog→1\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c36d1a7d-78bc-4a58-88fa-d26a037d9f99",
      "metadata": {
        "id": "c36d1a7d-78bc-4a58-88fa-d26a037d9f99"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2832243b-6442-4bc5-9926-f690647a5658",
      "metadata": {
        "id": "2832243b-6442-4bc5-9926-f690647a5658"
      },
      "outputs": [],
      "source": [
        "transformIMG = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "036a6c76-bc3b-44b8-acf1-50893a352c62",
      "metadata": {
        "id": "036a6c76-bc3b-44b8-acf1-50893a352c62"
      },
      "outputs": [],
      "source": [
        "full = BinaryPet(\"data\", trainval_names, species_map, transform=transformIMG)\n",
        "n_val = int(0.1 * len(full))\n",
        "train_ds, val_ds = random_split(full, [len(full)-n_val, n_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "55a8eecd-7f70-4223-9218-6023fff72e3d",
      "metadata": {
        "id": "55a8eecd-7f70-4223-9218-6023fff72e3d"
      },
      "outputs": [],
      "source": [
        "test_ds = BinaryPet(\"data\", test_names, species_map, transform=transformIMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6d2e5899-3a81-461a-bd4a-b1a5c850cb8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d2e5899-3a81-461a-bd4a-b1a5c850cb8a",
        "outputId": "cce9a9a5-ab9e-4457-9ff7-ed79e93c8036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0260f07f-a459-4d27-9f5d-bb6c1eee575f",
      "metadata": {
        "id": "0260f07f-a459-4d27-9f5d-bb6c1eee575f"
      },
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0460ecda-9f16-4270-b7e8-a988442797c5",
      "metadata": {
        "id": "0460ecda-9f16-4270-b7e8-a988442797c5"
      },
      "source": [
        "## Model Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7ed618ac-37af-464d-a735-3223b0dbc071",
      "metadata": {
        "id": "7ed618ac-37af-464d-a735-3223b0dbc071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59cadc4-d508-443f-bfde-cc025fcb9369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 159MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "# freezing all\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "# changing the fully connected layer\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "# Unfreeze the fully connected last layer\n",
        "for name, p in model.named_parameters():\n",
        "    if name.startswith(\"fc\"):\n",
        "        p.requires_grad = True\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c32651b9-0f2c-4736-b3db-10fbb6486f70",
      "metadata": {
        "id": "c32651b9-0f2c-4736-b3db-10fbb6486f70"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "55100d27-1851-43fb-8039-3d1cd7ab6b6c",
      "metadata": {
        "id": "55100d27-1851-43fb-8039-3d1cd7ab6b6c"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam([\n",
        "    {\"params\": model.fc.parameters(),     \"lr\": 1e-3, \"weight_decay\": 1e-4},\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "428edba5-4df2-4d37-9f61-18da01050f30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "428edba5-4df2-4d37-9f61-18da01050f30",
        "outputId": "31130a0b-06aa-42bd-cc55-7da92b4804e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d1cdba-bc33-42a1-8f75-3dd5de75288e",
      "metadata": {
        "id": "f0d1cdba-bc33-42a1-8f75-3dd5de75288e"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d1dcabae-3911-4cd2-96ac-52e4c0158183",
      "metadata": {
        "id": "d1dcabae-3911-4cd2-96ac-52e4c0158183"
      },
      "outputs": [],
      "source": [
        "def run_epoch(model, loader, train=True, criterion=criterion, optimizer=optimizer): # TODO: Include criterion and optimizer in a neater way\n",
        "    model.train() if train else model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    for imgs, labs in loader:\n",
        "        imgs, labs = imgs.to(device), labs.to(device)\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss   = criterion(logits, labs)\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        preds      = logits.argmax(dim=1)\n",
        "        correct   += (preds == labs).sum().item()\n",
        "        total     += imgs.size(0)\n",
        "    return total_loss/total, correct/total*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "30e5a381-42b4-4676-8d65-1d1a7e8bebc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30e5a381-42b4-4676-8d65-1d1a7e8bebc7",
        "outputId": "8441ca1d-7597-4c78-c690-6828820f9820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train: 94.02% | Val: 98.64%\n",
            "Epoch  2 | Train: 98.16% | Val: 98.64%\n",
            "Epoch  3 | Train: 98.34% | Val: 98.91%\n",
            "Epoch  4 | Train: 98.67% | Val: 98.91%\n",
            "Epoch  5 | Train: 98.25% | Val: 99.18%\n",
            "Epoch  6 | Train: 98.79% | Val: 98.91%\n",
            "Epoch  7 | Train: 98.82% | Val: 99.18%\n",
            "Epoch  8 | Train: 99.25% | Val: 99.18%\n",
            "Epoch  9 | Train: 99.06% | Val: 99.18%\n",
            "Epoch 10 | Train: 98.79% | Val: 99.18%\n",
            "Epoch 11 | Train: 98.49% | Val: 99.18%\n",
            "Epoch 12 | Train: 98.97% | Val: 99.18%\n",
            "Epoch 13 | Train: 99.25% | Val: 99.18%\n",
            "Epoch 14 | Train: 99.03% | Val: 98.64%\n",
            "Epoch 15 | Train: 99.03% | Val: 99.18%\n",
            "Epoch 16 | Train: 98.82% | Val: 99.18%\n",
            "Epoch 17 | Train: 99.12% | Val: 99.18%\n",
            "Epoch 18 | Train: 99.03% | Val: 99.18%\n",
            "Epoch 19 | Train: 99.28% | Val: 98.91%\n",
            "Epoch 20 | Train: 99.28% | Val: 99.18%\n",
            "Epoch 21 | Train: 99.06% | Val: 99.18%\n",
            "Epoch 22 | Train: 99.31% | Val: 99.18%\n",
            "Epoch 23 | Train: 99.21% | Val: 98.91%\n",
            "Epoch 24 | Train: 99.25% | Val: 99.18%\n"
          ]
        }
      ],
      "source": [
        "best_val_acc = 0.0\n",
        "for epoch in range(1, 25):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc = run_epoch(model, val_loader, train=False)\n",
        "    print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_binary_resnet34.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "32b86600-f7a0-4cc0-afb1-3e954c369c90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32b86600-f7a0-4cc0-afb1-3e954c369c90",
        "outputId": "78b4a294-7f40-48c3-b827-babffce23040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.10%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_binary_resnet34.pth\"))\n",
        "test_loss, test_acc = run_epoch(model, test_loader, train=False)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d5105c-c2ad-4f6c-9691-8a633635463e",
      "metadata": {
        "id": "96d5105c-c2ad-4f6c-9691-8a633635463e"
      },
      "source": [
        "# Multi Class Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60b2b63a-6c41-4a5b-b02d-f978f488fc29",
      "metadata": {
        "id": "60b2b63a-6c41-4a5b-b02d-f978f488fc29"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cef39a61-b139-4313-8f38-abdd1179c503",
      "metadata": {
        "id": "cef39a61-b139-4313-8f38-abdd1179c503"
      },
      "outputs": [],
      "source": [
        "annnotations_dir = os.path.join(\"data\", \"oxford-iiit-pet\", \"annotations\")\n",
        "lines_for_files = open(os.path.join(annnotations_dir, \"list.txt\")).read().splitlines()[6:]\n",
        "breeds_map = {l.split()[0]:re.split(r'_\\d+', l.split()[0])[0] for l in lines_for_files}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "899dfeff-7a12-4688-8387-0c1f366ee339",
      "metadata": {
        "id": "899dfeff-7a12-4688-8387-0c1f366ee339"
      },
      "outputs": [],
      "source": [
        "breed_to_id = {val: i for i, val in enumerate(sorted(set(breeds_map.values())))}\n",
        "id_to_breed = {v: k for k, v in breed_to_id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "eebff8d5-3e15-4157-a97d-4ba02ee3c76a",
      "metadata": {
        "id": "eebff8d5-3e15-4157-a97d-4ba02ee3c76a"
      },
      "outputs": [],
      "source": [
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        img_path = os.path.join(\n",
        "            self.root, \"oxford-iiit-pet\", \"images\", name + \".jpg\"\n",
        "        )\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[name]]\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1c7ff718-7080-4814-8bbd-ff42a8f04f85",
      "metadata": {
        "id": "1c7ff718-7080-4814-8bbd-ff42a8f04f85"
      },
      "outputs": [],
      "source": [
        "full = MultiClassPet(\"data\", trainval_names, breeds_map, transform=transformIMG)\n",
        "n_val = int(0.1 * len(full))\n",
        "train_ds, val_ds = random_split(full, [len(full)-n_val, n_val])\n",
        "test_ds = MultiClassPet(\"data\", test_names, breeds_map, transform=transformIMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f3de2fcd-22e5-4c98-8cb4-0bc40dd99953",
      "metadata": {
        "id": "f3de2fcd-22e5-4c98-8cb4-0bc40dd99953"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb96530-c12c-44f0-ac11-a2c554314e5d",
      "metadata": {
        "id": "2fb96530-c12c-44f0-ac11-a2c554314e5d"
      },
      "source": [
        "## Model Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b159b267-e687-41fc-b7f9-066b5d96848c",
      "metadata": {
        "id": "b159b267-e687-41fc-b7f9-066b5d96848c"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27d260d-a15a-4003-b0f2-a2ecbc50297b",
      "metadata": {
        "id": "d27d260d-a15a-4003-b0f2-a2ecbc50297b"
      },
      "source": [
        "-> Strategy 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WJbuKDtJaKgA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "WJbuKDtJaKgA",
        "outputId": "ff511d4f-f7eb-4044-d96f-01e38c72818c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training model with 1 last layers trainable\n",
            "Epoch  1 | Train: 59.81% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.04% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.43% | Val: 90.22%\n",
            "Epoch  4 | Train: 93.39% | Val: 91.03%\n",
            "Epoch  5 | Train: 93.99% | Val: 92.12%\n",
            "Epoch  6 | Train: 94.69% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.20% | Val: 91.03%\n",
            "Epoch  8 | Train: 96.07% | Val: 90.76%\n",
            "Epoch  9 | Train: 96.68% | Val: 91.58%\n",
            "Epoch 10 | Train: 96.92% | Val: 92.39%\n",
            "Test Accuracy: 89.45%\n",
            "Start training model with 2 last layers trainable\n",
            "Epoch  1 | Train: 60.90% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.41% | Val: 88.32%\n",
            "Epoch  3 | Train: 91.52% | Val: 90.22%\n",
            "Epoch  4 | Train: 91.94% | Val: 89.13%\n",
            "Epoch  5 | Train: 94.41% | Val: 90.49%\n",
            "Epoch  6 | Train: 94.63% | Val: 91.30%\n",
            "Epoch  7 | Train: 95.95% | Val: 90.22%\n",
            "Epoch  8 | Train: 95.83% | Val: 91.85%\n",
            "Epoch  9 | Train: 96.53% | Val: 89.95%\n",
            "Epoch 10 | Train: 97.31% | Val: 89.40%\n",
            "Test Accuracy: 89.32%\n",
            "Start training model with 3 last layers trainable\n",
            "Epoch  1 | Train: 60.75% | Val: 85.60%\n",
            "Epoch  2 | Train: 88.35% | Val: 88.32%\n",
            "Epoch  3 | Train: 91.39% | Val: 88.32%\n",
            "Epoch  4 | Train: 92.54% | Val: 88.86%\n",
            "Epoch  5 | Train: 94.54% | Val: 89.13%\n",
            "Epoch  6 | Train: 95.02% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.26% | Val: 89.40%\n",
            "Epoch  8 | Train: 96.14% | Val: 89.40%\n",
            "Epoch  9 | Train: 96.32% | Val: 90.49%\n",
            "Epoch 10 | Train: 96.62% | Val: 89.40%\n",
            "Test Accuracy: 89.70%\n",
            "Start training model with 4 last layers trainable\n",
            "Epoch  1 | Train: 61.20% | Val: 85.05%\n",
            "Epoch  2 | Train: 87.29% | Val: 88.32%\n",
            "Epoch  3 | Train: 91.43% | Val: 90.76%\n",
            "Epoch  4 | Train: 92.51% | Val: 91.58%\n",
            "Epoch  5 | Train: 94.38% | Val: 89.95%\n",
            "Epoch  6 | Train: 94.75% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.41% | Val: 92.12%\n",
            "Epoch  8 | Train: 95.71% | Val: 91.58%\n",
            "Epoch  9 | Train: 96.62% | Val: 90.49%\n",
            "Epoch 10 | Train: 96.50% | Val: 89.95%\n",
            "Test Accuracy: 89.42%\n",
            "Start training model with 5 last layers trainable\n",
            "Epoch  1 | Train: 60.18% | Val: 86.68%\n",
            "Epoch  2 | Train: 88.56% | Val: 88.59%\n",
            "Epoch  3 | Train: 91.70% | Val: 89.40%\n",
            "Epoch  4 | Train: 93.15% | Val: 88.59%\n",
            "Epoch  5 | Train: 93.36% | Val: 89.40%\n",
            "Epoch  6 | Train: 94.99% | Val: 89.40%\n",
            "Epoch  7 | Train: 94.99% | Val: 90.76%\n",
            "Epoch  8 | Train: 96.26% | Val: 89.67%\n",
            "Epoch  9 | Train: 97.16% | Val: 91.30%\n",
            "Epoch 10 | Train: 97.16% | Val: 90.22%\n",
            "Test Accuracy: 89.70%\n",
            "Start training model with 6 last layers trainable\n",
            "Epoch  1 | Train: 62.71% | Val: 85.33%\n",
            "Epoch  2 | Train: 88.22% | Val: 86.14%\n",
            "Epoch  3 | Train: 91.43% | Val: 91.03%\n",
            "Epoch  4 | Train: 92.39% | Val: 91.03%\n",
            "Epoch  5 | Train: 94.02% | Val: 91.58%\n",
            "Epoch  6 | Train: 94.84% | Val: 92.12%\n",
            "Epoch  7 | Train: 95.47% | Val: 89.67%\n",
            "Epoch  8 | Train: 95.92% | Val: 89.40%\n",
            "Epoch  9 | Train: 96.32% | Val: 89.95%\n",
            "Epoch 10 | Train: 96.80% | Val: 90.49%\n",
            "Test Accuracy: 90.24%\n",
            "Start training model with 7 last layers trainable\n",
            "Epoch  1 | Train: 60.08% | Val: 83.97%\n",
            "Epoch  2 | Train: 88.83% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.55% | Val: 89.40%\n",
            "Epoch  4 | Train: 93.18% | Val: 89.13%\n",
            "Epoch  5 | Train: 94.11% | Val: 90.49%\n",
            "Epoch  6 | Train: 94.72% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.50% | Val: 89.95%\n",
            "Epoch  8 | Train: 95.65% | Val: 90.22%\n",
            "Epoch  9 | Train: 96.65% | Val: 88.59%\n",
            "Epoch 10 | Train: 96.83% | Val: 89.95%\n",
            "Test Accuracy: 89.26%\n",
            "Start training model with 8 last layers trainable\n",
            "Epoch  1 | Train: 58.91% | Val: 83.15%\n",
            "Epoch  2 | Train: 87.98% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.46% | Val: 88.32%\n",
            "Epoch  4 | Train: 92.63% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.99% | Val: 92.39%\n",
            "Epoch  6 | Train: 94.81% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.41% | Val: 90.76%\n",
            "Epoch  8 | Train: 96.41% | Val: 90.49%\n",
            "Epoch  9 | Train: 96.86% | Val: 90.22%\n",
            "Epoch 10 | Train: 96.89% | Val: 90.22%\n",
            "Test Accuracy: 89.37%\n",
            "Start training model with 9 last layers trainable\n",
            "Epoch  1 | Train: 59.75% | Val: 84.51%\n",
            "Epoch  2 | Train: 87.83% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.18% | Val: 89.13%\n",
            "Epoch  4 | Train: 92.84% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.96% | Val: 91.03%\n",
            "Epoch  6 | Train: 94.35% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.71% | Val: 91.58%\n",
            "Epoch  8 | Train: 96.44% | Val: 91.85%\n",
            "Epoch  9 | Train: 96.44% | Val: 89.40%\n",
            "Epoch 10 | Train: 96.74% | Val: 90.76%\n",
            "Test Accuracy: 89.72%\n"
          ]
        }
      ],
      "source": [
        "# Strategy 1: train with l layers unfrozen simultaneously\n",
        "accs = []\n",
        "for L in range(1, 10):\n",
        "  print(f\"Start training model with {L} last layers trainable\")\n",
        "  modelmulti = NeuralNetwork(basemodel, 37, train_loader, val_loader, test_loader, unfreeze=L)\n",
        "  accs.append(modelmulti.train(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c430ee-62c5-4d22-8ee1-2692741d9810",
      "metadata": {
        "id": "05c430ee-62c5-4d22-8ee1-2692741d9810",
        "outputId": "5df49277-f1b9-46bb-8317-080cd81d3e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=False\n",
            "Epoch  1 | Train: 74.61% | Val: 86.14%\n",
            "Epoch  2 | Train: 94.11% | Val: 89.95%\n",
            "Epoch  3 | Train: 97.49% | Val: 89.40%\n",
            "Epoch  4 | Train: 99.49% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.61% | Val: 89.95%\n",
            "Epoch  6 | Train: 99.64% | Val: 90.49%\n",
            "Epoch  7 | Train: 99.88% | Val: 90.22%\n",
            "Epoch  8 | Train: 99.94% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.82% | Val: 89.13%\n",
            "Epoch 10 | Train: 99.91% | Val: 89.40%\n",
            "Test Accuracy: 89.62%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=True\n",
            "Epoch  1 | Train: 75.91% | Val: 88.86%\n",
            "Epoch  2 | Train: 94.75% | Val: 88.59%\n",
            "Epoch  3 | Train: 97.83% | Val: 88.32%\n",
            "Epoch  4 | Train: 99.12% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.55% | Val: 89.67%\n",
            "Epoch  6 | Train: 99.85% | Val: 90.22%\n",
            "Epoch  7 | Train: 99.91% | Val: 89.40%\n",
            "Epoch  8 | Train: 99.97% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.97% | Val: 89.95%\n",
            "Epoch 10 | Train: 99.97% | Val: 90.22%\n",
            "Test Accuracy: 90.87%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=False\n",
            "Epoch  1 | Train: 74.12% | Val: 88.86%\n",
            "Epoch  2 | Train: 94.14% | Val: 90.49%\n",
            "Epoch  3 | Train: 97.77% | Val: 89.95%\n",
            "Epoch  4 | Train: 99.09% | Val: 88.86%\n",
            "Epoch  5 | Train: 99.70% | Val: 90.49%\n",
            "Epoch  6 | Train: 99.85% | Val: 91.30%\n",
            "Epoch  7 | Train: 99.88% | Val: 90.76%\n",
            "Epoch  8 | Train: 99.94% | Val: 89.13%\n",
            "Epoch  9 | Train: 99.91% | Val: 90.49%\n",
            "Epoch 10 | Train: 99.82% | Val: 90.22%\n",
            "Test Accuracy: 90.38%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=True\n",
            "Epoch  1 | Train: 74.43% | Val: 87.23%\n",
            "Epoch  2 | Train: 93.78% | Val: 86.41%\n",
            "Epoch  3 | Train: 97.68% | Val: 89.40%\n",
            "Epoch  4 | Train: 98.94% | Val: 90.76%\n",
            "Epoch  5 | Train: 99.61% | Val: 89.95%\n",
            "Epoch  6 | Train: 99.88% | Val: 90.76%\n",
            "Epoch  7 | Train: 99.97% | Val: 91.03%\n",
            "Epoch  8 | Train: 99.97% | Val: 90.76%\n",
            "Epoch  9 | Train: 99.94% | Val: 91.30%\n",
            "Epoch 10 | Train: 100.00% | Val: 90.49%\n",
            "Test Accuracy: 90.57%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=False\n",
            "Epoch  1 | Train: 73.31% | Val: 86.96%\n",
            "Epoch  2 | Train: 94.08% | Val: 88.32%\n",
            "Epoch  3 | Train: 98.01% | Val: 86.68%\n",
            "Epoch  4 | Train: 99.06% | Val: 88.32%\n",
            "Epoch  5 | Train: 99.09% | Val: 88.32%\n",
            "Epoch  6 | Train: 99.91% | Val: 88.86%\n",
            "Epoch  7 | Train: 99.73% | Val: 88.59%\n",
            "Epoch  8 | Train: 99.97% | Val: 88.86%\n",
            "Epoch  9 | Train: 99.97% | Val: 87.77%\n",
            "Epoch 10 | Train: 99.91% | Val: 89.13%\n",
            "Test Accuracy: 90.30%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=True\n",
            "Epoch  1 | Train: 75.00% | Val: 87.77%\n",
            "Epoch  2 | Train: 94.11% | Val: 88.04%\n",
            "Epoch  3 | Train: 97.86% | Val: 90.76%\n",
            "Epoch  4 | Train: 98.82% | Val: 88.86%\n",
            "Epoch  5 | Train: 99.43% | Val: 89.67%\n",
            "Epoch  6 | Train: 99.91% | Val: 90.49%\n",
            "Epoch  7 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  8 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  9 | Train: 100.00% | Val: 89.40%\n",
            "Epoch 10 | Train: 99.94% | Val: 90.49%\n",
            "Test Accuracy: 91.11%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=False\n",
            "Epoch  1 | Train: 73.64% | Val: 87.50%\n",
            "Epoch  2 | Train: 94.11% | Val: 88.04%\n",
            "Epoch  3 | Train: 97.40% | Val: 89.67%\n",
            "Epoch  4 | Train: 98.97% | Val: 89.13%\n",
            "Epoch  5 | Train: 99.40% | Val: 88.32%\n",
            "Epoch  6 | Train: 99.85% | Val: 89.40%\n",
            "Epoch  7 | Train: 99.85% | Val: 91.03%\n",
            "Epoch  8 | Train: 99.79% | Val: 90.49%\n",
            "Epoch  9 | Train: 99.94% | Val: 89.40%\n",
            "Epoch 10 | Train: 99.97% | Val: 90.49%\n",
            "Test Accuracy: 90.24%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=True\n",
            "Epoch  1 | Train: 74.82% | Val: 86.68%\n",
            "Epoch  2 | Train: 93.96% | Val: 88.04%\n",
            "Epoch  3 | Train: 98.01% | Val: 89.40%\n",
            "Epoch  4 | Train: 98.97% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.52% | Val: 90.22%\n",
            "Epoch  6 | Train: 99.88% | Val: 89.95%\n",
            "Epoch  7 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  8 | Train: 100.00% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.97% | Val: 89.95%\n",
            "Epoch 10 | Train: 99.94% | Val: 89.95%\n",
            "Test Accuracy: 90.54%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=False\n",
            "Epoch  1 | Train: 71.17% | Val: 85.05%\n",
            "Epoch  2 | Train: 90.07% | Val: 88.04%\n",
            "Epoch  3 | Train: 93.45% | Val: 88.04%\n",
            "Epoch  4 | Train: 95.56% | Val: 87.23%\n",
            "Epoch  5 | Train: 96.32% | Val: 89.13%\n",
            "Epoch  6 | Train: 97.04% | Val: 88.32%\n",
            "Epoch  7 | Train: 97.58% | Val: 88.59%\n",
            "Epoch  8 | Train: 98.22% | Val: 86.41%\n",
            "Epoch  9 | Train: 97.83% | Val: 84.78%\n",
            "Epoch 10 | Train: 98.25% | Val: 88.32%\n",
            "Test Accuracy: 88.14%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=True\n",
            "Epoch  1 | Train: 69.05% | Val: 86.96%\n",
            "Epoch  2 | Train: 89.19% | Val: 87.23%\n",
            "Epoch  3 | Train: 93.27% | Val: 88.32%\n",
            "Epoch  4 | Train: 95.29% | Val: 88.04%\n",
            "Epoch  5 | Train: 96.68% | Val: 87.23%\n",
            "Epoch  6 | Train: 98.16% | Val: 89.13%\n",
            "Epoch  7 | Train: 98.82% | Val: 91.03%\n",
            "Epoch  8 | Train: 98.67% | Val: 87.23%\n",
            "Epoch  9 | Train: 98.79% | Val: 89.67%\n",
            "Epoch 10 | Train: 99.06% | Val: 87.77%\n",
            "Test Accuracy: 89.70%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=False\n",
            "Epoch  1 | Train: 71.92% | Val: 86.14%\n",
            "Epoch  2 | Train: 90.25% | Val: 86.68%\n",
            "Epoch  3 | Train: 93.54% | Val: 86.68%\n",
            "Epoch  4 | Train: 95.08% | Val: 86.96%\n",
            "Epoch  5 | Train: 96.71% | Val: 85.33%\n",
            "Epoch  6 | Train: 97.40% | Val: 88.86%\n",
            "Epoch  7 | Train: 97.04% | Val: 88.86%\n",
            "Epoch  8 | Train: 97.89% | Val: 86.14%\n",
            "Epoch  9 | Train: 98.85% | Val: 88.86%\n",
            "Epoch 10 | Train: 98.61% | Val: 88.32%\n",
            "Test Accuracy: 87.33%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=True\n",
            "Epoch  1 | Train: 69.29% | Val: 85.05%\n",
            "Epoch  2 | Train: 90.43% | Val: 86.68%\n",
            "Epoch  3 | Train: 93.21% | Val: 89.13%\n",
            "Epoch  4 | Train: 94.96% | Val: 88.32%\n",
            "Epoch  5 | Train: 96.53% | Val: 85.87%\n",
            "Epoch  6 | Train: 98.04% | Val: 89.13%\n",
            "Epoch  7 | Train: 98.49% | Val: 90.22%\n",
            "Epoch  8 | Train: 98.37% | Val: 88.32%\n",
            "Epoch  9 | Train: 98.82% | Val: 91.03%\n",
            "Epoch 10 | Train: 99.18% | Val: 90.22%\n",
            "Test Accuracy: 89.70%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=False\n",
            "Epoch  1 | Train: 71.04% | Val: 83.70%\n",
            "Epoch  2 | Train: 90.28% | Val: 86.14%\n",
            "Epoch  3 | Train: 92.84% | Val: 87.23%\n",
            "Epoch  4 | Train: 95.77% | Val: 87.50%\n",
            "Epoch  5 | Train: 96.71% | Val: 87.23%\n",
            "Epoch  6 | Train: 97.28% | Val: 88.86%\n",
            "Epoch  7 | Train: 98.28% | Val: 86.68%\n",
            "Epoch  8 | Train: 97.40% | Val: 86.14%\n",
            "Epoch  9 | Train: 98.49% | Val: 87.50%\n",
            "Epoch 10 | Train: 98.52% | Val: 88.04%\n",
            "Test Accuracy: 88.28%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=True\n",
            "Epoch  1 | Train: 70.08% | Val: 86.96%\n",
            "Epoch  2 | Train: 90.37% | Val: 85.87%\n",
            "Epoch  3 | Train: 94.02% | Val: 88.04%\n",
            "Epoch  4 | Train: 95.38% | Val: 87.50%\n",
            "Epoch  5 | Train: 96.47% | Val: 88.32%\n",
            "Epoch  6 | Train: 97.89% | Val: 88.59%\n",
            "Epoch  7 | Train: 98.40% | Val: 88.32%\n",
            "Epoch  8 | Train: 98.67% | Val: 88.86%\n",
            "Epoch  9 | Train: 98.91% | Val: 89.40%\n",
            "Epoch 10 | Train: 98.85% | Val: 89.95%\n",
            "Test Accuracy: 89.56%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=False\n",
            "Epoch  1 | Train: 70.98% | Val: 85.87%\n",
            "Epoch  2 | Train: 89.49% | Val: 86.41%\n",
            "Epoch  3 | Train: 92.36% | Val: 88.04%\n",
            "Epoch  4 | Train: 94.90% | Val: 88.32%\n",
            "Epoch  5 | Train: 96.38% | Val: 88.32%\n",
            "Epoch  6 | Train: 96.86% | Val: 88.04%\n",
            "Epoch  7 | Train: 98.49% | Val: 85.87%\n",
            "Epoch  8 | Train: 98.22% | Val: 88.04%\n",
            "Epoch  9 | Train: 98.19% | Val: 89.13%\n",
            "Epoch 10 | Train: 98.01% | Val: 90.22%\n",
            "Test Accuracy: 86.43%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=True\n",
            "Epoch  1 | Train: 70.02% | Val: 86.14%\n",
            "Epoch  2 | Train: 89.98% | Val: 85.33%\n",
            "Epoch  3 | Train: 93.39% | Val: 87.77%\n",
            "Epoch  4 | Train: 95.35% | Val: 88.86%\n",
            "Epoch  5 | Train: 96.41% | Val: 89.13%\n",
            "Epoch  6 | Train: 97.92% | Val: 88.86%\n",
            "Epoch  7 | Train: 98.61% | Val: 89.95%\n",
            "Epoch  8 | Train: 98.88% | Val: 87.77%\n",
            "Epoch  9 | Train: 99.03% | Val: 89.13%\n",
            "Epoch 10 | Train: 99.31% | Val: 89.40%\n",
            "Test Accuracy: 89.45%\n",
            "\n",
            "=== Strategy 1 Extended Grid Results ===\n",
            "aug=False, freeze_bn=False, L2=False, sched=False → Test Acc: 89.62%\n",
            "aug=False, freeze_bn=False, L2=False, sched=True → Test Acc: 90.87%\n",
            "aug=False, freeze_bn=False, L2=True, sched=False → Test Acc: 90.38%\n",
            "aug=False, freeze_bn=False, L2=True, sched=True → Test Acc: 90.57%\n",
            "aug=False, freeze_bn=True, L2=False, sched=False → Test Acc: 90.30%\n",
            "aug=False, freeze_bn=True, L2=False, sched=True → Test Acc: 91.11%\n",
            "aug=False, freeze_bn=True, L2=True, sched=False → Test Acc: 90.24%\n",
            "aug=False, freeze_bn=True, L2=True, sched=True → Test Acc: 90.54%\n",
            "aug=True, freeze_bn=False, L2=False, sched=False → Test Acc: 88.14%\n",
            "aug=True, freeze_bn=False, L2=False, sched=True → Test Acc: 89.70%\n",
            "aug=True, freeze_bn=False, L2=True, sched=False → Test Acc: 87.33%\n",
            "aug=True, freeze_bn=False, L2=True, sched=True → Test Acc: 89.70%\n",
            "aug=True, freeze_bn=True, L2=False, sched=False → Test Acc: 88.28%\n",
            "aug=True, freeze_bn=True, L2=False, sched=True → Test Acc: 89.56%\n",
            "aug=True, freeze_bn=True, L2=True, sched=False → Test Acc: 86.43%\n",
            "aug=True, freeze_bn=True, L2=True, sched=True → Test Acc: 89.45%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Transforms\n",
        "base_tf = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "aug_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(), transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "# Create datasets and split 90/10\n",
        "full_ds = MultiClassPet(\"data\", trainval_names, breeds_map, transform=base_tf)\n",
        "n_val   = int(0.1 * len(full_ds))\n",
        "train_ds, val_ds = random_split(full_ds, [len(full_ds)-n_val, n_val])\n",
        "test_ds = MultiClassPet(\"data\", test_names, breeds_map, transform=base_tf)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 32\n",
        "val_loader  = DataLoader(val_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Strategy 1 grid\n",
        "results = []\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "\n",
        "for use_aug in [False, True]:\n",
        "    for freeze_bn in [False, True]:\n",
        "        for use_l2 in [False, True]:\n",
        "            for use_sched in [False, True]:\n",
        "                print(f\"\\n>>> aug={use_aug}, freeze_bn={freeze_bn}, L2={use_l2}, sched={use_sched}\")\n",
        "\n",
        "                # a) Set train transform\n",
        "                train_ds.dataset.transform = aug_tf if use_aug else base_tf\n",
        "\n",
        "                # b) Train loader\n",
        "                train_loader = DataLoader(\n",
        "                    train_ds, batch_size=batch_size, shuffle=True,\n",
        "                    num_workers=4, pin_memory=True\n",
        "                )\n",
        "\n",
        "                # c) Init model, fine-tune last 6 layers\n",
        "                model = NeuralNetwork(\n",
        "                    basemodel=basemodel,\n",
        "                    output=len(breed_names),\n",
        "                    train_loader=train_loader,\n",
        "                    val_loader=val_loader,\n",
        "                    test_loader=test_loader,\n",
        "                    unfreeze=6,\n",
        "                    parameters={}\n",
        "                )\n",
        "                model.model.to(device)\n",
        "\n",
        "                # d) Freeze batch-norm if requested\n",
        "                if freeze_bn:\n",
        "                    for m in model.model.modules():\n",
        "                        if isinstance(m, nn.BatchNorm2d):\n",
        "                            m.eval()\n",
        "                            for p in m.parameters():\n",
        "                                p.requires_grad = False\n",
        "\n",
        "                # e) Optimizer with two LR groups, optional L2 weight decay\n",
        "                wd = 1e-2 if use_l2 else 0.0\n",
        "                head_p = list(model.model.fc.parameters())\n",
        "                back_p = [p for n,p in model.model.named_parameters()\n",
        "                          if p.requires_grad and not n.startswith(\"fc\")]\n",
        "                model.optimizer = optim.AdamW([\n",
        "                    {\"params\": head_p, \"lr\":1e-3, \"weight_decay\":wd},\n",
        "                    {\"params\": back_p, \"lr\":1e-4, \"weight_decay\":wd}\n",
        "                ])\n",
        "\n",
        "                # f) Scheduler if requested\n",
        "                if use_sched:\n",
        "                    model.scheduler = optim.lr_scheduler.StepLR(model.optimizer, step_size=5, gamma=0.1)\n",
        "                else:\n",
        "                    model.scheduler = None\n",
        "\n",
        "                # g) Train and record test accuracy\n",
        "                acc = model.train(epochs=10)\n",
        "                results.append(((use_aug, freeze_bn, use_l2, use_sched), acc))\n",
        "\n",
        "# Summary for comparison\n",
        "print(\"\\n=== Strategy 1 Extended Grid Results ===\")\n",
        "for (aug, bn, l2, sched), acc in results:\n",
        "    print(f\"aug={aug}, freeze_bn={bn}, L2={l2}, sched={sched} → Test Acc: {acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "906198d5-6a25-4adb-b4cc-aaf32dc13b1c",
      "metadata": {
        "id": "906198d5-6a25-4adb-b4cc-aaf32dc13b1c"
      },
      "source": [
        "-> Strategy 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vQdtxDaSeTEd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vQdtxDaSeTEd",
        "outputId": "18dc5d37-1421-411b-c3f7-38d9bd3021bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training model with uf_rate 0.3\n",
            "Epoch  1 | Train: 61.08% | Val: 83.97%\n",
            "Epoch  2 | Train: 88.68% | Val: 89.13%\n",
            "Epoch  3 | Train: 91.46% | Val: 90.76%\n",
            "Epoch  4 | Train: 92.39% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.75% | Val: 91.30%\n",
            "Epoch  6 | Train: 94.93% | Val: 90.22%\n",
            "Epoch  7 | Train: 95.77% | Val: 91.03%\n",
            "Epoch  8 | Train: 95.92% | Val: 90.22%\n",
            "Epoch  9 | Train: 96.71% | Val: 89.95%\n",
            "Epoch 10 | Train: 97.04% | Val: 90.22%\n",
            "Test Accuracy: 90.27%\n",
            "Start training model with uf_rate 0.5\n",
            "Epoch  1 | Train: 60.60% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.07% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.70% | Val: 89.67%\n",
            "Epoch  4 | Train: 93.48% | Val: 89.95%\n",
            "Epoch  5 | Train: 93.72% | Val: 90.49%\n",
            "Epoch  6 | Train: 94.96% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.59% | Val: 90.49%\n",
            "Epoch  8 | Train: 95.59% | Val: 89.40%\n",
            "Epoch  9 | Train: 95.98% | Val: 89.13%\n",
            "Epoch 10 | Train: 96.68% | Val: 89.40%\n",
            "Test Accuracy: 89.07%\n",
            "Start training model with uf_rate 0.8\n",
            "Epoch  1 | Train: 59.48% | Val: 85.60%\n",
            "Epoch  2 | Train: 88.77% | Val: 88.86%\n",
            "Epoch  3 | Train: 90.73% | Val: 91.03%\n",
            "Epoch  4 | Train: 92.69% | Val: 90.22%\n",
            "Epoch  5 | Train: 94.47% | Val: 91.30%\n",
            "Epoch  6 | Train: 94.84% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.71% | Val: 91.03%\n",
            "Epoch  8 | Train: 96.01% | Val: 91.30%\n",
            "Epoch  9 | Train: 96.74% | Val: 90.76%\n",
            "Epoch 10 | Train: 96.89% | Val: 90.76%\n",
            "Test Accuracy: 89.37%\n",
            "Start training model with uf_rate 1\n",
            "Epoch  1 | Train: 58.97% | Val: 82.88%\n",
            "Epoch  2 | Train: 88.32% | Val: 87.50%\n",
            "Epoch  3 | Train: 92.09% | Val: 88.86%\n",
            "Epoch  4 | Train: 92.75% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.75% | Val: 89.13%\n",
            "Epoch  6 | Train: 94.84% | Val: 91.85%\n",
            "Epoch  7 | Train: 95.68% | Val: 89.13%\n",
            "Epoch  8 | Train: 96.29% | Val: 89.95%\n",
            "Epoch  9 | Train: 96.29% | Val: 89.67%\n",
            "Epoch 10 | Train: 96.71% | Val: 89.40%\n",
            "Test Accuracy: 89.67%\n",
            "Start training model with uf_rate 2\n",
            "Epoch  1 | Train: 61.29% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.16% | Val: 87.77%\n",
            "Epoch  3 | Train: 91.49% | Val: 88.86%\n",
            "Epoch  4 | Train: 92.75% | Val: 88.04%\n",
            "Epoch  5 | Train: 93.39% | Val: 88.86%\n",
            "Epoch  6 | Train: 95.11% | Val: 89.40%\n",
            "Epoch  7 | Train: 95.62% | Val: 90.49%\n",
            "Epoch  8 | Train: 95.29% | Val: 89.95%\n",
            "Epoch  9 | Train: 96.62% | Val: 89.95%\n",
            "Epoch 10 | Train: 96.32% | Val: 89.13%\n",
            "Test Accuracy: 90.27%\n",
            "Start training model with uf_rate 3\n",
            "Epoch  1 | Train: 60.99% | Val: 85.87%\n",
            "Epoch  2 | Train: 89.01% | Val: 88.59%\n",
            "Epoch  3 | Train: 90.88% | Val: 90.49%\n",
            "Epoch  4 | Train: 93.48% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.84% | Val: 90.22%\n",
            "Epoch  6 | Train: 95.20% | Val: 91.58%\n",
            "Epoch  7 | Train: 95.62% | Val: 90.76%\n",
            "Epoch  8 | Train: 95.83% | Val: 89.40%\n",
            "Epoch  9 | Train: 96.41% | Val: 89.67%\n",
            "Epoch 10 | Train: 97.04% | Val: 88.86%\n",
            "Test Accuracy: 89.94%\n"
          ]
        }
      ],
      "source": [
        "# Strategy 2: train with gradual unfreezing\n",
        "parameters = {}\n",
        "parameters['gradual_unfreezing'] = True\n",
        "accs = []\n",
        "\n",
        "# test rates in steps of two\n",
        "for rate in [0.3, 0.5, 0.8, 1, 2, 3]:\n",
        "  print(f\"Start training model with uf_rate {rate}\")\n",
        "  parameters['unfreezing_rate'] = rate\n",
        "  modelmulti = NeuralNetwork(basemodel, 37, train_loader, val_loader, test_loader, unfreeze=1, parameters=parameters)   # start with only one unfrozen layer\n",
        "  accs.append(modelmulti.train(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd91e0d3-e161-4eaa-a1c6-963be4e032bb",
      "metadata": {
        "id": "bd91e0d3-e161-4eaa-a1c6-963be4e032bb",
        "outputId": "b19382e0-6211-441b-f921-410a1c6e17a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=none\n",
            "Epoch  1 | Train: 60.63% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.74% | Val: 86.41%\n",
            "Epoch  3 | Train: 91.24% | Val: 84.78%\n",
            "Epoch  4 | Train: 93.15% | Val: 88.59%\n",
            "Epoch  5 | Train: 94.50% | Val: 88.32%\n",
            "Epoch  6 | Train: 95.59% | Val: 89.40%\n",
            "Epoch  7 | Train: 95.44% | Val: 88.04%\n",
            "Epoch  8 | Train: 96.29% | Val: 90.22%\n",
            "Epoch  9 | Train: 97.16% | Val: 88.04%\n",
            "Epoch 10 | Train: 97.31% | Val: 88.59%\n",
            "Test Accuracy: 89.34%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=steplr\n",
            "Epoch  1 | Train: 59.51% | Val: 82.34%\n",
            "Epoch  2 | Train: 88.13% | Val: 86.68%\n",
            "Epoch  3 | Train: 91.82% | Val: 89.13%\n",
            "Epoch  4 | Train: 92.84% | Val: 89.13%\n",
            "Epoch  5 | Train: 93.90% | Val: 89.95%\n",
            "Epoch  6 | Train: 95.89% | Val: 91.30%\n",
            "Epoch  7 | Train: 96.01% | Val: 91.03%\n",
            "Epoch  8 | Train: 96.38% | Val: 91.30%\n",
            "Epoch  9 | Train: 96.35% | Val: 91.58%\n",
            "Epoch 10 | Train: 96.26% | Val: 91.03%\n",
            "Test Accuracy: 89.70%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=onecycle\n",
            "Epoch  1 | Train: 3.83% | Val: 5.98%\n",
            "Epoch  2 | Train: 12.26% | Val: 16.03%\n",
            "Epoch  3 | Train: 24.09% | Val: 30.16%\n",
            "Epoch  4 | Train: 39.31% | Val: 44.84%\n",
            "Epoch  5 | Train: 52.51% | Val: 57.34%\n",
            "Epoch  6 | Train: 61.20% | Val: 64.13%\n",
            "Epoch  7 | Train: 68.30% | Val: 67.39%\n",
            "Epoch  8 | Train: 72.71% | Val: 72.01%\n",
            "Epoch  9 | Train: 74.79% | Val: 74.73%\n",
            "Epoch 10 | Train: 77.84% | Val: 76.63%\n",
            "Test Accuracy: 78.06%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=none\n",
            "Epoch  1 | Train: 63.29% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.22% | Val: 86.14%\n",
            "Epoch  3 | Train: 90.85% | Val: 88.04%\n",
            "Epoch  4 | Train: 93.15% | Val: 89.40%\n",
            "Epoch  5 | Train: 94.08% | Val: 89.13%\n",
            "Epoch  6 | Train: 95.20% | Val: 90.49%\n",
            "Epoch  7 | Train: 96.41% | Val: 89.67%\n",
            "Epoch  8 | Train: 95.59% | Val: 88.32%\n",
            "Epoch  9 | Train: 96.71% | Val: 90.22%\n",
            "Epoch 10 | Train: 97.34% | Val: 89.40%\n",
            "Test Accuracy: 89.72%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 59.60% | Val: 82.88%\n",
            "Epoch  2 | Train: 88.59% | Val: 87.77%\n",
            "Epoch  3 | Train: 91.85% | Val: 86.68%\n",
            "Epoch  4 | Train: 93.27% | Val: 88.32%\n",
            "Epoch  5 | Train: 94.29% | Val: 88.04%\n",
            "Epoch  6 | Train: 95.80% | Val: 88.86%\n",
            "Epoch  7 | Train: 96.23% | Val: 88.86%\n",
            "Epoch  8 | Train: 96.26% | Val: 88.86%\n",
            "Epoch  9 | Train: 96.29% | Val: 90.22%\n",
            "Epoch 10 | Train: 96.56% | Val: 90.22%\n",
            "Test Accuracy: 90.05%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=onecycle\n",
            "Epoch  1 | Train: 5.40% | Val: 8.97%\n",
            "Epoch  2 | Train: 15.61% | Val: 19.84%\n",
            "Epoch  3 | Train: 28.59% | Val: 37.50%\n",
            "Epoch  4 | Train: 43.48% | Val: 48.91%\n",
            "Epoch  5 | Train: 54.59% | Val: 57.88%\n",
            "Epoch  6 | Train: 62.02% | Val: 65.76%\n",
            "Epoch  7 | Train: 68.66% | Val: 68.75%\n",
            "Epoch  8 | Train: 73.67% | Val: 71.47%\n",
            "Epoch  9 | Train: 77.26% | Val: 73.91%\n",
            "Epoch 10 | Train: 79.53% | Val: 76.36%\n",
            "Test Accuracy: 78.63%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=none\n",
            "Epoch  1 | Train: 59.90% | Val: 84.24%\n",
            "Epoch  2 | Train: 88.50% | Val: 89.13%\n",
            "Epoch  3 | Train: 91.91% | Val: 87.50%\n",
            "Epoch  4 | Train: 93.00% | Val: 89.13%\n",
            "Epoch  5 | Train: 93.69% | Val: 89.40%\n",
            "Epoch  6 | Train: 95.74% | Val: 89.40%\n",
            "Epoch  7 | Train: 95.92% | Val: 88.86%\n",
            "Epoch  8 | Train: 96.62% | Val: 90.22%\n",
            "Epoch  9 | Train: 97.19% | Val: 89.95%\n",
            "Epoch 10 | Train: 96.98% | Val: 90.76%\n",
            "Test Accuracy: 89.34%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=steplr\n",
            "Epoch  1 | Train: 60.39% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.41% | Val: 86.96%\n",
            "Epoch  3 | Train: 90.97% | Val: 87.23%\n",
            "Epoch  4 | Train: 92.63% | Val: 88.04%\n",
            "Epoch  5 | Train: 94.44% | Val: 87.77%\n",
            "Epoch  6 | Train: 95.74% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.80% | Val: 89.95%\n",
            "Epoch  8 | Train: 95.95% | Val: 89.95%\n",
            "Epoch  9 | Train: 95.95% | Val: 90.22%\n",
            "Epoch 10 | Train: 96.26% | Val: 90.22%\n",
            "Test Accuracy: 89.64%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=onecycle\n",
            "Epoch  1 | Train: 4.83% | Val: 8.97%\n",
            "Epoch  2 | Train: 13.35% | Val: 21.47%\n",
            "Epoch  3 | Train: 26.15% | Val: 36.41%\n",
            "Epoch  4 | Train: 40.58% | Val: 48.91%\n",
            "Epoch  5 | Train: 50.94% | Val: 56.52%\n",
            "Epoch  6 | Train: 59.45% | Val: 61.96%\n",
            "Epoch  7 | Train: 66.79% | Val: 67.39%\n",
            "Epoch  8 | Train: 70.59% | Val: 72.55%\n",
            "Epoch  9 | Train: 74.94% | Val: 74.73%\n",
            "Epoch 10 | Train: 78.26% | Val: 78.53%\n",
            "Test Accuracy: 77.24%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=none\n",
            "Epoch  1 | Train: 60.60% | Val: 84.24%\n",
            "Epoch  2 | Train: 87.71% | Val: 88.59%\n",
            "Epoch  3 | Train: 91.58% | Val: 88.32%\n",
            "Epoch  4 | Train: 93.30% | Val: 87.50%\n",
            "Epoch  5 | Train: 93.57% | Val: 88.59%\n",
            "Epoch  6 | Train: 94.99% | Val: 88.86%\n",
            "Epoch  7 | Train: 95.80% | Val: 90.49%\n",
            "Epoch  8 | Train: 96.26% | Val: 89.67%\n",
            "Epoch  9 | Train: 96.47% | Val: 89.13%\n",
            "Epoch 10 | Train: 96.50% | Val: 90.22%\n",
            "Test Accuracy: 89.13%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 59.27% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.25% | Val: 88.32%\n",
            "Epoch  3 | Train: 91.52% | Val: 87.77%\n",
            "Epoch  4 | Train: 93.24% | Val: 89.13%\n",
            "Epoch  5 | Train: 94.26% | Val: 90.22%\n",
            "Epoch  6 | Train: 95.89% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.95% | Val: 89.95%\n",
            "Epoch  8 | Train: 95.89% | Val: 89.67%\n",
            "Epoch  9 | Train: 96.50% | Val: 89.40%\n",
            "Epoch 10 | Train: 96.44% | Val: 88.86%\n",
            "Test Accuracy: 90.24%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=onecycle\n",
            "Epoch  1 | Train: 5.43% | Val: 8.97%\n",
            "Epoch  2 | Train: 14.70% | Val: 19.84%\n",
            "Epoch  3 | Train: 28.59% | Val: 34.51%\n",
            "Epoch  4 | Train: 40.73% | Val: 46.47%\n",
            "Epoch  5 | Train: 52.14% | Val: 54.62%\n",
            "Epoch  6 | Train: 62.47% | Val: 64.13%\n",
            "Epoch  7 | Train: 67.57% | Val: 70.11%\n",
            "Epoch  8 | Train: 73.31% | Val: 73.91%\n",
            "Epoch  9 | Train: 77.39% | Val: 76.63%\n",
            "Epoch 10 | Train: 79.80% | Val: 78.26%\n",
            "Test Accuracy: 78.90%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=none\n",
            "Epoch  1 | Train: 53.47% | Val: 78.53%\n",
            "Epoch  2 | Train: 82.91% | Val: 84.51%\n",
            "Epoch  3 | Train: 87.71% | Val: 85.33%\n",
            "Epoch  4 | Train: 88.86% | Val: 85.33%\n",
            "Epoch  5 | Train: 90.13% | Val: 83.97%\n",
            "Epoch  6 | Train: 91.36% | Val: 84.78%\n",
            "Epoch  7 | Train: 91.94% | Val: 87.50%\n",
            "Epoch  8 | Train: 92.33% | Val: 88.04%\n",
            "Epoch  9 | Train: 91.67% | Val: 85.87%\n",
            "Epoch 10 | Train: 93.06% | Val: 87.77%\n",
            "Test Accuracy: 89.04%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=steplr\n",
            "Epoch  1 | Train: 56.43% | Val: 80.71%\n",
            "Epoch  2 | Train: 83.24% | Val: 84.24%\n",
            "Epoch  3 | Train: 87.83% | Val: 82.34%\n",
            "Epoch  4 | Train: 88.56% | Val: 87.23%\n",
            "Epoch  5 | Train: 89.46% | Val: 86.41%\n",
            "Epoch  6 | Train: 92.12% | Val: 87.50%\n",
            "Epoch  7 | Train: 93.06% | Val: 88.04%\n",
            "Epoch  8 | Train: 92.69% | Val: 88.04%\n",
            "Epoch  9 | Train: 92.93% | Val: 86.41%\n",
            "Epoch 10 | Train: 93.21% | Val: 86.96%\n",
            "Test Accuracy: 89.07%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=onecycle\n",
            "Epoch  1 | Train: 3.26% | Val: 5.43%\n",
            "Epoch  2 | Train: 9.18% | Val: 15.76%\n",
            "Epoch  3 | Train: 19.44% | Val: 23.64%\n",
            "Epoch  4 | Train: 31.37% | Val: 37.50%\n",
            "Epoch  5 | Train: 42.48% | Val: 48.37%\n",
            "Epoch  6 | Train: 51.60% | Val: 52.99%\n",
            "Epoch  7 | Train: 59.24% | Val: 64.13%\n",
            "Epoch  8 | Train: 65.22% | Val: 67.12%\n",
            "Epoch  9 | Train: 70.17% | Val: 71.74%\n",
            "Epoch 10 | Train: 73.10% | Val: 72.55%\n",
            "Test Accuracy: 74.63%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=none\n",
            "Epoch  1 | Train: 56.25% | Val: 81.25%\n",
            "Epoch  2 | Train: 83.27% | Val: 84.51%\n",
            "Epoch  3 | Train: 87.65% | Val: 85.05%\n",
            "Epoch  4 | Train: 88.53% | Val: 86.41%\n",
            "Epoch  5 | Train: 90.28% | Val: 86.41%\n",
            "Epoch  6 | Train: 91.33% | Val: 85.87%\n",
            "Epoch  7 | Train: 92.00% | Val: 87.50%\n",
            "Epoch  8 | Train: 92.63% | Val: 87.50%\n",
            "Epoch  9 | Train: 92.54% | Val: 86.14%\n",
            "Epoch 10 | Train: 93.48% | Val: 88.32%\n",
            "Test Accuracy: 88.58%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 54.80% | Val: 79.35%\n",
            "Epoch  2 | Train: 83.36% | Val: 85.05%\n",
            "Epoch  3 | Train: 87.65% | Val: 87.50%\n",
            "Epoch  4 | Train: 89.40% | Val: 87.23%\n",
            "Epoch  5 | Train: 90.49% | Val: 87.77%\n",
            "Epoch  6 | Train: 92.36% | Val: 87.77%\n",
            "Epoch  7 | Train: 92.84% | Val: 86.68%\n",
            "Epoch  8 | Train: 92.42% | Val: 87.23%\n",
            "Epoch  9 | Train: 93.27% | Val: 88.04%\n",
            "Epoch 10 | Train: 92.51% | Val: 87.23%\n",
            "Test Accuracy: 88.93%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=onecycle\n",
            "Epoch  1 | Train: 3.80% | Val: 5.43%\n",
            "Epoch  2 | Train: 10.30% | Val: 16.58%\n",
            "Epoch  3 | Train: 20.17% | Val: 27.45%\n",
            "Epoch  4 | Train: 32.97% | Val: 33.97%\n",
            "Epoch  5 | Train: 44.08% | Val: 45.65%\n",
            "Epoch  6 | Train: 51.87% | Val: 52.17%\n",
            "Epoch  7 | Train: 58.79% | Val: 59.78%\n",
            "Epoch  8 | Train: 64.37% | Val: 61.41%\n",
            "Epoch  9 | Train: 70.29% | Val: 68.21%\n",
            "Epoch 10 | Train: 71.86% | Val: 71.47%\n",
            "Test Accuracy: 73.18%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=none\n",
            "Epoch  1 | Train: 53.29% | Val: 77.99%\n",
            "Epoch  2 | Train: 84.30% | Val: 83.97%\n",
            "Epoch  3 | Train: 87.68% | Val: 84.51%\n",
            "Epoch  4 | Train: 88.98% | Val: 85.60%\n",
            "Epoch  5 | Train: 90.19% | Val: 87.77%\n",
            "Epoch  6 | Train: 90.49% | Val: 86.96%\n",
            "Epoch  7 | Train: 92.09% | Val: 89.40%\n",
            "Epoch  8 | Train: 92.78% | Val: 86.41%\n",
            "Epoch  9 | Train: 92.84% | Val: 86.96%\n",
            "Epoch 10 | Train: 92.66% | Val: 87.23%\n",
            "Test Accuracy: 88.39%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=steplr\n",
            "Epoch  1 | Train: 54.77% | Val: 80.43%\n",
            "Epoch  2 | Train: 83.09% | Val: 82.34%\n",
            "Epoch  3 | Train: 87.92% | Val: 85.87%\n",
            "Epoch  4 | Train: 89.01% | Val: 85.60%\n",
            "Epoch  5 | Train: 90.07% | Val: 86.96%\n",
            "Epoch  6 | Train: 91.64% | Val: 87.77%\n",
            "Epoch  7 | Train: 92.72% | Val: 86.68%\n",
            "Epoch  8 | Train: 92.75% | Val: 88.32%\n",
            "Epoch  9 | Train: 93.00% | Val: 88.04%\n",
            "Epoch 10 | Train: 92.84% | Val: 86.68%\n",
            "Test Accuracy: 89.37%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=onecycle\n",
            "Epoch  1 | Train: 5.31% | Val: 10.60%\n",
            "Epoch  2 | Train: 13.10% | Val: 20.92%\n",
            "Epoch  3 | Train: 24.76% | Val: 32.34%\n",
            "Epoch  4 | Train: 38.32% | Val: 42.66%\n",
            "Epoch  5 | Train: 47.89% | Val: 53.53%\n",
            "Epoch  6 | Train: 57.52% | Val: 58.42%\n",
            "Epoch  7 | Train: 62.77% | Val: 63.86%\n",
            "Epoch  8 | Train: 66.52% | Val: 67.39%\n",
            "Epoch  9 | Train: 71.32% | Val: 70.11%\n",
            "Epoch 10 | Train: 73.85% | Val: 72.55%\n",
            "Test Accuracy: 75.28%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=none\n",
            "Epoch  1 | Train: 55.46% | Val: 79.89%\n",
            "Epoch  2 | Train: 85.30% | Val: 83.15%\n",
            "Epoch  3 | Train: 87.41% | Val: 83.70%\n",
            "Epoch  4 | Train: 89.52% | Val: 86.96%\n",
            "Epoch  5 | Train: 89.89% | Val: 84.24%\n",
            "Epoch  6 | Train: 90.94% | Val: 86.14%\n",
            "Epoch  7 | Train: 91.70% | Val: 86.41%\n",
            "Epoch  8 | Train: 92.42% | Val: 85.33%\n",
            "Epoch  9 | Train: 92.81% | Val: 85.87%\n",
            "Epoch 10 | Train: 92.66% | Val: 86.68%\n",
            "Test Accuracy: 87.90%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 56.31% | Val: 79.89%\n",
            "Epoch  2 | Train: 85.75% | Val: 82.61%\n",
            "Epoch  3 | Train: 87.98% | Val: 85.87%\n",
            "Epoch  4 | Train: 89.86% | Val: 85.33%\n",
            "Epoch  5 | Train: 90.61% | Val: 86.14%\n",
            "Epoch  6 | Train: 92.09% | Val: 86.68%\n",
            "Epoch  7 | Train: 92.63% | Val: 84.78%\n",
            "Epoch  8 | Train: 92.84% | Val: 85.33%\n",
            "Epoch  9 | Train: 92.39% | Val: 88.04%\n",
            "Epoch 10 | Train: 92.33% | Val: 86.68%\n",
            "Test Accuracy: 89.13%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=onecycle\n",
            "Epoch  1 | Train: 4.44% | Val: 8.15%\n",
            "Epoch  2 | Train: 11.59% | Val: 19.57%\n",
            "Epoch  3 | Train: 22.16% | Val: 28.26%\n",
            "Epoch  4 | Train: 33.70% | Val: 39.13%\n",
            "Epoch  5 | Train: 44.63% | Val: 47.28%\n",
            "Epoch  6 | Train: 54.74% | Val: 52.99%\n",
            "Epoch  7 | Train: 58.82% | Val: 57.88%\n",
            "Epoch  8 | Train: 65.43% | Val: 64.13%\n",
            "Epoch  9 | Train: 68.39% | Val: 64.95%\n",
            "Epoch 10 | Train: 72.04% | Val: 69.57%\n",
            "Test Accuracy: 76.70%\n",
            "\n",
            "=== Strategy 2 Grid Search Results ===\n",
            "aug | freeze_bn | L2   | scheduler | TestAcc\n",
            "----|-----------|------|-----------|--------\n",
            "False | False     | False | none      |  89.34%\n",
            "False | False     | False | steplr    |  89.70%\n",
            "False | False     | False | onecycle  |  78.06%\n",
            "False | False     | True | none      |  89.72%\n",
            "False | False     | True | steplr    |  90.05%\n",
            "False | False     | True | onecycle  |  78.63%\n",
            "False | True      | False | none      |  89.34%\n",
            "False | True      | False | steplr    |  89.64%\n",
            "False | True      | False | onecycle  |  77.24%\n",
            "False | True      | True | none      |  89.13%\n",
            "False | True      | True | steplr    |  90.24%\n",
            "False | True      | True | onecycle  |  78.90%\n",
            "True | False     | False | none      |  89.04%\n",
            "True | False     | False | steplr    |  89.07%\n",
            "True | False     | False | onecycle  |  74.63%\n",
            "True | False     | True | none      |  88.58%\n",
            "True | False     | True | steplr    |  88.93%\n",
            "True | False     | True | onecycle  |  73.18%\n",
            "True | True      | False | none      |  88.39%\n",
            "True | True      | False | steplr    |  89.37%\n",
            "True | True      | False | onecycle  |  75.28%\n",
            "True | True      | True | none      |  87.90%\n",
            "True | True      | True | steplr    |  89.13%\n",
            "True | True      | True | onecycle  |  76.70%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# transforms\n",
        "base_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "])\n",
        "aug_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "# model\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "\n",
        "# fixed unfreeze rate\n",
        "fixed_rate = 2.0\n",
        "\n",
        "# grid definitions\n",
        "augmentations = [False, True]\n",
        "freeze_bns    = [False, True]\n",
        "use_l2s       = [False, True]\n",
        "schedulers    = ['none', 'steplr', 'onecycle']\n",
        "\n",
        "results = []\n",
        "\n",
        "# running the grid\n",
        "for use_aug in augmentations:\n",
        "    # update train transform\n",
        "    train_ds.dataset.transform = aug_tf if use_aug else base_tf\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    for freeze_bn in freeze_bns:\n",
        "        for use_l2 in use_l2s:\n",
        "            for sched in schedulers:\n",
        "                print(f\"\\n>>> aug={use_aug}, freeze_bn={freeze_bn}, L2={use_l2}, sched={sched}\")\n",
        "\n",
        "                # a) Instantiate with gradual unfreezing\n",
        "                params = {'gradual_unfreezing': True, 'unfreezing_rate': fixed_rate}\n",
        "                model = NeuralNetwork(\n",
        "                    basemodel,\n",
        "                    len(breed_names),\n",
        "                    train_loader,\n",
        "                    val_loader,\n",
        "                    test_loader,\n",
        "                    unfreeze=1,\n",
        "                    parameters=params\n",
        "                )\n",
        "                model.model.to(device)\n",
        "\n",
        "                # b) Optionally freeze BatchNorm layers\n",
        "                if freeze_bn:\n",
        "                    for m in model.model.modules():\n",
        "                        if isinstance(m, nn.BatchNorm2d):\n",
        "                            m.eval()\n",
        "                            for p in m.parameters():\n",
        "                                p.requires_grad = False\n",
        "\n",
        "                # c) Build optimizer (head @1e-3, backbone @1e-4), optional L2\n",
        "                wd = 1e-2 if use_l2 else 0.0\n",
        "                head_p = list(model.model.fc.parameters())\n",
        "                back_p = [\n",
        "                    p for n,p in model.model.named_parameters()\n",
        "                    if p.requires_grad and not n.startswith(\"fc\")\n",
        "                ]\n",
        "                model.optimizer = optim.AdamW([\n",
        "                    {'params': head_p, 'lr':1e-3, 'weight_decay':wd},\n",
        "                    {'params': back_p, 'lr':1e-4, 'weight_decay':wd},\n",
        "                ])\n",
        "\n",
        "                # d) Attach scheduler if desired\n",
        "                if sched == 'steplr':\n",
        "                    model.scheduler = optim.lr_scheduler.StepLR(\n",
        "                        model.optimizer,\n",
        "                        step_size=5,\n",
        "                        gamma=0.1\n",
        "                    )\n",
        "                elif sched == 'onecycle':\n",
        "                    total_steps = len(train_loader) * 10\n",
        "                    model.scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "                        model.optimizer,\n",
        "                        max_lr=[1e-3,1e-4],\n",
        "                        total_steps=total_steps,\n",
        "                        pct_start=0.3,\n",
        "                        anneal_strategy='cos'\n",
        "                    )\n",
        "                else:\n",
        "                    model.scheduler = None\n",
        "\n",
        "                # e) Train & record\n",
        "                acc = model.train2(epochs=10)\n",
        "                results.append((use_aug, freeze_bn, use_l2, sched, acc))\n",
        "\n",
        "# Summary for comparison\n",
        "print(\"\\n=== Strategy 2 Grid Search Results ===\")\n",
        "print(\"aug | freeze_bn | L2   | scheduler | TestAcc\")\n",
        "print(\"----|-----------|------|-----------|--------\")\n",
        "for aug, fb, l2, sch, acc in results:\n",
        "    print(f\"{str(aug):<3} | {str(fb):<9} | {str(l2):<4} | {sch:<9} | {acc:6.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f013e172-d1f0-43e0-969b-ada6fb408829",
      "metadata": {
        "id": "f013e172-d1f0-43e0-969b-ada6fb408829"
      },
      "source": [
        "## Imbalanced classes\n",
        "\n",
        "1. Load the annotations/trainval.txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e5d5f38e-a763-4d5d-8d79-343db8b33475",
      "metadata": {
        "id": "e5d5f38e-a763-4d5d-8d79-343db8b33475"
      },
      "outputs": [],
      "source": [
        "# 0) Prepare names and label maps\n",
        "names = []\n",
        "breeds_map = {}\n",
        "\n",
        "with open(\"data/oxford-iiit-pet/annotations/trainval.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        name = parts[0]\n",
        "        class_id = int(parts[1]) - 1  # 0-indexed\n",
        "        names.append(name)\n",
        "        breeds_map[name] = class_id\n",
        "\n",
        "breed_to_id = {i: i for i in set(breeds_map.values())}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a77baf1",
      "metadata": {
        "id": "3a77baf1"
      },
      "source": [
        "Training with normal cross-entropy loss with limited data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9253ea5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9253ea5c",
        "outputId": "8bcd74bd-2c54-428f-c371-cd88c52a6e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Total samples in imbalanced dataset: 734\n",
            "Class distribution (samples, total, percentage):\n",
            "Abyssinian: 20/100 (20.0%)\n",
            "Bengal: 20/100 (20.0%)\n",
            "Birman: 20/100 (20.0%)\n",
            "Bombay: 19/96 (19.8%)\n",
            "British_Shorthair: 20/100 (20.0%)\n",
            "Egyptian_Mau: 18/93 (19.4%)\n",
            "Maine_Coon: 20/100 (20.0%)\n",
            "Persian: 20/100 (20.0%)\n",
            "Ragdoll: 20/100 (20.0%)\n",
            "Russian_Blue: 20/100 (20.0%)\n",
            "Siamese: 19/99 (19.2%)\n",
            "Sphynx: 20/100 (20.0%)\n",
            "american_bulldog: 20/100 (20.0%)\n",
            "american_pit_bull_terrier: 20/100 (20.0%)\n",
            "basset_hound: 20/100 (20.0%)\n",
            "beagle: 20/100 (20.0%)\n",
            "boxer: 20/100 (20.0%)\n",
            "chihuahua: 20/100 (20.0%)\n",
            "english_cocker_spaniel: 19/96 (19.8%)\n",
            "english_setter: 20/100 (20.0%)\n",
            "german_shorthaired: 20/100 (20.0%)\n",
            "great_pyrenees: 20/100 (20.0%)\n",
            "havanese: 20/100 (20.0%)\n",
            "japanese_chin: 20/100 (20.0%)\n",
            "keeshond: 20/100 (20.0%)\n",
            "leonberger: 20/100 (20.0%)\n",
            "miniature_pinscher: 20/100 (20.0%)\n",
            "newfoundland: 19/96 (19.8%)\n",
            "pomeranian: 20/100 (20.0%)\n",
            "pug: 20/100 (20.0%)\n",
            "saint_bernard: 20/100 (20.0%)\n",
            "samoyed: 20/100 (20.0%)\n",
            "scottish_terrier: 20/100 (20.0%)\n",
            "shiba_inu: 20/100 (20.0%)\n",
            "staffordshire_bull_terrier: 20/100 (20.0%)\n",
            "wheaten_terrier: 20/100 (20.0%)\n",
            "yorkshire_terrier: 20/100 (20.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Training Baseline Model with Standard Cross-Entropy Loss ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 191MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train: 13.29% | Val: 30.61%\n",
            "Epoch  2 | Train: 54.68% | Val: 60.54%\n",
            "Epoch  3 | Train: 77.17% | Val: 70.75%\n",
            "Epoch  4 | Train: 83.99% | Val: 73.47%\n",
            "Epoch  5 | Train: 89.27% | Val: 77.55%\n",
            "Epoch  6 | Train: 91.99% | Val: 80.27%\n",
            "Epoch  7 | Train: 93.87% | Val: 82.31%\n",
            "Epoch  8 | Train: 95.57% | Val: 84.35%\n",
            "Epoch  9 | Train: 96.59% | Val: 80.95%\n",
            "Epoch 10 | Train: 96.93% | Val: 85.71%\n",
            "Test Accuracy: 9.70%\n",
            "⮞ Baseline (last 5 layers) Test Acc: 9.70%\n",
            "\n",
            "==== Analysis of Impact on Classes with Limited Data ====\n",
            "Correlation between class sample count and accuracy: -0.0171\n",
            "\n",
            "Average accuracy across all classes: 9.84%\n"
          ]
        }
      ],
      "source": [
        "## Train only using 20%\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        "    SubsetRandomSampler,\n",
        "    WeightedRandomSampler\n",
        ")\n",
        "\n",
        "# --- Ensure device is defined ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load trainval metadata\n",
        "tmp_train = OxfordIIITPet(root=\"data\", split=\"trainval\", target_types=\"category\", download=True)\n",
        "# Extract image stems: e.g. \"Abyssinian_1\"\n",
        "names = [p.stem for p in tmp_train._images]\n",
        "\n",
        "# Build mapping from stem → breed_name\n",
        "breeds_map = {n: n.rsplit(\"_\", 1)[0] for n in names}\n",
        "breed_names = sorted(set(breeds_map.values()))   # 37 unique breed strings\n",
        "breed_to_id = {b: i for i, b in enumerate(breed_names)}\n",
        "\n",
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nm = self.names[idx]\n",
        "        img_path = os.path.join(self.root, \"oxford-iiit-pet\", \"images\", nm + \".jpg\")\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[nm]]\n",
        "        return img, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "root = \"data\"\n",
        "# Full train/val dataset\n",
        "full_dataset = MultiClassPet(root, names, breeds_map, transform=transform)\n",
        "\n",
        "# Build 20%-per-class imbalanced index list\n",
        "class_idxs = defaultdict(list)\n",
        "for idx, nm in enumerate(names):\n",
        "    lbl = breed_to_id[breeds_map[nm]]\n",
        "    class_idxs[lbl].append(idx)\n",
        "\n",
        "# Create an artificially imbalanced dataset with some breeds at 20%\n",
        "imbalanced = []\n",
        "class_percentages = {}  # To track how many samples are used from each class\n",
        "\n",
        "for lbl, idxs in class_idxs.items():\n",
        "    # Use 20% of data for each breed\n",
        "    k = max(1, int(0.2 * len(idxs)))\n",
        "    selected_idxs = random.sample(idxs, k)\n",
        "    imbalanced += selected_idxs\n",
        "    class_percentages[breed_names[lbl]] = (k, len(idxs), k/len(idxs)*100)\n",
        "\n",
        "# Print dataset stats\n",
        "print(f\"Total samples in imbalanced dataset: {len(imbalanced)}\")\n",
        "print(\"Class distribution (samples, total, percentage):\")\n",
        "for breed, (count, total, percentage) in sorted(class_percentages.items()):\n",
        "    print(f\"{breed}: {count}/{total} ({percentage:.1f}%)\")\n",
        "\n",
        "# Split imbalanced list into train/val (80/20)\n",
        "random.shuffle(imbalanced)\n",
        "split = int(0.8 * len(imbalanced))\n",
        "train_idxs = imbalanced[:split]\n",
        "val_idxs = imbalanced[split:]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Test loader via torchvision to avoid missing stems\n",
        "test_ds = OxfordIIITPet(\n",
        "    root=root,\n",
        "    split=\"test\",\n",
        "    target_types=\"category\",\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define the NeuralNetwork class for training and evaluation\n",
        "def make_model(unfreeze_layers=5):\n",
        "    \"\"\"\n",
        "    Returns a NeuralNetwork instance fine-tuned on the\n",
        "    imbalanced train_loader/val_loader/test_loader.\n",
        "    \"\"\"\n",
        "    basemodel = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    m = NeuralNetwork(\n",
        "        basemodel,\n",
        "        len(breed_names),\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        unfreeze=unfreeze_layers\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# Train baseline model with normal cross-entropy loss\n",
        "print(\"\\n==== Training Baseline Model with Standard Cross-Entropy Loss ====\")\n",
        "model_base = make_model(unfreeze_layers=5)\n",
        "base_acc = model_base.train(epochs=10)\n",
        "print(f\"⮞ Baseline (last 5 layers) Test Acc: {base_acc:.2f}%\")\n",
        "\n",
        "# Analyze the results - impact on the classes with limited data\n",
        "print(\"\\n==== Analysis of Impact on Classes with Limited Data ====\")\n",
        "test_acc, per_class_acc, class_counts = model_base.evaluate()\n",
        "\n",
        "# Calculate correlation between class sample counts and accuracy\n",
        "class_samples = [class_percentages[breed][0] for breed in breed_names]\n",
        "correlation = np.corrcoef(class_samples, per_class_acc)[0, 1]\n",
        "print(f\"Correlation between class sample count and accuracy: {correlation:.4f}\")\n",
        "\n",
        "# Compare accuracy of classes with fewer samples vs classes with more samples\n",
        "# (Since all classes are at 20%, this might not show significant differences)\n",
        "print(\"\\nAverage accuracy across all classes: {:.2f}%\".format(sum(per_class_acc) / len(per_class_acc)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb56283",
      "metadata": {
        "id": "4bb56283"
      },
      "source": [
        "Strategy using weighted cross-entropy and over-sampling of the minority classes to compensate for the imbalanced training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f6a519b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6a519b9",
        "outputId": "3bc466e6-2d2f-4055-85ef-ea521dba0802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Total samples in imbalanced dataset: 734\n",
            "Class distribution (samples, total, percentage):\n",
            "Abyssinian: 20/100 (20.0%)\n",
            "Bengal: 20/100 (20.0%)\n",
            "Birman: 20/100 (20.0%)\n",
            "Bombay: 19/96 (19.8%)\n",
            "British_Shorthair: 20/100 (20.0%)\n",
            "Egyptian_Mau: 18/93 (19.4%)\n",
            "Maine_Coon: 20/100 (20.0%)\n",
            "Persian: 20/100 (20.0%)\n",
            "Ragdoll: 20/100 (20.0%)\n",
            "Russian_Blue: 20/100 (20.0%)\n",
            "Siamese: 19/99 (19.2%)\n",
            "Sphynx: 20/100 (20.0%)\n",
            "american_bulldog: 20/100 (20.0%)\n",
            "american_pit_bull_terrier: 20/100 (20.0%)\n",
            "basset_hound: 20/100 (20.0%)\n",
            "beagle: 20/100 (20.0%)\n",
            "boxer: 20/100 (20.0%)\n",
            "chihuahua: 20/100 (20.0%)\n",
            "english_cocker_spaniel: 19/96 (19.8%)\n",
            "english_setter: 20/100 (20.0%)\n",
            "german_shorthaired: 20/100 (20.0%)\n",
            "great_pyrenees: 20/100 (20.0%)\n",
            "havanese: 20/100 (20.0%)\n",
            "japanese_chin: 20/100 (20.0%)\n",
            "keeshond: 20/100 (20.0%)\n",
            "leonberger: 20/100 (20.0%)\n",
            "miniature_pinscher: 20/100 (20.0%)\n",
            "newfoundland: 19/96 (19.8%)\n",
            "pomeranian: 20/100 (20.0%)\n",
            "pug: 20/100 (20.0%)\n",
            "saint_bernard: 20/100 (20.0%)\n",
            "samoyed: 20/100 (20.0%)\n",
            "scottish_terrier: 20/100 (20.0%)\n",
            "shiba_inu: 20/100 (20.0%)\n",
            "staffordshire_bull_terrier: 20/100 (20.0%)\n",
            "wheaten_terrier: 20/100 (20.0%)\n",
            "yorkshire_terrier: 20/100 (20.0%)\n",
            "\n",
            "==== Training Baseline Model with Standard Cross-Entropy Loss ====\n",
            "Epoch  1 | Train: 12.95% | Val: 40.14%\n",
            "Epoch  2 | Train: 57.92% | Val: 68.03%\n",
            "Epoch  3 | Train: 79.22% | Val: 71.43%\n",
            "Epoch  4 | Train: 86.54% | Val: 78.91%\n",
            "Epoch  5 | Train: 90.97% | Val: 78.91%\n",
            "Epoch  6 | Train: 92.84% | Val: 81.63%\n",
            "Epoch  7 | Train: 96.25% | Val: 82.31%\n",
            "Epoch  8 | Train: 97.10% | Val: 83.67%\n",
            "Epoch  9 | Train: 98.30% | Val: 82.31%\n",
            "Epoch 10 | Train: 97.96% | Val: 84.35%\n",
            "Test Accuracy: 8.18%\n",
            "⮞ Baseline (last 5 layers) Test Acc: 8.18%\n",
            "\n",
            "==== Analysis of Impact on Classes with Limited Data ====\n",
            "Correlation between class sample count and accuracy: 0.0748\n",
            "\n",
            "Average accuracy across all classes: 8.31%\n",
            "\n",
            "==== Training with Weighted Cross-Entropy Loss ====\n",
            "Class weights:\n",
            "Abyssinian: 1.2056 (samples: 13)\n",
            "Bengal: 0.9219 (samples: 17)\n",
            "Birman: 0.9219 (samples: 17)\n",
            "Bombay: 0.9796 (samples: 16)\n",
            "British_Shorthair: 0.9219 (samples: 17)\n",
            "Egyptian_Mau: 1.1195 (samples: 14)\n",
            "Maine_Coon: 0.9796 (samples: 16)\n",
            "Persian: 0.8707 (samples: 18)\n",
            "Ragdoll: 1.1195 (samples: 14)\n",
            "Russian_Blue: 0.8249 (samples: 19)\n",
            "Siamese: 0.9796 (samples: 16)\n",
            "Sphynx: 0.9796 (samples: 16)\n",
            "american_bulldog: 1.2056 (samples: 13)\n",
            "american_pit_bull_terrier: 0.7836 (samples: 20)\n",
            "basset_hound: 0.8707 (samples: 18)\n",
            "beagle: 0.9796 (samples: 16)\n",
            "boxer: 1.2056 (samples: 13)\n",
            "chihuahua: 1.0449 (samples: 15)\n",
            "english_cocker_spaniel: 0.9219 (samples: 17)\n",
            "english_setter: 1.0449 (samples: 15)\n",
            "german_shorthaired: 0.9796 (samples: 16)\n",
            "great_pyrenees: 0.8707 (samples: 18)\n",
            "havanese: 0.9219 (samples: 17)\n",
            "japanese_chin: 0.9219 (samples: 17)\n",
            "keeshond: 0.9219 (samples: 17)\n",
            "leonberger: 1.2056 (samples: 13)\n",
            "miniature_pinscher: 1.0449 (samples: 15)\n",
            "newfoundland: 0.9219 (samples: 17)\n",
            "pomeranian: 1.0449 (samples: 15)\n",
            "pug: 1.0449 (samples: 15)\n",
            "saint_bernard: 0.9219 (samples: 17)\n",
            "samoyed: 1.0449 (samples: 15)\n",
            "scottish_terrier: 1.1195 (samples: 14)\n",
            "shiba_inu: 1.0449 (samples: 15)\n",
            "staffordshire_bull_terrier: 0.8707 (samples: 18)\n",
            "wheaten_terrier: 1.1195 (samples: 14)\n",
            "yorkshire_terrier: 1.1195 (samples: 14)\n",
            "Epoch  1 | Train: 48.55% | Val: 61.22%\n",
            "Epoch  2 | Train: 94.55% | Val: 74.15%\n",
            "Epoch  3 | Train: 99.15% | Val: 76.19%\n",
            "Epoch  4 | Train: 100.00% | Val: 77.55%\n",
            "Epoch  5 | Train: 100.00% | Val: 76.87%\n",
            "Epoch  6 | Train: 100.00% | Val: 81.63%\n",
            "Epoch  7 | Train: 100.00% | Val: 80.95%\n",
            "Epoch  8 | Train: 100.00% | Val: 78.23%\n",
            "Epoch  9 | Train: 100.00% | Val: 78.91%\n",
            "Epoch 10 | Train: 100.00% | Val: 76.87%\n",
            "Test Accuracy: 8.39%\n",
            "⮞ Weighted CE (last 5 layers) Test Acc: 8.39%\n",
            "\n",
            "Per-class accuracy changes (Weighted CE vs Baseline):\n",
            "Abyssinian: 54.08% → 55.10% (+1.02%)\n",
            "Bengal: 0.00% → 0.00% (+0.00%)\n",
            "Birman: 0.00% → 0.00% (+0.00%)\n",
            "Bombay: 0.00% → 0.00% (+0.00%)\n",
            "British_Shorthair: 0.00% → 0.00% (+0.00%)\n",
            "Egyptian_Mau: 11.00% → 18.00% (+7.00%)\n",
            "Maine_Coon: 1.00% → 0.00% (-1.00%)\n",
            "Persian: 0.00% → 0.00% (+0.00%)\n",
            "Ragdoll: 0.00% → 0.00% (+0.00%)\n",
            "Russian_Blue: 10.00% → 18.00% (+8.00%)\n",
            "Siamese: 1.00% → 0.00% (-1.00%)\n",
            "Sphynx: 0.00% → 0.00% (+0.00%)\n",
            "american_bulldog: 0.00% → 0.00% (+0.00%)\n",
            "american_pit_bull_terrier: 0.00% → 0.00% (+0.00%)\n",
            "basset_hound: 0.00% → 0.00% (+0.00%)\n",
            "beagle: 0.00% → 0.00% (+0.00%)\n",
            "boxer: 0.00% → 0.00% (+0.00%)\n",
            "chihuahua: 0.00% → 0.00% (+0.00%)\n",
            "english_cocker_spaniel: 0.00% → 0.00% (+0.00%)\n",
            "english_setter: 1.00% → 0.00% (-1.00%)\n",
            "german_shorthaired: 0.00% → 0.00% (+0.00%)\n",
            "great_pyrenees: 0.00% → 0.00% (+0.00%)\n",
            "havanese: 0.00% → 0.00% (+0.00%)\n",
            "japanese_chin: 0.00% → 0.00% (+0.00%)\n",
            "keeshond: 0.00% → 0.00% (+0.00%)\n",
            "leonberger: 0.00% → 0.00% (+0.00%)\n",
            "miniature_pinscher: 0.00% → 0.00% (+0.00%)\n",
            "newfoundland: 0.00% → 0.00% (+0.00%)\n",
            "pomeranian: 0.00% → 0.00% (+0.00%)\n",
            "pug: 0.00% → 0.00% (+0.00%)\n",
            "saint_bernard: 0.00% → 0.00% (+0.00%)\n",
            "samoyed: 2.00% → 2.00% (+0.00%)\n",
            "scottish_terrier: 0.00% → 0.00% (+0.00%)\n",
            "shiba_inu: 0.00% → 0.00% (+0.00%)\n",
            "staffordshire_bull_terrier: 58.43% → 57.30% (-1.12%)\n",
            "wheaten_terrier: 79.00% → 77.00% (-2.00%)\n",
            "yorkshire_terrier: 90.00% → 88.00% (-2.00%)\n",
            "\n",
            "==== Training with Oversampling of Minority Classes ====\n",
            "Epoch  1 | Train: 88.16% | Val: 29.25%\n",
            "Epoch  2 | Train: 99.23% | Val: 30.61%\n",
            "Epoch  3 | Train: 100.00% | Val: 31.97%\n",
            "Epoch  4 | Train: 100.00% | Val: 31.29%\n",
            "Epoch  5 | Train: 100.00% | Val: 31.29%\n",
            "Epoch  6 | Train: 100.00% | Val: 31.29%\n",
            "Epoch  7 | Train: 100.00% | Val: 31.29%\n",
            "Epoch  8 | Train: 100.00% | Val: 30.61%\n",
            "Epoch  9 | Train: 100.00% | Val: 31.29%\n",
            "Epoch 10 | Train: 100.00% | Val: 31.29%\n",
            "Test Accuracy: 3.11%\n",
            "⮞ Oversampling (last 5 layers) Test Acc: 3.11%\n",
            "\n",
            "Per-class accuracy changes (Oversampling vs Baseline):\n",
            "Abyssinian: 54.08% → 86.73% (+32.65%)\n",
            "Bengal: 0.00% → 0.00% (+0.00%)\n",
            "Birman: 0.00% → 0.00% (+0.00%)\n",
            "Bombay: 0.00% → 0.00% (+0.00%)\n",
            "British_Shorthair: 0.00% → 0.00% (+0.00%)\n",
            "Egyptian_Mau: 11.00% → 3.00% (-8.00%)\n",
            "Maine_Coon: 1.00% → 0.00% (-1.00%)\n",
            "Persian: 0.00% → 0.00% (+0.00%)\n",
            "Ragdoll: 0.00% → 0.00% (+0.00%)\n",
            "Russian_Blue: 10.00% → 0.00% (-10.00%)\n",
            "Siamese: 1.00% → 0.00% (-1.00%)\n",
            "Sphynx: 0.00% → 0.00% (+0.00%)\n",
            "american_bulldog: 0.00% → 2.00% (+2.00%)\n",
            "american_pit_bull_terrier: 0.00% → 3.00% (+3.00%)\n",
            "basset_hound: 0.00% → 14.00% (+14.00%)\n",
            "beagle: 0.00% → 5.00% (+5.00%)\n",
            "boxer: 0.00% → 0.00% (+0.00%)\n",
            "chihuahua: 0.00% → 2.00% (+2.00%)\n",
            "english_cocker_spaniel: 0.00% → 0.00% (+0.00%)\n",
            "english_setter: 1.00% → 0.00% (-1.00%)\n",
            "german_shorthaired: 0.00% → 0.00% (+0.00%)\n",
            "great_pyrenees: 0.00% → 0.00% (+0.00%)\n",
            "havanese: 0.00% → 0.00% (+0.00%)\n",
            "japanese_chin: 0.00% → 0.00% (+0.00%)\n",
            "keeshond: 0.00% → 0.00% (+0.00%)\n",
            "leonberger: 0.00% → 0.00% (+0.00%)\n",
            "miniature_pinscher: 0.00% → 0.00% (+0.00%)\n",
            "newfoundland: 0.00% → 0.00% (+0.00%)\n",
            "pomeranian: 0.00% → 0.00% (+0.00%)\n",
            "pug: 0.00% → 0.00% (+0.00%)\n",
            "saint_bernard: 0.00% → 0.00% (+0.00%)\n",
            "samoyed: 2.00% → 0.00% (-2.00%)\n",
            "scottish_terrier: 0.00% → 0.00% (+0.00%)\n",
            "shiba_inu: 0.00% → 0.00% (+0.00%)\n",
            "staffordshire_bull_terrier: 58.43% → 0.00% (-58.43%)\n",
            "wheaten_terrier: 79.00% → 0.00% (-79.00%)\n",
            "yorkshire_terrier: 90.00% → 0.00% (-90.00%)\n",
            "\n",
            "==== Overall Comparison of Approaches ====\n",
            "Baseline Test Accuracy: 90.00%\n",
            "Weighted CE Test Accuracy: 88.00%\n",
            "Oversampling Test Accuracy: 0.00%\n",
            "\n",
            "Average per-class improvement with Weighted CE: 0.21%\n",
            "Average per-class improvement with Oversampling: -5.18%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        "    SubsetRandomSampler,\n",
        "    WeightedRandomSampler\n",
        ")\n",
        "\n",
        "# --- Ensure device is defined ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load trainval metadata\n",
        "tmp_train = OxfordIIITPet(root=\"data\", split=\"trainval\", target_types=\"category\", download=True)\n",
        "# Extract image stems: e.g. \"Abyssinian_1\"\n",
        "names = [p.stem for p in tmp_train._images]\n",
        "\n",
        "# Build mapping from stem → breed_name\n",
        "breeds_map = {n: n.rsplit(\"_\", 1)[0] for n in names}\n",
        "breed_names = sorted(set(breeds_map.values()))   # 37 unique breed strings\n",
        "breed_to_id = {b: i for i, b in enumerate(breed_names)}\n",
        "\n",
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nm = self.names[idx]\n",
        "        img_path = os.path.join(self.root, \"oxford-iiit-pet\", \"images\", nm + \".jpg\")\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[nm]]\n",
        "        return img, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "root = \"data\"\n",
        "# Full train/val dataset\n",
        "full_dataset = MultiClassPet(root, names, breeds_map, transform=transform)\n",
        "\n",
        "# Build 20%-per-class imbalanced index list\n",
        "class_idxs = defaultdict(list)\n",
        "for idx, nm in enumerate(names):\n",
        "    lbl = breed_to_id[breeds_map[nm]]\n",
        "    class_idxs[lbl].append(idx)\n",
        "\n",
        "# Create an artificially imbalanced dataset with some breeds at 20%\n",
        "imbalanced = []\n",
        "class_percentages = {}  # To track how many samples are used from each class\n",
        "\n",
        "for lbl, idxs in class_idxs.items():\n",
        "    # Use 20% of data for each breed\n",
        "    k = max(1, int(0.2 * len(idxs)))\n",
        "    selected_idxs = random.sample(idxs, k)\n",
        "    imbalanced += selected_idxs\n",
        "    class_percentages[breed_names[lbl]] = (k, len(idxs), k/len(idxs)*100)\n",
        "\n",
        "# Print dataset stats\n",
        "print(f\"Total samples in imbalanced dataset: {len(imbalanced)}\")\n",
        "print(\"Class distribution (samples, total, percentage):\")\n",
        "for breed, (count, total, percentage) in sorted(class_percentages.items()):\n",
        "    print(f\"{breed}: {count}/{total} ({percentage:.1f}%)\")\n",
        "\n",
        "# Split imbalanced list into train/val (80/20)\n",
        "random.shuffle(imbalanced)\n",
        "split = int(0.8 * len(imbalanced))\n",
        "train_idxs = imbalanced[:split]\n",
        "val_idxs = imbalanced[split:]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Test loader via torchvision to avoid missing stems\n",
        "test_ds = OxfordIIITPet(\n",
        "    root=root,\n",
        "    split=\"test\",\n",
        "    target_types=\"category\",\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define the NeuralNetwork class for training and evaluation\n",
        "def make_model(unfreeze_layers=5):\n",
        "    \"\"\"\n",
        "    Returns a NeuralNetwork instance fine-tuned on the\n",
        "    imbalanced train_loader/val_loader/test_loader.\n",
        "    \"\"\"\n",
        "    basemodel = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    m = NeuralNetwork(\n",
        "        basemodel,\n",
        "        len(breed_names),\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        unfreeze=unfreeze_layers\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# Train baseline model with normal cross-entropy loss\n",
        "print(\"\\n==== Training Baseline Model with Standard Cross-Entropy Loss ====\")\n",
        "model_base = make_model(unfreeze_layers=5)\n",
        "base_acc = model_base.train(epochs=10)\n",
        "print(f\"⮞ Baseline (last 5 layers) Test Acc: {base_acc:.2f}%\")\n",
        "\n",
        "# Analyze the results - impact on the classes with limited data\n",
        "print(\"\\n==== Analysis of Impact on Classes with Limited Data ====\")\n",
        "test_acc, per_class_acc, class_counts = model_base.evaluate()\n",
        "baseline_per_class_acc = per_class_acc.copy()  # Store for comparison\n",
        "\n",
        "# Calculate correlation between class sample counts and accuracy\n",
        "class_samples = [class_percentages[breed][0] for breed in breed_names]\n",
        "correlation = np.corrcoef(class_samples, per_class_acc)[0, 1]\n",
        "print(f\"Correlation between class sample count and accuracy: {correlation:.4f}\")\n",
        "\n",
        "# Compare accuracy of classes with fewer samples vs classes with more samples\n",
        "# (Since all classes are at 20%, this might not show significant differences)\n",
        "print(\"\\nAverage accuracy across all classes: {:.2f}%\".format(sum(per_class_acc) / len(per_class_acc)))\n",
        "\n",
        "# ===== WEIGHTED CROSS-ENTROPY APPROACH =====\n",
        "print(\"\\n==== Training with Weighted Cross-Entropy Loss ====\")\n",
        "\n",
        "# Compute class weights inversely proportional to class frequencies\n",
        "# First, count samples per class in training set\n",
        "per_labels = [breed_to_id[breeds_map[names[i]]] for i in train_idxs]\n",
        "class_counts = torch.tensor([per_labels.count(c) for c in range(len(breed_names))], dtype=torch.float)\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * len(class_counts)  # Normalize\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "print(\"Class weights:\")\n",
        "for i, (breed, weight) in enumerate(zip(breed_names, class_weights.cpu().numpy())):\n",
        "    samples = per_labels.count(i)\n",
        "    print(f\"{breed}: {weight:.4f} (samples: {samples})\")\n",
        "\n",
        "# Train with weighted cross-entropy\n",
        "model_w = make_model(unfreeze_layers=5)\n",
        "model_w.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "model_w.optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_w.model.parameters()),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "w_acc = model_w.train(epochs=10)\n",
        "print(f\"⮞ Weighted CE (last 5 layers) Test Acc: {w_acc:.2f}%\")\n",
        "\n",
        "# Analyze per-class improvements\n",
        "_, w_per_class_acc, _ = model_w.evaluate()\n",
        "print(\"\\nPer-class accuracy changes (Weighted CE vs Baseline):\")\n",
        "for i, (breed, base_acc, w_acc) in enumerate(zip(breed_names, baseline_per_class_acc, w_per_class_acc)):\n",
        "    diff = w_acc - base_acc\n",
        "    print(f\"{breed}: {base_acc:.2f}% → {w_acc:.2f}% ({diff:+.2f}%)\")\n",
        "\n",
        "# ===== OVERSAMPLING APPROACH =====\n",
        "print(\"\\n==== Training with Oversampling of Minority Classes ====\")\n",
        "\n",
        "# Implement weighted random sampling to oversample minority classes\n",
        "sample_weights = [1.0 / class_counts[per_labels[i]].item() for i in range(len(train_idxs))]\n",
        "oversampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights) * 2, replacement=True)\n",
        "\n",
        "# Create a new dataloader with oversampling\n",
        "oversampled_train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=oversampler,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Train with oversampling\n",
        "model_o = make_model(unfreeze_layers=5)\n",
        "model_o.train_loader = oversampled_train_loader\n",
        "model_o.optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_o.model.parameters()),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "o_acc = model_o.train(epochs=10)\n",
        "print(f\"⮞ Oversampling (last 5 layers) Test Acc: {o_acc:.2f}%\")\n",
        "\n",
        "# Analyze per-class improvements\n",
        "_, o_per_class_acc, _ = model_o.evaluate()\n",
        "print(\"\\nPer-class accuracy changes (Oversampling vs Baseline):\")\n",
        "for i, (breed, base_acc, o_acc) in enumerate(zip(breed_names, baseline_per_class_acc, o_per_class_acc)):\n",
        "    diff = o_acc - base_acc\n",
        "    print(f\"{breed}: {base_acc:.2f}% → {o_acc:.2f}% ({diff:+.2f}%)\")\n",
        "\n",
        "# ===== COMPARE ALL APPROACHES =====\n",
        "print(\"\\n==== Overall Comparison of Approaches ====\")\n",
        "print(f\"Baseline Test Accuracy: {base_acc:.2f}%\")\n",
        "print(f\"Weighted CE Test Accuracy: {w_acc:.2f}%\")\n",
        "print(f\"Oversampling Test Accuracy: {o_acc:.2f}%\")\n",
        "\n",
        "# Plot comparison of per-class accuracies across methods\n",
        "plt.figure(figsize=(15, 10))\n",
        "x = np.arange(len(breed_names))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, baseline_per_class_acc, width, label='Baseline')\n",
        "plt.bar(x, w_per_class_acc, width, label='Weighted CE')\n",
        "plt.bar(x + width, o_per_class_acc, width, label='Oversampling')\n",
        "\n",
        "plt.xlabel('Breed')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Per-class Accuracy Comparison Across Methods')\n",
        "plt.xticks(x, breed_names, rotation=90)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('comparison_per_class.png')\n",
        "plt.close()\n",
        "\n",
        "# Calculate average improvement across all classes\n",
        "w_avg_improvement = sum(w - b for w, b in zip(w_per_class_acc, baseline_per_class_acc)) / len(breed_names)\n",
        "o_avg_improvement = sum(o - b for o, b in zip(o_per_class_acc, baseline_per_class_acc)) / len(breed_names)\n",
        "\n",
        "print(f\"\\nAverage per-class improvement with Weighted CE: {w_avg_improvement:.2f}%\")\n",
        "print(f\"Average per-class improvement with Oversampling: {o_avg_improvement:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}