{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b501857-78ba-481b-ab7a-3f5b4bc144a4",
      "metadata": {
        "id": "5b501857-78ba-481b-ab7a-3f5b4bc144a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.datasets import OxfordIIITPet, Flowers102\n",
        "import scipy\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a73f1dd-2fc0-45cb-a11c-1c0cc532a9a0",
      "metadata": {
        "id": "3a73f1dd-2fc0-45cb-a11c-1c0cc532a9a0"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b801c40-5114-4193-8892-16c62225204f",
      "metadata": {
        "id": "5b801c40-5114-4193-8892-16c62225204f"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self, basemodel, output, train_loader, val_loader, test_loader, unfreeze=0, parameters=None):\n",
        "        # Init model\n",
        "        self.model = copy.deepcopy(basemodel)\n",
        "        # changing the fully connected layer\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, output)\n",
        "        # Unfreeze the L last layers and fully connected last layer\n",
        "        self.unfreeze_layers(unfreeze)\n",
        "        self.model = self.model.to(device)\n",
        "\n",
        "        self.optimizer = optim.Adam([{\"params\": self.model.fc.parameters(),\"lr\": 1e-3, \"weight_decay\": 1e-4},])\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        self.parameters = parameters if parameters is not None else {}\n",
        "\n",
        "\n",
        "    def unfreeze_layers(self, L):\n",
        "      # freezing all layers\n",
        "      for p in self.model.parameters():\n",
        "          p.requires_grad = False\n",
        "\n",
        "      layer = 0\n",
        "      # unfreeze last L layers and fully connected layer\n",
        "      for name, p in reversed(list(self.model.named_parameters())):\n",
        "        if layer < L+1:\n",
        "          if not name.endswith(\"bias\"):\n",
        "            layer += 1\n",
        "          p.requires_grad = True\n",
        "\n",
        "    def check_trainable_layers(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(f\"{name} requires grad\")\n",
        "            else:\n",
        "                print(f\"{name} does NOT require grad\")\n",
        "\n",
        "\n",
        "    def run_epoch(self, loader, train=True):\n",
        "        self.model.train() if train else self.model.eval()\n",
        "        total_loss, correct, total = 0.0, 0, 0\n",
        "        for imgs, labs in loader:\n",
        "            imgs, labs = imgs.to(device), labs.to(device)\n",
        "            if train:\n",
        "                self.optimizer.zero_grad()\n",
        "            logits = self.model(imgs)\n",
        "            loss   = self.criterion(logits, labs)\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds      = logits.argmax(dim=1)\n",
        "            correct   += (preds == labs).sum().item()\n",
        "            total     += imgs.size(0)\n",
        "        return total_loss/total, correct/total*100\n",
        "\n",
        "\n",
        "    def test_model(self, test_loader=None):\n",
        "      if test_loader != None:\n",
        "        loader = test_loader\n",
        "      else:\n",
        "        loader = self.test_loader\n",
        "\n",
        "      test_loss, test_acc = self.run_epoch(loader, train=False)\n",
        "      print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "      return test_acc\n",
        "\n",
        "    def train(self, epochs, path=\"model.pth\"):\n",
        "      best_val_acc = 0.0\n",
        "      for epoch in range(1,epochs+1):\n",
        "\n",
        "        # gradually unfreeze layers for strategy 2 according to rate parameter\n",
        "        if 'gradual_unfreezing' in self.parameters:\n",
        "            uf_rate = 1 if not 'unfreezing_rate' in self.parameters else parameters['unfreezing_rate']\n",
        "            L = np.floor(uf_rate*(1+epoch)) # allow for rates < 1\n",
        "            if L < 1:\n",
        "                L = 1\n",
        "            self.unfreeze_layers(L)\n",
        "\n",
        "        tr_loss, tr_acc = self.run_epoch(self.train_loader, train=True)\n",
        "        val_loss, val_acc = self.run_epoch(self.val_loader, train=False)\n",
        "        print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(self.model.state_dict(), path)\n",
        "\n",
        "      test_acc = self.test_model()\n",
        "      return test_acc\n",
        "\n",
        "    def train2(self, epochs, path=\"model.pth\", tee = False, test_loader=None): # tee=test_eac_epoch\n",
        "        best_val_acc = 0.0\n",
        "        for epoch in range(1, epochs+1):\n",
        "            # Gradual unfreezing\n",
        "            if self.parameters.get('gradual_unfreezing', False):\n",
        "                uf_rate = self.parameters.get('unfreezing_rate', 1)\n",
        "                L = int(np.floor(uf_rate * (epoch + 1)))\n",
        "                if L < 1:\n",
        "                    L = 1\n",
        "                self.unfreeze_layers(L)\n",
        "\n",
        "            tr_loss, tr_acc = self.run_epoch(self.train_loader, train=True)\n",
        "            val_loss, val_acc = self.run_epoch(self.val_loader, train=False)\n",
        "            print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "\n",
        "            # Save best\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(self.model.state_dict(), path)\n",
        "\n",
        "            # Step scheduler if present\n",
        "            if hasattr(self, 'scheduler') and self.scheduler is not None:\n",
        "                self.scheduler.step()\n",
        "\n",
        "        return self.test_model()\n",
        "\n",
        "    def train_catastrophic(self, epochs, path=\"model.pth\", tee = True, test_loader=None): # tee=test_eac_epoch\n",
        "        best_val_acc = 0.0\n",
        "        results = {\"primary\": [], \"secondary\":[]}\n",
        "        for epoch in range(1, epochs+1):\n",
        "            # Gradual unfreezing\n",
        "            if self.parameters.get('gradual_unfreezing', False):\n",
        "                uf_rate = self.parameters.get('unfreezing_rate', 1)\n",
        "                L = int(np.floor(uf_rate * (epoch + 1)))\n",
        "                if L < 1:\n",
        "                    L = 1\n",
        "                self.unfreeze_layers(L)\n",
        "\n",
        "            tr_loss, tr_acc = self.run_epoch(self.train_loader, train=True)\n",
        "            val_loss, val_acc = self.run_epoch(self.val_loader, train=False)\n",
        "            print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "\n",
        "            # Save best\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(self.model.state_dict(), path)\n",
        "\n",
        "            if tee:\n",
        "                results[\"primary\"].append(self.test_model())\n",
        "                if test_loader != None:\n",
        "                    results[\"secondary\"].append(self.test_model(test_loader = test_loader))\n",
        "            # Step scheduler if present\n",
        "            if hasattr(self, 'scheduler') and self.scheduler is not None:\n",
        "                self.scheduler.step()\n",
        "        if not tee:\n",
        "            return self.test_model()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Track per-class accuracy\n",
        "        class_correct = [0] * len(breed_names)\n",
        "        class_total = [0] * len(breed_names)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in self.test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                # Overall accuracy\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                for i in range(len(targets)):\n",
        "                    label = targets[i].item()\n",
        "                    class_total[label] += 1\n",
        "                    if predicted[i] == targets[i]:\n",
        "                        class_correct[label] += 1\n",
        "\n",
        "        overall_acc = 100.0 * correct / total\n",
        "        per_class_acc = [(100.0 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0.0)\n",
        "                          for i in range(len(breed_names))]\n",
        "\n",
        "        return overall_acc, per_class_acc, class_total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7479cf3f-4699-4cb4-ab82-010e8ddb2635",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7479cf3f-4699-4cb4-ab82-010e8ddb2635",
        "outputId": "ce5103f6-1726-4e2b-8b8f-8ed26622f104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:34<00:00, 22.9MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 11.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset OxfordIIITPet\n",
              "    Number of datapoints: 3680\n",
              "    Root location: data"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "OxfordIIITPet(root=\"data\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d431898-55ce-49dc-91f9-7dceed1fec13",
      "metadata": {
        "id": "6d431898-55ce-49dc-91f9-7dceed1fec13"
      },
      "outputs": [],
      "source": [
        "annnotations_dir = os.path.join(\"data\", \"oxford-iiit-pet\", \"annotations\")\n",
        "lines_for_files = open(os.path.join(annnotations_dir, \"list.txt\")).read().splitlines()[6:]\n",
        "species_map = {l.split()[0]: int(l.split()[2]) for l in lines_for_files}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c852e4-7055-4c82-97c9-3e99e736d052",
      "metadata": {
        "id": "66c852e4-7055-4c82-97c9-3e99e736d052"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(annnotations_dir, \"trainval.txt\")) as f:\n",
        "    trainval_names = [l.split()[0] for l in f if l.strip()]\n",
        "with open(os.path.join(annnotations_dir, \"test.txt\")) as f:\n",
        "    test_names = [l.split()[0] for l in f if l.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145827fc-38aa-4e39-8049-e5640ed7cbe0",
      "metadata": {
        "id": "145827fc-38aa-4e39-8049-e5640ed7cbe0"
      },
      "outputs": [],
      "source": [
        "class BinaryPet(Dataset):\n",
        "    def __init__(self, root, names, species_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.species_map = species_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        img_path = os.path.join(\n",
        "            self.root, \"oxford-iiit-pet\", \"images\", name + \".jpg\"\n",
        "        )\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.species_map[name] - 1  # 1→cat→0, 2→dog→1\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c36d1a7d-78bc-4a58-88fa-d26a037d9f99",
      "metadata": {
        "id": "c36d1a7d-78bc-4a58-88fa-d26a037d9f99"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2832243b-6442-4bc5-9926-f690647a5658",
      "metadata": {
        "id": "2832243b-6442-4bc5-9926-f690647a5658"
      },
      "outputs": [],
      "source": [
        "transformIMG = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036a6c76-bc3b-44b8-acf1-50893a352c62",
      "metadata": {
        "id": "036a6c76-bc3b-44b8-acf1-50893a352c62"
      },
      "outputs": [],
      "source": [
        "full = BinaryPet(\"data\", trainval_names, species_map, transform=transformIMG)\n",
        "n_val = int(0.1 * len(full))\n",
        "train_ds, val_ds = random_split(full, [len(full)-n_val, n_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a8eecd-7f70-4223-9218-6023fff72e3d",
      "metadata": {
        "id": "55a8eecd-7f70-4223-9218-6023fff72e3d"
      },
      "outputs": [],
      "source": [
        "test_ds = BinaryPet(\"data\", test_names, species_map, transform=transformIMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2e5899-3a81-461a-bd4a-b1a5c850cb8a",
      "metadata": {
        "id": "6d2e5899-3a81-461a-bd4a-b1a5c850cb8a"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0260f07f-a459-4d27-9f5d-bb6c1eee575f",
      "metadata": {
        "id": "0260f07f-a459-4d27-9f5d-bb6c1eee575f"
      },
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0460ecda-9f16-4270-b7e8-a988442797c5",
      "metadata": {
        "id": "0460ecda-9f16-4270-b7e8-a988442797c5"
      },
      "source": [
        "## Model Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed618ac-37af-464d-a735-3223b0dbc071",
      "metadata": {
        "id": "7ed618ac-37af-464d-a735-3223b0dbc071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67a990c-8f64-4f46-b6db-f5fe5c6f229d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 149MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "# freezing all\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "# changing the fully connected layer\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "# Unfreeze the fully connected last layer\n",
        "for name, p in model.named_parameters():\n",
        "    if name.startswith(\"fc\"):\n",
        "        p.requires_grad = True\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c32651b9-0f2c-4736-b3db-10fbb6486f70",
      "metadata": {
        "id": "c32651b9-0f2c-4736-b3db-10fbb6486f70"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55100d27-1851-43fb-8039-3d1cd7ab6b6c",
      "metadata": {
        "id": "55100d27-1851-43fb-8039-3d1cd7ab6b6c"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam([\n",
        "    {\"params\": model.fc.parameters(),     \"lr\": 1e-3, \"weight_decay\": 1e-4},\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "428edba5-4df2-4d37-9f61-18da01050f30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "428edba5-4df2-4d37-9f61-18da01050f30",
        "outputId": "7fbd22ce-f66e-42c2-bcd4-693936c16961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d1cdba-bc33-42a1-8f75-3dd5de75288e",
      "metadata": {
        "id": "f0d1cdba-bc33-42a1-8f75-3dd5de75288e"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1dcabae-3911-4cd2-96ac-52e4c0158183",
      "metadata": {
        "id": "d1dcabae-3911-4cd2-96ac-52e4c0158183"
      },
      "outputs": [],
      "source": [
        "def run_epoch(model, loader, train=True, criterion=criterion, optimizer=optimizer): # TODO: Include criterion and optimizer in a neater way\n",
        "    model.train() if train else model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    for imgs, labs in loader:\n",
        "        imgs, labs = imgs.to(device), labs.to(device)\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss   = criterion(logits, labs)\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        preds      = logits.argmax(dim=1)\n",
        "        correct   += (preds == labs).sum().item()\n",
        "        total     += imgs.size(0)\n",
        "    return total_loss/total, correct/total*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e5a381-42b4-4676-8d65-1d1a7e8bebc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30e5a381-42b4-4676-8d65-1d1a7e8bebc7",
        "outputId": "22c5b5eb-ff84-4a2d-f23a-e4d8e586a618"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/youngbinpyo/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'BinaryPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m best_val_acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m25\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     tr_loss, tr_acc \u001b[39m=\u001b[39m run_epoch(model, train_loader, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m run_epoch(model, val_loader, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m2d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Train: \u001b[39m\u001b[39m{\u001b[39;00mtr_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% | Val: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(model, loader, train, criterion, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mtrain() \u001b[39mif\u001b[39;00m train \u001b[39melse\u001b[39;00m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m total_loss, correct, total \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m imgs, labs \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m      5\u001b[0m     imgs, labs \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(device), labs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m train:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:493\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    492\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_iterator()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:424\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 424\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1171\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1164\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1171\u001b[0m w\u001b[39m.\u001b[39mstart()\n\u001b[1;32m   1172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Popen(\u001b[39mself\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39mget_context()\u001b[39m.\u001b[39mProcess\u001b[39m.\u001b[39m_Popen(process_obj)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/context.py:289\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    288\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(process_obj)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_launch(process_obj)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39mwrite(fp\u001b[39m.\u001b[39mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_val_acc = 0.0\n",
        "for epoch in range(1, 25):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc = run_epoch(model, val_loader, train=False)\n",
        "    print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_binary_resnet34.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32b86600-f7a0-4cc0-afb1-3e954c369c90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32b86600-f7a0-4cc0-afb1-3e954c369c90",
        "outputId": "f6752014-bd4b-4e6c-e54e-88b08ee65910"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best_binary_resnet34.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mbest_binary_resnet34.pth\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m run_epoch(model, test_loader, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _opener[IO[\u001b[39mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    760\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike[\u001b[39mstr\u001b[39m]], mode: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39m(name, mode))\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_binary_resnet34.pth'"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_binary_resnet34.pth\"))\n",
        "test_loss, test_acc = run_epoch(model, test_loader, train=False)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d5105c-c2ad-4f6c-9691-8a633635463e",
      "metadata": {
        "id": "96d5105c-c2ad-4f6c-9691-8a633635463e"
      },
      "source": [
        "# Multi Class Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a105be8d-b6d6-469d-a4df-4b5b02ef6bc8",
      "metadata": {
        "id": "a105be8d-b6d6-469d-a4df-4b5b02ef6bc8"
      },
      "source": [
        "TODO:\n",
        "* different learning rates/learning rate schedulers for different layers\n",
        "* data augmentation\n",
        "* Effect of fine-tuning batch-norm parameters\n",
        "* Train with Imbalanced Dataset\n",
        "* Testing and logging of the above\n",
        "* gradual_unfreezing testing\n",
        "* unfreezing l layers at a time testing\n",
        "  \n",
        "DONE:\n",
        "* gradual_unfreezing\n",
        "* unfreezing l layers at a time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60b2b63a-6c41-4a5b-b02d-f978f488fc29",
      "metadata": {
        "id": "60b2b63a-6c41-4a5b-b02d-f978f488fc29"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cef39a61-b139-4313-8f38-abdd1179c503",
      "metadata": {
        "id": "cef39a61-b139-4313-8f38-abdd1179c503"
      },
      "outputs": [],
      "source": [
        "annnotations_dir = os.path.join(\"data\", \"oxford-iiit-pet\", \"annotations\")\n",
        "lines_for_files = open(os.path.join(annnotations_dir, \"list.txt\")).read().splitlines()[6:]\n",
        "breeds_map = {l.split()[0]:re.split(r'_\\d+', l.split()[0])[0] for l in lines_for_files}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "899dfeff-7a12-4688-8387-0c1f366ee339",
      "metadata": {
        "id": "899dfeff-7a12-4688-8387-0c1f366ee339"
      },
      "outputs": [],
      "source": [
        "breed_to_id = {val: i for i, val in enumerate(sorted(set(breeds_map.values())))}\n",
        "id_to_breed = {v: k for k, v in breed_to_id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eebff8d5-3e15-4157-a97d-4ba02ee3c76a",
      "metadata": {
        "id": "eebff8d5-3e15-4157-a97d-4ba02ee3c76a"
      },
      "outputs": [],
      "source": [
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        img_path = os.path.join(\n",
        "            self.root, \"oxford-iiit-pet\", \"images\", name + \".jpg\"\n",
        "        )\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[name]]\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7ff718-7080-4814-8bbd-ff42a8f04f85",
      "metadata": {
        "id": "1c7ff718-7080-4814-8bbd-ff42a8f04f85"
      },
      "outputs": [],
      "source": [
        "full = MultiClassPet(\"data\", trainval_names, breeds_map, transform=transformIMG)\n",
        "n_val = int(0.1 * len(full))\n",
        "train_ds, val_ds = random_split(full, [len(full)-n_val, n_val])\n",
        "test_ds = MultiClassPet(\"data\", test_names, breeds_map, transform=transformIMG)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D9ksAjJGLB19"
      },
      "id": "D9ksAjJGLB19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3de2fcd-22e5-4c98-8cb4-0bc40dd99953",
      "metadata": {
        "id": "f3de2fcd-22e5-4c98-8cb4-0bc40dd99953"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb96530-c12c-44f0-ac11-a2c554314e5d",
      "metadata": {
        "id": "2fb96530-c12c-44f0-ac11-a2c554314e5d"
      },
      "source": [
        "## Model Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b159b267-e687-41fc-b7f9-066b5d96848c",
      "metadata": {
        "id": "b159b267-e687-41fc-b7f9-066b5d96848c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2358cfdb-aeea-44bb-bc52-875a8491d56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 193MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27d260d-a15a-4003-b0f2-a2ecbc50297b",
      "metadata": {
        "id": "d27d260d-a15a-4003-b0f2-a2ecbc50297b"
      },
      "source": [
        "-> Strategy 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WJbuKDtJaKgA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "WJbuKDtJaKgA",
        "outputId": "78bd2be5-1d65-4f42-89f6-f215f6065eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training model with 1 last layers trainable\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-7171e1885a2e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Start training model with {L} last layers trainable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodelmulti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasemodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelmulti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-bcdd57301589>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, path)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-bcdd57301589>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, loader, train)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Strategy 1: train with l layers unfrozen simultaneously\n",
        "accs = []\n",
        "for L in range(1, 10):\n",
        "  print(f\"Start training model with {L} last layers trainable\")\n",
        "  modelmulti = NeuralNetwork(basemodel, 37, train_loader, val_loader, test_loader, unfreeze=L)\n",
        "  accs.append(modelmulti.train(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c430ee-62c5-4d22-8ee1-2692741d9810",
      "metadata": {
        "id": "05c430ee-62c5-4d22-8ee1-2692741d9810",
        "outputId": "c3acdbcb-7345-47c6-dfaf-a0dd72614c00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=False\n",
            "Epoch  1 | Train: 74.61% | Val: 86.14%\n",
            "Epoch  2 | Train: 94.11% | Val: 89.95%\n",
            "Epoch  3 | Train: 97.49% | Val: 89.40%\n",
            "Epoch  4 | Train: 99.49% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.61% | Val: 89.95%\n",
            "Epoch  6 | Train: 99.64% | Val: 90.49%\n",
            "Epoch  7 | Train: 99.88% | Val: 90.22%\n",
            "Epoch  8 | Train: 99.94% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.82% | Val: 89.13%\n",
            "Epoch 10 | Train: 99.91% | Val: 89.40%\n",
            "Test Accuracy: 89.62%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=True\n",
            "Epoch  1 | Train: 75.91% | Val: 88.86%\n",
            "Epoch  2 | Train: 94.75% | Val: 88.59%\n",
            "Epoch  3 | Train: 97.83% | Val: 88.32%\n",
            "Epoch  4 | Train: 99.12% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.55% | Val: 89.67%\n",
            "Epoch  6 | Train: 99.85% | Val: 90.22%\n",
            "Epoch  7 | Train: 99.91% | Val: 89.40%\n",
            "Epoch  8 | Train: 99.97% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.97% | Val: 89.95%\n",
            "Epoch 10 | Train: 99.97% | Val: 90.22%\n",
            "Test Accuracy: 90.87%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=False\n",
            "Epoch  1 | Train: 74.12% | Val: 88.86%\n",
            "Epoch  2 | Train: 94.14% | Val: 90.49%\n",
            "Epoch  3 | Train: 97.77% | Val: 89.95%\n",
            "Epoch  4 | Train: 99.09% | Val: 88.86%\n",
            "Epoch  5 | Train: 99.70% | Val: 90.49%\n",
            "Epoch  6 | Train: 99.85% | Val: 91.30%\n",
            "Epoch  7 | Train: 99.88% | Val: 90.76%\n",
            "Epoch  8 | Train: 99.94% | Val: 89.13%\n",
            "Epoch  9 | Train: 99.91% | Val: 90.49%\n",
            "Epoch 10 | Train: 99.82% | Val: 90.22%\n",
            "Test Accuracy: 90.38%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=True\n",
            "Epoch  1 | Train: 74.43% | Val: 87.23%\n",
            "Epoch  2 | Train: 93.78% | Val: 86.41%\n",
            "Epoch  3 | Train: 97.68% | Val: 89.40%\n",
            "Epoch  4 | Train: 98.94% | Val: 90.76%\n",
            "Epoch  5 | Train: 99.61% | Val: 89.95%\n",
            "Epoch  6 | Train: 99.88% | Val: 90.76%\n",
            "Epoch  7 | Train: 99.97% | Val: 91.03%\n",
            "Epoch  8 | Train: 99.97% | Val: 90.76%\n",
            "Epoch  9 | Train: 99.94% | Val: 91.30%\n",
            "Epoch 10 | Train: 100.00% | Val: 90.49%\n",
            "Test Accuracy: 90.57%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=False\n",
            "Epoch  1 | Train: 73.31% | Val: 86.96%\n",
            "Epoch  2 | Train: 94.08% | Val: 88.32%\n",
            "Epoch  3 | Train: 98.01% | Val: 86.68%\n",
            "Epoch  4 | Train: 99.06% | Val: 88.32%\n",
            "Epoch  5 | Train: 99.09% | Val: 88.32%\n",
            "Epoch  6 | Train: 99.91% | Val: 88.86%\n",
            "Epoch  7 | Train: 99.73% | Val: 88.59%\n",
            "Epoch  8 | Train: 99.97% | Val: 88.86%\n",
            "Epoch  9 | Train: 99.97% | Val: 87.77%\n",
            "Epoch 10 | Train: 99.91% | Val: 89.13%\n",
            "Test Accuracy: 90.30%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=True\n",
            "Epoch  1 | Train: 75.00% | Val: 87.77%\n",
            "Epoch  2 | Train: 94.11% | Val: 88.04%\n",
            "Epoch  3 | Train: 97.86% | Val: 90.76%\n",
            "Epoch  4 | Train: 98.82% | Val: 88.86%\n",
            "Epoch  5 | Train: 99.43% | Val: 89.67%\n",
            "Epoch  6 | Train: 99.91% | Val: 90.49%\n",
            "Epoch  7 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  8 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  9 | Train: 100.00% | Val: 89.40%\n",
            "Epoch 10 | Train: 99.94% | Val: 90.49%\n",
            "Test Accuracy: 91.11%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=False\n",
            "Epoch  1 | Train: 73.64% | Val: 87.50%\n",
            "Epoch  2 | Train: 94.11% | Val: 88.04%\n",
            "Epoch  3 | Train: 97.40% | Val: 89.67%\n",
            "Epoch  4 | Train: 98.97% | Val: 89.13%\n",
            "Epoch  5 | Train: 99.40% | Val: 88.32%\n",
            "Epoch  6 | Train: 99.85% | Val: 89.40%\n",
            "Epoch  7 | Train: 99.85% | Val: 91.03%\n",
            "Epoch  8 | Train: 99.79% | Val: 90.49%\n",
            "Epoch  9 | Train: 99.94% | Val: 89.40%\n",
            "Epoch 10 | Train: 99.97% | Val: 90.49%\n",
            "Test Accuracy: 90.24%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=True\n",
            "Epoch  1 | Train: 74.82% | Val: 86.68%\n",
            "Epoch  2 | Train: 93.96% | Val: 88.04%\n",
            "Epoch  3 | Train: 98.01% | Val: 89.40%\n",
            "Epoch  4 | Train: 98.97% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.52% | Val: 90.22%\n",
            "Epoch  6 | Train: 99.88% | Val: 89.95%\n",
            "Epoch  7 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  8 | Train: 100.00% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.97% | Val: 89.95%\n",
            "Epoch 10 | Train: 99.94% | Val: 89.95%\n",
            "Test Accuracy: 90.54%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=False\n",
            "Epoch  1 | Train: 71.17% | Val: 85.05%\n",
            "Epoch  2 | Train: 90.07% | Val: 88.04%\n",
            "Epoch  3 | Train: 93.45% | Val: 88.04%\n",
            "Epoch  4 | Train: 95.56% | Val: 87.23%\n",
            "Epoch  5 | Train: 96.32% | Val: 89.13%\n",
            "Epoch  6 | Train: 97.04% | Val: 88.32%\n",
            "Epoch  7 | Train: 97.58% | Val: 88.59%\n",
            "Epoch  8 | Train: 98.22% | Val: 86.41%\n",
            "Epoch  9 | Train: 97.83% | Val: 84.78%\n",
            "Epoch 10 | Train: 98.25% | Val: 88.32%\n",
            "Test Accuracy: 88.14%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=True\n",
            "Epoch  1 | Train: 69.05% | Val: 86.96%\n",
            "Epoch  2 | Train: 89.19% | Val: 87.23%\n",
            "Epoch  3 | Train: 93.27% | Val: 88.32%\n",
            "Epoch  4 | Train: 95.29% | Val: 88.04%\n",
            "Epoch  5 | Train: 96.68% | Val: 87.23%\n",
            "Epoch  6 | Train: 98.16% | Val: 89.13%\n",
            "Epoch  7 | Train: 98.82% | Val: 91.03%\n",
            "Epoch  8 | Train: 98.67% | Val: 87.23%\n",
            "Epoch  9 | Train: 98.79% | Val: 89.67%\n",
            "Epoch 10 | Train: 99.06% | Val: 87.77%\n",
            "Test Accuracy: 89.70%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=False\n",
            "Epoch  1 | Train: 71.92% | Val: 86.14%\n",
            "Epoch  2 | Train: 90.25% | Val: 86.68%\n",
            "Epoch  3 | Train: 93.54% | Val: 86.68%\n",
            "Epoch  4 | Train: 95.08% | Val: 86.96%\n",
            "Epoch  5 | Train: 96.71% | Val: 85.33%\n",
            "Epoch  6 | Train: 97.40% | Val: 88.86%\n",
            "Epoch  7 | Train: 97.04% | Val: 88.86%\n",
            "Epoch  8 | Train: 97.89% | Val: 86.14%\n",
            "Epoch  9 | Train: 98.85% | Val: 88.86%\n",
            "Epoch 10 | Train: 98.61% | Val: 88.32%\n",
            "Test Accuracy: 87.33%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=True\n",
            "Epoch  1 | Train: 69.29% | Val: 85.05%\n",
            "Epoch  2 | Train: 90.43% | Val: 86.68%\n",
            "Epoch  3 | Train: 93.21% | Val: 89.13%\n",
            "Epoch  4 | Train: 94.96% | Val: 88.32%\n",
            "Epoch  5 | Train: 96.53% | Val: 85.87%\n",
            "Epoch  6 | Train: 98.04% | Val: 89.13%\n",
            "Epoch  7 | Train: 98.49% | Val: 90.22%\n",
            "Epoch  8 | Train: 98.37% | Val: 88.32%\n",
            "Epoch  9 | Train: 98.82% | Val: 91.03%\n",
            "Epoch 10 | Train: 99.18% | Val: 90.22%\n",
            "Test Accuracy: 89.70%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=False\n",
            "Epoch  1 | Train: 71.04% | Val: 83.70%\n",
            "Epoch  2 | Train: 90.28% | Val: 86.14%\n",
            "Epoch  3 | Train: 92.84% | Val: 87.23%\n",
            "Epoch  4 | Train: 95.77% | Val: 87.50%\n",
            "Epoch  5 | Train: 96.71% | Val: 87.23%\n",
            "Epoch  6 | Train: 97.28% | Val: 88.86%\n",
            "Epoch  7 | Train: 98.28% | Val: 86.68%\n",
            "Epoch  8 | Train: 97.40% | Val: 86.14%\n",
            "Epoch  9 | Train: 98.49% | Val: 87.50%\n",
            "Epoch 10 | Train: 98.52% | Val: 88.04%\n",
            "Test Accuracy: 88.28%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=True\n",
            "Epoch  1 | Train: 70.08% | Val: 86.96%\n",
            "Epoch  2 | Train: 90.37% | Val: 85.87%\n",
            "Epoch  3 | Train: 94.02% | Val: 88.04%\n",
            "Epoch  4 | Train: 95.38% | Val: 87.50%\n",
            "Epoch  5 | Train: 96.47% | Val: 88.32%\n",
            "Epoch  6 | Train: 97.89% | Val: 88.59%\n",
            "Epoch  7 | Train: 98.40% | Val: 88.32%\n",
            "Epoch  8 | Train: 98.67% | Val: 88.86%\n",
            "Epoch  9 | Train: 98.91% | Val: 89.40%\n",
            "Epoch 10 | Train: 98.85% | Val: 89.95%\n",
            "Test Accuracy: 89.56%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=False\n",
            "Epoch  1 | Train: 70.98% | Val: 85.87%\n",
            "Epoch  2 | Train: 89.49% | Val: 86.41%\n",
            "Epoch  3 | Train: 92.36% | Val: 88.04%\n",
            "Epoch  4 | Train: 94.90% | Val: 88.32%\n",
            "Epoch  5 | Train: 96.38% | Val: 88.32%\n",
            "Epoch  6 | Train: 96.86% | Val: 88.04%\n",
            "Epoch  7 | Train: 98.49% | Val: 85.87%\n",
            "Epoch  8 | Train: 98.22% | Val: 88.04%\n",
            "Epoch  9 | Train: 98.19% | Val: 89.13%\n",
            "Epoch 10 | Train: 98.01% | Val: 90.22%\n",
            "Test Accuracy: 86.43%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=True\n",
            "Epoch  1 | Train: 70.02% | Val: 86.14%\n",
            "Epoch  2 | Train: 89.98% | Val: 85.33%\n",
            "Epoch  3 | Train: 93.39% | Val: 87.77%\n",
            "Epoch  4 | Train: 95.35% | Val: 88.86%\n",
            "Epoch  5 | Train: 96.41% | Val: 89.13%\n",
            "Epoch  6 | Train: 97.92% | Val: 88.86%\n",
            "Epoch  7 | Train: 98.61% | Val: 89.95%\n",
            "Epoch  8 | Train: 98.88% | Val: 87.77%\n",
            "Epoch  9 | Train: 99.03% | Val: 89.13%\n",
            "Epoch 10 | Train: 99.31% | Val: 89.40%\n",
            "Test Accuracy: 89.45%\n",
            "\n",
            "=== Strategy 1 Extended Grid Results ===\n",
            "aug=False, freeze_bn=False, L2=False, sched=False → Test Acc: 89.62%\n",
            "aug=False, freeze_bn=False, L2=False, sched=True → Test Acc: 90.87%\n",
            "aug=False, freeze_bn=False, L2=True, sched=False → Test Acc: 90.38%\n",
            "aug=False, freeze_bn=False, L2=True, sched=True → Test Acc: 90.57%\n",
            "aug=False, freeze_bn=True, L2=False, sched=False → Test Acc: 90.30%\n",
            "aug=False, freeze_bn=True, L2=False, sched=True → Test Acc: 91.11%\n",
            "aug=False, freeze_bn=True, L2=True, sched=False → Test Acc: 90.24%\n",
            "aug=False, freeze_bn=True, L2=True, sched=True → Test Acc: 90.54%\n",
            "aug=True, freeze_bn=False, L2=False, sched=False → Test Acc: 88.14%\n",
            "aug=True, freeze_bn=False, L2=False, sched=True → Test Acc: 89.70%\n",
            "aug=True, freeze_bn=False, L2=True, sched=False → Test Acc: 87.33%\n",
            "aug=True, freeze_bn=False, L2=True, sched=True → Test Acc: 89.70%\n",
            "aug=True, freeze_bn=True, L2=False, sched=False → Test Acc: 88.28%\n",
            "aug=True, freeze_bn=True, L2=False, sched=True → Test Acc: 89.56%\n",
            "aug=True, freeze_bn=True, L2=True, sched=False → Test Acc: 86.43%\n",
            "aug=True, freeze_bn=True, L2=True, sched=True → Test Acc: 89.45%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Transforms\n",
        "base_tf = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "aug_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(), transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "# Create datasets and split 90/10\n",
        "full_ds = MultiClassPet(\"data\", trainval_names, breeds_map, transform=base_tf)\n",
        "n_val   = int(0.1 * len(full_ds))\n",
        "train_ds, val_ds = random_split(full_ds, [len(full_ds)-n_val, n_val])\n",
        "test_ds = MultiClassPet(\"data\", test_names, breeds_map, transform=base_tf)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 32\n",
        "val_loader  = DataLoader(val_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Strategy 1 grid\n",
        "results = []\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "\n",
        "for use_aug in [False, True]:\n",
        "    for freeze_bn in [False, True]:\n",
        "        for use_l2 in [False, True]:\n",
        "            for use_sched in [False, True]:\n",
        "                print(f\"\\n>>> aug={use_aug}, freeze_bn={freeze_bn}, L2={use_l2}, sched={use_sched}\")\n",
        "\n",
        "                # a) Set train transform\n",
        "                train_ds.dataset.transform = aug_tf if use_aug else base_tf\n",
        "\n",
        "                # b) Train loader\n",
        "                train_loader = DataLoader(\n",
        "                    train_ds, batch_size=batch_size, shuffle=True,\n",
        "                    num_workers=4, pin_memory=True\n",
        "                )\n",
        "\n",
        "                # c) Init model, fine-tune last 6 layers\n",
        "                model = NeuralNetwork(\n",
        "                    basemodel=basemodel,\n",
        "                    output=len(breed_names),\n",
        "                    train_loader=train_loader,\n",
        "                    val_loader=val_loader,\n",
        "                    test_loader=test_loader,\n",
        "                    unfreeze=6,\n",
        "                    parameters={}\n",
        "                )\n",
        "                model.model.to(device)\n",
        "\n",
        "                # d) Freeze batch-norm if requested\n",
        "                if freeze_bn:\n",
        "                    for m in model.model.modules():\n",
        "                        if isinstance(m, nn.BatchNorm2d):\n",
        "                            m.eval()\n",
        "                            for p in m.parameters():\n",
        "                                p.requires_grad = False\n",
        "\n",
        "                # e) Optimizer with two LR groups, optional L2 weight decay\n",
        "                wd = 1e-2 if use_l2 else 0.0\n",
        "                head_p = list(model.model.fc.parameters())\n",
        "                back_p = [p for n,p in model.model.named_parameters()\n",
        "                          if p.requires_grad and not n.startswith(\"fc\")]\n",
        "                model.optimizer = optim.AdamW([\n",
        "                    {\"params\": head_p, \"lr\":1e-3, \"weight_decay\":wd},\n",
        "                    {\"params\": back_p, \"lr\":1e-4, \"weight_decay\":wd}\n",
        "                ])\n",
        "\n",
        "                # f) Scheduler if requested\n",
        "                if use_sched:\n",
        "                    model.scheduler = optim.lr_scheduler.StepLR(model.optimizer, step_size=5, gamma=0.1)\n",
        "                else:\n",
        "                    model.scheduler = None\n",
        "\n",
        "                # g) Train and record test accuracy\n",
        "                acc = model.train(epochs=10)\n",
        "                results.append(((use_aug, freeze_bn, use_l2, use_sched), acc))\n",
        "\n",
        "# Summary for comparison\n",
        "print(\"\\n=== Strategy 1 Extended Grid Results ===\")\n",
        "for (aug, bn, l2, sched), acc in results:\n",
        "    print(f\"aug={aug}, freeze_bn={bn}, L2={l2}, sched={sched} → Test Acc: {acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "906198d5-6a25-4adb-b4cc-aaf32dc13b1c",
      "metadata": {
        "id": "906198d5-6a25-4adb-b4cc-aaf32dc13b1c"
      },
      "source": [
        "-> Strategy 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vQdtxDaSeTEd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vQdtxDaSeTEd",
        "outputId": "18dc5d37-1421-411b-c3f7-38d9bd3021bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training model with uf_rate 0.3\n",
            "Epoch  1 | Train: 61.08% | Val: 83.97%\n",
            "Epoch  2 | Train: 88.68% | Val: 89.13%\n",
            "Epoch  3 | Train: 91.46% | Val: 90.76%\n",
            "Epoch  4 | Train: 92.39% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.75% | Val: 91.30%\n",
            "Epoch  6 | Train: 94.93% | Val: 90.22%\n",
            "Epoch  7 | Train: 95.77% | Val: 91.03%\n",
            "Epoch  8 | Train: 95.92% | Val: 90.22%\n",
            "Epoch  9 | Train: 96.71% | Val: 89.95%\n",
            "Epoch 10 | Train: 97.04% | Val: 90.22%\n",
            "Test Accuracy: 90.27%\n",
            "Start training model with uf_rate 0.5\n",
            "Epoch  1 | Train: 60.60% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.07% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.70% | Val: 89.67%\n",
            "Epoch  4 | Train: 93.48% | Val: 89.95%\n",
            "Epoch  5 | Train: 93.72% | Val: 90.49%\n",
            "Epoch  6 | Train: 94.96% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.59% | Val: 90.49%\n",
            "Epoch  8 | Train: 95.59% | Val: 89.40%\n",
            "Epoch  9 | Train: 95.98% | Val: 89.13%\n",
            "Epoch 10 | Train: 96.68% | Val: 89.40%\n",
            "Test Accuracy: 89.07%\n",
            "Start training model with uf_rate 0.8\n",
            "Epoch  1 | Train: 59.48% | Val: 85.60%\n",
            "Epoch  2 | Train: 88.77% | Val: 88.86%\n",
            "Epoch  3 | Train: 90.73% | Val: 91.03%\n",
            "Epoch  4 | Train: 92.69% | Val: 90.22%\n",
            "Epoch  5 | Train: 94.47% | Val: 91.30%\n",
            "Epoch  6 | Train: 94.84% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.71% | Val: 91.03%\n",
            "Epoch  8 | Train: 96.01% | Val: 91.30%\n",
            "Epoch  9 | Train: 96.74% | Val: 90.76%\n",
            "Epoch 10 | Train: 96.89% | Val: 90.76%\n",
            "Test Accuracy: 89.37%\n",
            "Start training model with uf_rate 1\n",
            "Epoch  1 | Train: 58.97% | Val: 82.88%\n",
            "Epoch  2 | Train: 88.32% | Val: 87.50%\n",
            "Epoch  3 | Train: 92.09% | Val: 88.86%\n",
            "Epoch  4 | Train: 92.75% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.75% | Val: 89.13%\n",
            "Epoch  6 | Train: 94.84% | Val: 91.85%\n",
            "Epoch  7 | Train: 95.68% | Val: 89.13%\n",
            "Epoch  8 | Train: 96.29% | Val: 89.95%\n",
            "Epoch  9 | Train: 96.29% | Val: 89.67%\n",
            "Epoch 10 | Train: 96.71% | Val: 89.40%\n",
            "Test Accuracy: 89.67%\n",
            "Start training model with uf_rate 2\n",
            "Epoch  1 | Train: 61.29% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.16% | Val: 87.77%\n",
            "Epoch  3 | Train: 91.49% | Val: 88.86%\n",
            "Epoch  4 | Train: 92.75% | Val: 88.04%\n",
            "Epoch  5 | Train: 93.39% | Val: 88.86%\n",
            "Epoch  6 | Train: 95.11% | Val: 89.40%\n",
            "Epoch  7 | Train: 95.62% | Val: 90.49%\n",
            "Epoch  8 | Train: 95.29% | Val: 89.95%\n",
            "Epoch  9 | Train: 96.62% | Val: 89.95%\n",
            "Epoch 10 | Train: 96.32% | Val: 89.13%\n",
            "Test Accuracy: 90.27%\n",
            "Start training model with uf_rate 3\n",
            "Epoch  1 | Train: 60.99% | Val: 85.87%\n",
            "Epoch  2 | Train: 89.01% | Val: 88.59%\n",
            "Epoch  3 | Train: 90.88% | Val: 90.49%\n",
            "Epoch  4 | Train: 93.48% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.84% | Val: 90.22%\n",
            "Epoch  6 | Train: 95.20% | Val: 91.58%\n",
            "Epoch  7 | Train: 95.62% | Val: 90.76%\n",
            "Epoch  8 | Train: 95.83% | Val: 89.40%\n",
            "Epoch  9 | Train: 96.41% | Val: 89.67%\n",
            "Epoch 10 | Train: 97.04% | Val: 88.86%\n",
            "Test Accuracy: 89.94%\n"
          ]
        }
      ],
      "source": [
        "# Strategy 2: train with gradual unfreezing\n",
        "parameters = {}\n",
        "parameters['gradual_unfreezing'] = True\n",
        "accs = []\n",
        "\n",
        "# test rates in steps of two\n",
        "for rate in [0.3, 0.5, 0.8, 1, 2, 3]:\n",
        "  print(f\"Start training model with uf_rate {rate}\")\n",
        "  parameters['unfreezing_rate'] = rate\n",
        "  modelmulti = NeuralNetwork(basemodel, 37, train_loader, val_loader, test_loader, unfreeze=1, parameters=parameters)   # start with only one unfrozen layer\n",
        "  accs.append(modelmulti.train(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd91e0d3-e161-4eaa-a1c6-963be4e032bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd91e0d3-e161-4eaa-a1c6-963be4e032bb",
        "outputId": "e827233a-e14d-455b-d6f4-236066225819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=none\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train: 58.21% | Val: 86.14%\n",
            "Epoch  2 | Train: 86.71% | Val: 88.04%\n",
            "Epoch  3 | Train: 89.61% | Val: 89.40%\n",
            "Epoch  4 | Train: 91.12% | Val: 88.04%\n",
            "Epoch  5 | Train: 92.36% | Val: 88.86%\n",
            "Epoch  6 | Train: 93.09% | Val: 89.40%\n",
            "Epoch  7 | Train: 93.33% | Val: 87.50%\n",
            "Epoch  8 | Train: 94.05% | Val: 88.86%\n",
            "Epoch  9 | Train: 94.84% | Val: 89.13%\n",
            "Epoch 10 | Train: 94.47% | Val: 89.67%\n",
            "Epoch 11 | Train: 94.78% | Val: 87.77%\n",
            "Epoch 12 | Train: 95.59% | Val: 87.50%\n",
            "Epoch 13 | Train: 95.80% | Val: 88.59%\n",
            "Epoch 14 | Train: 95.83% | Val: 88.59%\n",
            "Epoch 15 | Train: 95.98% | Val: 87.50%\n",
            "Test Accuracy: 88.28%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=none\n",
            "Epoch  1 | Train: 58.09% | Val: 83.42%\n",
            "Epoch  2 | Train: 85.60% | Val: 83.97%\n",
            "Epoch  3 | Train: 88.71% | Val: 85.05%\n",
            "Epoch  4 | Train: 89.89% | Val: 89.40%\n",
            "Epoch  5 | Train: 91.73% | Val: 87.23%\n",
            "Epoch  6 | Train: 91.52% | Val: 88.86%\n",
            "Epoch  7 | Train: 92.57% | Val: 88.59%\n",
            "Epoch  8 | Train: 93.72% | Val: 88.59%\n",
            "Epoch  9 | Train: 94.41% | Val: 87.77%\n",
            "Epoch 10 | Train: 93.96% | Val: 89.67%\n",
            "Epoch 11 | Train: 94.41% | Val: 88.59%\n",
            "Epoch 12 | Train: 95.05% | Val: 87.77%\n",
            "Epoch 13 | Train: 94.81% | Val: 87.50%\n",
            "Epoch 14 | Train: 95.35% | Val: 87.50%\n",
            "Epoch 15 | Train: 96.04% | Val: 86.96%\n",
            "Test Accuracy: 87.30%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=none\n",
            "Epoch  1 | Train: 53.99% | Val: 76.90%\n",
            "Epoch  2 | Train: 84.60% | Val: 84.51%\n",
            "Epoch  3 | Train: 88.07% | Val: 83.70%\n",
            "Epoch  4 | Train: 89.19% | Val: 88.04%\n",
            "Epoch  5 | Train: 89.73% | Val: 88.04%\n",
            "Epoch  6 | Train: 90.91% | Val: 86.14%\n",
            "Epoch  7 | Train: 92.63% | Val: 84.51%\n",
            "Epoch  8 | Train: 92.24% | Val: 87.50%\n",
            "Epoch  9 | Train: 92.75% | Val: 85.87%\n",
            "Epoch 10 | Train: 93.39% | Val: 86.41%\n",
            "Epoch 11 | Train: 93.36% | Val: 87.50%\n",
            "Epoch 12 | Train: 94.38% | Val: 88.32%\n",
            "Epoch 13 | Train: 94.23% | Val: 87.50%\n",
            "Epoch 14 | Train: 93.93% | Val: 88.04%\n",
            "Epoch 15 | Train: 94.17% | Val: 85.60%\n",
            "Test Accuracy: 87.74%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=none\n",
            "Epoch  1 | Train: 49.09% | Val: 80.43%\n",
            "Epoch  2 | Train: 82.07% | Val: 82.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "   Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> \n",
            " Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "     self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    if w.is_alive():^\n",
            " ^   ^ ^^ ^ ^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                ^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    if w.is_alive():\n",
            "     ^  ^ ^ ^^^^^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    \n",
            "^assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError^\n",
            ": ^ can only test a child process^ \n",
            "^^^  ^^  Exception ignored in:   ^  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive(): \n",
            "^^^ ^ ^ ^ ^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "\n",
            "AssertionError^ ^:  ^can only test a child process ^\n",
            " ^^ ^ ^ ^Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> \n",
            " Traceback (most recent call last):\n",
            " ^^^^^\n",
            "AssertionError^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            ": ^^^^^^^    ^can only test a child process^\n",
            "self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^^ Exception ignored in: ^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^Exception ignored in: \n",
            " ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^ Traceback (most recent call last):\n",
            "\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^Traceback (most recent call last):\n",
            "^        File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^self._shutdown_workers()    \n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^^^    ^self._shutdown_workers()if w.is_alive():^\n",
            "\n",
            "\n",
            "AssertionError ^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^     :  ^if w.is_alive():can only test a child process \n",
            "^ \n",
            "Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^\n",
            " Traceback (most recent call last):\n",
            "  ^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^ ^^     \n",
            "self._shutdown_workers()   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^     \n",
            "^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^\n",
            " ^if w.is_alive():^^^\n",
            " ^  ^^^^ ^ ^ \n",
            " ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  ^     \n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            " assert self._parent_pid == os.getpid(), 'can only test a child process'      \n",
            " assert self._parent_pid == os.getpid(), 'can only test a child process'   ^^ \n",
            "^ ^ ^ ^ ^ ^^^ ^^ ^ ^ ^ ^ ^^ \n",
            "  ^    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^      ^^^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            " ^^  ^ ^^ ^  ^^^ ^^^^ ^^^^^^^^^ ^ ^^^^^^^^^^^^ ^\n",
            "AssertionError^: ^^can only test a child process^^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^^^^\n",
            "^^Traceback (most recent call last):\n",
            "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^^^    ^^^^self._shutdown_workers()^^\n",
            "^^^^^^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^AssertionError^^\n",
            "^^:  ^^can only test a child process ^ \n",
            "\n",
            "^ AssertionError^ : ^ can only test a child process \n",
            "\n",
            "^AssertionErrorException ignored in: : ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>can only test a child process^\n",
            "\n",
            "^Traceback (most recent call last):\n",
            "Exception ignored in: ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^    \n",
            "^self._shutdown_workers()Traceback (most recent call last):\n",
            "\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^if w.is_alive():Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>    ^\n",
            "^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^ self._shutdown_workers() \n",
            "    \n",
            " self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "              if w.is_alive():if w.is_alive(): \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    \n",
            " ^   ^    ^^^ ^  ^  ^ ^^ ^ ^   ^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "     ^^ ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^ ^^^\n",
            "^^^ ^^^^^^ ^^^ ^^\n",
            " ^\n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'^     \n",
            "^ assert self._parent_pid == os.getpid(), 'can only test a child process'^  \n",
            "^   ^   ^  ^^ ^ ^ ^ ^ ^^^  ^  ^   ^ ^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^AssertionError^^: ^^^can only test a child process^^^\n",
            "^^^^^^^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^\n",
            "^^^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^^    ^^^self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^\n",
            "AssertionError^^\n",
            "^^AssertionError    : : \n",
            "if w.is_alive():can only test a child processcan only test a child processAssertionError\n",
            "\n",
            "\n",
            ":  can only test a child process \n",
            " Exception ignored in: Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540><function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "\n",
            "Traceback (most recent call last):\n",
            " Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "         \n",
            "self._shutdown_workers()self._shutdown_workers() \n",
            "^\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    if w.is_alive():    self._shutdown_workers()if w.is_alive():        File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "\n",
            "\n",
            "^if w.is_alive():  \n",
            "       ^ ^ ^ ^^^^^\n",
            "^^^^^ ^^^ ^^^ ^^^^ ^^^ \n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            " ^\n",
            "     ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^^\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "        \n",
            "^ assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "\n",
            "^   ^  ^ ^ ^ ^   ^ ^   \n",
            "     File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "        ^ assert self._parent_pid == os.getpid(), 'can only test a child process' ^  ^ \n",
            "  ^ ^  ^^ ^  ^^ ^ ^ ^^^^^ ^^^^^^ ^^^^^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^AssertionError^: ^^can only test a child process^^\n",
            "^^^^^^^^^^^Exception ignored in: ^^^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^^^\n",
            "\n",
            "^^Traceback (most recent call last):\n",
            "\n",
            "AssertionError^:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "AssertionError^can only test a child process    : self._shutdown_workers()can only test a child process^\n",
            "\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "^^^^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "if w.is_alive(): \n",
            "       ^ ^ ^ \n",
            " AssertionError: can only test a child process\n",
            "  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "                     ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError: ^\n",
            "can only test a child process\n",
            "AssertionError: can only test a child processException ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  3 | Train: 86.65% | Val: 84.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "        Exception ignored in: self._shutdown_workers()if w.is_alive():\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "\n",
            "  Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "Exception ignored in:     if w.is_alive():\n",
            "       ^^if w.is_alive():\n",
            " ^  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "   ^^  ^ ^   ^    ^^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    if w.is_alive():^\n",
            " ^^ ^ ^^^ ^ ^ ^^^^ ^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^\n",
            "\n",
            "^    ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ \n",
            "    ^ \n",
            " assert self._parent_pid == os.getpid(), 'can only test a child process'   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            " \n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "       ^ ^  ^   ^^   ^^ ^ ^^^^^^^^^^^^^^^ ^^ ^^^^^^^^^ ^^^ ^^    ^^^^^^^^^^^ ^ ^^^\n",
            "AssertionError^^^^  ^^^^^: ^^^^^^^^^^can only test a child process^^^^^^^^^^\n",
            "AssertionError^: ^^\n",
            "can only test a child process^^\n",
            "^^^^^^^^^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^^^^^^\n",
            "^^\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "^^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    ^    ^^Exception ignored in: if w.is_alive():self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^\n",
            "\n",
            "AssertionError:     can only test a child process\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " if w.is_alive():    \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> self._shutdown_workers()   \n",
            "  \n",
            "    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "       File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "  if w.is_alive():^    \n",
            "  ^ ^ self._shutdown_workers()^^\n",
            " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " ^^     ^^if w.is_alive(): ^^\n",
            " ^ ^^ ^^ ^^^  ^  ^^^^^^^^^^^^^^^\n",
            "^^^^^^^\n",
            "^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process' ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "\n",
            " ^   \n",
            "        File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "       assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "                    ^  ^ ^^^^^ ^^^ ^^^^^^^^^^^ ^^^^ ^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^AssertionError^^^: ^^^can only test a child process^^\n",
            "\n",
            "^^AssertionError^^: ^\n",
            "can only test a child process^AssertionError\n",
            "^: ^Exception ignored in: ^^^can only test a child process^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^Exception ignored in:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>    ^\n",
            "Exception ignored in: if w.is_alive():^Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "\n",
            " AssertionError    Traceback (most recent call last):\n",
            " : self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " can only test a child process\n",
            "     \n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "self._shutdown_workers()      \n",
            "if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " \n",
            "    ^ if w.is_alive():^ Exception ignored in: \n",
            "^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> ^ \n",
            " ^ Traceback (most recent call last):\n",
            " ^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^      ^^self._shutdown_workers()^^\n",
            "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^ ^    ^^^if w.is_alive():\n",
            "^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^     ^^ assert self._parent_pid == os.getpid(), 'can only test a child process'^ \n",
            "  ^^^^  ^^ ^\n",
            "  ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^ ^^     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^^\n",
            "^ ^\n",
            "  ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "        ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^  \n",
            "^  ^ ^ ^^\n",
            "^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^     ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
            "^^   ^^  ^^^^  ^^^^ ^^ ^^ ^^  ^^  ^  ^ ^^ ^^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^^^AssertionError^^^: ^^^can only test a child process^\n",
            "^\n",
            "^AssertionError^^: ^can only test a child process^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^\n",
            "\n",
            "^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>    ^^\n",
            "^self._shutdown_workers()^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "\n",
            "\n",
            "^^AssertionError      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "\n",
            "    if w.is_alive():self._shutdown_workers(): AssertionError\n",
            "\n",
            "can only test a child process:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "\n",
            " can only test a child process\n",
            "      if w.is_alive():Exception ignored in: \n",
            "Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> \n",
            " <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>   \n",
            "Traceback (most recent call last):\n",
            " Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^       File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^ self._shutdown_workers()^^    \n",
            "^^^self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^^\n",
            "^^^^      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^^if w.is_alive():^    \n",
            "if w.is_alive():^ \n",
            "^ \n",
            " ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  ^      ^assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "^  \n",
            "        File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^     ^^ assert self._parent_pid == os.getpid(), 'can only test a child process' ^^ \n",
            "  ^ ^ ^^  ^ ^^^ ^^^ ^^^ ^^^^ ^^^  ^^^^^ ^ \n",
            "^\n",
            "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^        ^assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "\n",
            "^^  ^ ^^^^^^^ ^^^ ^  ^^   ^ ^ ^ ^^  ^^ ^ ^^^^^^^^^^^^^^^^^^^\n",
            "^^^AssertionError^: ^^can only test a child process\n",
            "^^^^ ^ ^ ^Exception ignored in:  ^^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^^\n",
            "^^^^^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^^^\n",
            "    ^self._shutdown_workers()AssertionError^^\n",
            ": ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "can only test a child process^^    \n",
            "^^if w.is_alive():^^\n",
            "^^ ^^ ^^ ^Exception ignored in: ^  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "^\n",
            "AssertionError^ Traceback (most recent call last):\n",
            ": ^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^can only test a child process^    ^\n",
            "^^self._shutdown_workers()^\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^^if w.is_alive():Exception ignored in: ^^\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^ \n",
            "^ ^Traceback (most recent call last):\n",
            "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^^    ^ ^self._shutdown_workers()\n",
            " \n",
            "\n",
            " AssertionError  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^:         ^can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():^\n",
            "\n",
            "\n",
            "^  ^ ^ ^^Exception ignored in:       ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>  \n",
            " ^ Traceback (most recent call last):\n",
            "^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^\n",
            "       File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^self._shutdown_workers()     ^^^\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^^     ^^ if w.is_alive():^^ \n",
            "^^  ^^  ^\n",
            "  ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  ^      ^assert self._parent_pid == os.getpid(), 'can only test a child process'  ^\n",
            "  ^ ^ ^ ^^^ ^^^ ^^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^ ^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^^    ^^^^^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
            "^^^^^^ ^^^^ ^^^^^^ ^\n",
            "^ ^AssertionError ^ ^^^:  can only test a child process^^ ^ ^\n",
            "  ^^^^^^^^^^^^^\n",
            "^AssertionError^: ^^^^^can only test a child process^^\n",
            "^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> \n",
            " Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "       self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ ^ ^^  ^^  \n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^ ^ ^  ^^^ ^ \n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            " Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> \n",
            " Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    ^ self._shutdown_workers() ^\n",
            "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "      if w.is_alive(): ^ ^ ^\n",
            " ^ ^^^^ ^^ ^ ^ ^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    Traceback (most recent call last):\n",
            "^^assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^\n",
            "^    \n",
            " self._shutdown_workers()AssertionError ^: \n",
            " ^can only test a child process^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " ^     ^ ^^^if w.is_alive(): ^^ \n",
            "AssertionErrorException ignored in:  : \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>can only test a child process  \n",
            "\n",
            " ^^^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^     ^self._shutdown_workers()^\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "     if w.is_alive():^ Exception ignored in: ^ \n",
            " ^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^ ^  ^\n",
            "^  ^^^Traceback (most recent call last):\n",
            "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^^^^^^^    ^^^^^^^^^^self._shutdown_workers()\n",
            "^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'    ^if w.is_alive():^^\n",
            "^^\n",
            " ^ ^^ ^^  \n",
            "  ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            " ^     \n",
            "  AssertionError :  can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "   ^\n",
            "  ^^ ^ ^^^^^Exception ignored in:  ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> ^\n",
            " ^^Traceback (most recent call last):\n",
            " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^    ^^ self._shutdown_workers()^ \n",
            "^\n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "       File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^assert self._parent_pid == os.getpid(), 'can only test a child process'    ^^\n",
            "if w.is_alive():^^ \n",
            "^^  ^^  ^ ^ ^^ ^^ ^^  ^^ ^^^^^ ^^^^^^^^ ^^ ^^^^^^^ ^^^^\n",
            "^AssertionError^^ : ^can only test a child process^\n",
            " ^^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^^\n",
            "^^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^^^self._shutdown_workers()^\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^^\n",
            "^^      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^if w.is_alive():^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^\n",
            "\n",
            "AssertionError   ^:   can only test a child process^ \n",
            " ^ ^   ^     ^ Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^\n",
            "^^^^^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^^^^^    ^^^^self._shutdown_workers()^^^^\n",
            "\n",
            "^^^AssertionError^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():^: \n",
            "\n",
            "can only test a child process  ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "  ^^ ^     assert self._parent_pid == os.getpid(), 'can only test a child process' ^^\n",
            "^ Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "^ ^^Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^ ^    ^^^ self._shutdown_workers()^^ ^^ \n",
            "^^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^ ^^ ^ ^^if w.is_alive():^^^^^\n",
            "\n",
            "^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^\n",
            "     ^assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError^: \n",
            " ^  ^can only test a child process  \n",
            "  ^ ^Exception ignored in: ^^^ ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^ \n",
            "^^ Traceback (most recent call last):\n",
            "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^^    ^ ^^^^^^self._shutdown_workers() ^^^^^^^^\n",
            "\n",
            "^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^    \n",
            "AssertionError: can only test a child processif w.is_alive():\n",
            "^\n",
            "\n",
            "Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> ^^^ ^^ ^^^  ^\n",
            " Traceback (most recent call last):\n",
            "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^ ^ ^      self._shutdown_workers()  ^\n",
            "^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " ^^ ^     ^ ^if w.is_alive():^^\n",
            "^ ^^ ^^^ ^^^^^ ^^^^^^^^ ^^^  ^^^^\n",
            "AssertionError^\n",
            ": ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "can only test a child process    ^\n",
            "^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            " ^^ ^ ^^Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive(): ^\n",
            "^ ^^   ^ ^   \n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  ^     ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
            "^^^ ^^^^^ ^^ ^^^^ ^^ ^^^^ ^^^\n",
            " ^AssertionError^^^\n",
            "   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            ":      ^assert self._parent_pid == os.getpid(), 'can only test a child process'^ can only test a child process ^\n",
            "\n",
            "^^^^^^^^ ^^ Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^ ^\n",
            "^^Traceback (most recent call last):\n",
            " ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^ ^^self._shutdown_workers()^ \n",
            "^^ ^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " ^^     ^if w.is_alive(): \n",
            "^^^ ^\n",
            "^AssertionError^: ^can only test a child process\n",
            " ^^ ^^ ^^Exception ignored in:  ^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^    ^^self._shutdown_workers()^^\n",
            "^^^^^^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^^\n",
            "    ^AssertionError^^: can only test a child process^^if w.is_alive():\n",
            "^^^^\n",
            "^^^^^^^ ^^ ^Exception ignored in: ^^^^^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "\n",
            "AssertionErrorTraceback (most recent call last):\n",
            "^:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "can only test a child process\n",
            "  ^  Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>    ^\n",
            "self._shutdown_workers()^Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^         ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "^ self._shutdown_workers()^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "  ^\n",
            " ^       if w.is_alive():^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " \n",
            "  ^    ^^ if w.is_alive():^^\n",
            "^  \n",
            " ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            " ^ ^       ^assert self._parent_pid == os.getpid(), 'can only test a child process'^  ^^^ ^\n",
            "^^ ^ ^^ ^^^^ ^^^^^ ^^^^^ ^ ^^ ^ ^ ^^ ^^^^^^^^^^ ^^^^^\n",
            "\n",
            "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    AssertionError^: assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process^^\n",
            "\n",
            "^\n",
            "^ ^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in: ^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' ^ Traceback (most recent call last):\n",
            "\n",
            "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "       ^ self._shutdown_workers() ^ \n",
            " ^    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^ ^^^^^    ^ ^^if w.is_alive(): ^^\n",
            "^^ ^ ^^^ ^^ ^      ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^AssertionError\n",
            ": \n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "can only test a child processAssertionError^\n",
            ": ^    can only test a child process^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^\n",
            "^ ^ ^^Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^ ^ \n",
            "^^ Traceback (most recent call last):\n",
            " ^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^     ^self._shutdown_workers() ^\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^^ ^ ^\n",
            " ^AssertionError  : ^ can only test a child process\n",
            "^ ^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^\n",
            "^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^    self._shutdown_workers()^^^^^^\n",
            "^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'    ^\n",
            " ^^  if w.is_alive(): ^\n",
            "^ ^^    ^     ^   ^^^^ ^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^\n",
            "AssertionError^: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^^^^^^ ^ ^ ^ ^^^^ ^ ^ ^  ^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^^can only test a child process\n",
            "^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  4 | Train: 87.29% | Val: 82.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "   Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> \n",
            " Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    if w.is_alive():^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    ^ self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'      \n",
            "if w.is_alive(): \n",
            "               ^^   ^^ ^^ ^^^ ^^^^^^^^^^^^^^^^^^^^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "^\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "            ^assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()^\n",
            "\n",
            "\n",
            "^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " ^ ^ ^^       ^if w.is_alive():^  \n",
            " ^   ^   ^     ^    ^^^  ^^^^^^^^^^ \n",
            "AssertionError: can only test a child process\n",
            "^^^ ^^^^^^^Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^^^^\n",
            "^^Traceback (most recent call last):\n",
            "^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^\n",
            "^    ^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()^^    \n",
            "^^assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^\n",
            "    ^^ if w.is_alive():^^ \n",
            "^^  ^^ ^ ^ ^ ^  ^  ^ ^ ^ ^  ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "AssertionError^^    : ^^assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process^^^\n",
            "\n",
            "\n",
            " ^AssertionError ^:  ^ ^ can only test a child process^\n",
            " <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^ Exception ignored in: ^ \n",
            "Traceback (most recent call last):\n",
            "^    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^Exception ignored in: ^     <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^self._shutdown_workers()\n",
            "^^Traceback (most recent call last):\n",
            "^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^self._shutdown_workers()    if w.is_alive():^\n",
            "^\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^     ^AssertionError if w.is_alive(): \n",
            ": can only test a child process \n",
            "^   ^   ^ ^ Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^ \n",
            "^^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^^^    ^^self._shutdown_workers()^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            " ^ ^^ ^ ^^^ ^^  ^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^^^    \n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^^  \n",
            "^^  ^^ ^^ ^ ^^   ^^ ^ ^ \n",
            "    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^      \n",
            " ^assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError ^: \n",
            " ^can only test a child process  \n",
            "^  ^ ^^ ^^ ^^ ^^Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^\n",
            "Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " ^    ^if w.is_alive():^\n",
            "^ ^ ^  ^^ ^  ^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^\n",
            "^    ^AssertionError^assert self._parent_pid == os.getpid(), 'can only test a child process'^: ^\n",
            "^can only test a child process^ ^\n",
            "^ ^^ ^^ ^^^ ^^ ^^Exception ignored in:  ^^ <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^ \n",
            "\n",
            "^Traceback (most recent call last):\n",
            "AssertionError\n",
            "   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "AssertionError    : self._shutdown_workers() \n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "can only test a child process:     can only test a child process^\n",
            "\n",
            "^if w.is_alive():Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>Exception ignored in: ^\n",
            "\n",
            "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>Traceback (most recent call last):\n",
            " ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^ Traceback (most recent call last):\n",
            "    self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "\n",
            " ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "     ^    ^ self._shutdown_workers()if w.is_alive(): \n",
            "\n",
            " ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " ^ ^^      ^ if w.is_alive():^^ ^\n",
            "^^^^ ^^^ ^^^ ^^^ ^^^ ^^  ^^^^^^^^^^^^\n",
            "\n",
            "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'    ^\n",
            "^^   ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^ ^\n",
            "^  ^   ^ ^ ^  ^^ ^^^\n",
            " ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    AssertionError^ assert self._parent_pid == os.getpid(), 'can only test a child process' ^: \n",
            "^ can only test a child process  ^\n",
            "   ^Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^^ \n",
            "^ ^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            " ^^    ^ self._shutdown_workers()^^\n",
            "^ ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^ ^^     ^^ ^if w.is_alive():^^^\n",
            "^^^^^^ ^^^^ ^^ ^ ^^^^^^^^^ ^^^ ^^^ ^^^^^^^^^^^^^^^^\n",
            "^^AssertionError^^^^^^: \n",
            "^^AssertionErrorcan only test a child process: ^\n",
            "^can only test a child process^^Exception ignored in: ^^\n",
            "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>\n",
            "^^^\n",
            "^Traceback (most recent call last):\n",
            "^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    ^        self._shutdown_workers()self._shutdown_workers()^\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "         ^if w.is_alive(): if w.is_alive():\n",
            "\n",
            " \n",
            "AssertionError :    can only test a child process  \n",
            "         Exception ignored in: ^  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    ^self._shutdown_workers()  \n",
            " ^^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^ ^ ^^ ^^^ ^^ ^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^\n",
            "^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^\n",
            "^ ^^ ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            " ^      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^ ^    assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            " ^  ^  ^ assert self._parent_pid == os.getpid(), 'can only test a child process' ^^ \n",
            "    ^   \n",
            " ^  AssertionError ^ ^ : ^^ can only test a child process^^^\n",
            " ^^Exception ignored in:  ^    ^^^^^^^^^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^^\n",
            "^^^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^^    ^^^^^^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "^^    ^^^^^^^^if w.is_alive():^^^^^\n",
            "^^^ ^^^^ ^^ ^^ ^^ ^^ ^ ^^^^\n",
            "^^^^AssertionError: ^^^can only test a child process^^\n",
            "^^^^^Exception ignored in: ^^^^\n",
            "AssertionError^: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>can only test a child process\n",
            "^\n",
            "Traceback (most recent call last):\n",
            "^^^^Exception ignored in: ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "    ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540>^self._shutdown_workers()^\n",
            "\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "AssertionError  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
            "\n",
            "\n",
            "  :     Traceback (most recent call last):\n",
            "  can only test a child process  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "\n",
            " ^^     ^^self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            "    if w.is_alive(): \n",
            "  ^ Exception ignored in:  ^ ^  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f11645c4540> ^^  ^\n",
            "^^ ^^ \n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n",
            "^^\n",
            "      ^  self._shutdown_workers()^^ ^ ^^ \n",
            " \n",
            "^ ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n",
            " ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^ ^     if w.is_alive():^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  \n",
            "^ ^ ^^  ^ ^ ^^ ^^ ^^^^ ^^^ ^^^^ ^^^^^^   ^^^^^^^^^^ ^^^^^^\n",
            "^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
            "^  ^^ ^^ ^  ^^^\n",
            "AssertionError: ^ ^ ^^can only test a child process^^ ^\n",
            "^^ ^^^^^^^  ^^^^^^^^^^^^^^\n",
            "^^AssertionError^^^: can only test a child process^^^\n",
            "^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError: can only test a child process^^\n",
            "^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  5 | Train: 88.47% | Val: 86.14%\n",
            "Epoch  6 | Train: 88.38% | Val: 83.70%\n",
            "Epoch  7 | Train: 89.07% | Val: 85.05%\n",
            "Epoch  8 | Train: 90.52% | Val: 85.87%\n",
            "Epoch  9 | Train: 90.55% | Val: 85.33%\n",
            "Epoch 10 | Train: 91.12% | Val: 85.05%\n",
            "Epoch 11 | Train: 91.27% | Val: 85.05%\n",
            "Epoch 12 | Train: 92.12% | Val: 85.87%\n",
            "Epoch 13 | Train: 91.30% | Val: 84.78%\n",
            "Epoch 14 | Train: 91.79% | Val: 84.51%\n",
            "Epoch 15 | Train: 92.57% | Val: 86.96%\n",
            "Test Accuracy: 88.03%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=none\n",
            "Epoch  1 | Train: 60.14% | Val: 85.60%\n",
            "Epoch  2 | Train: 88.07% | Val: 88.59%\n",
            "Epoch  3 | Train: 91.21% | Val: 89.40%\n",
            "Epoch  4 | Train: 92.57% | Val: 88.86%\n",
            "Epoch  5 | Train: 93.42% | Val: 89.13%\n",
            "Epoch  6 | Train: 93.57% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.02% | Val: 91.03%\n",
            "Epoch  8 | Train: 96.14% | Val: 88.32%\n",
            "Epoch  9 | Train: 95.86% | Val: 90.76%\n",
            "Epoch 10 | Train: 96.53% | Val: 90.49%\n",
            "Epoch 11 | Train: 96.35% | Val: 89.95%\n",
            "Epoch 12 | Train: 96.35% | Val: 89.40%\n",
            "Epoch 13 | Train: 97.07% | Val: 91.03%\n",
            "Epoch 14 | Train: 97.55% | Val: 89.67%\n",
            "Epoch 15 | Train: 97.25% | Val: 91.03%\n",
            "Test Accuracy: 89.40%\n",
            "\n",
            "=== Strategy 2 Grid Search Results ===\n",
            "aug | freeze_bn | L2   | scheduler | TestAcc\n",
            "----|-----------|------|-----------|--------\n",
            "True | False     | False | none      |  88.28%\n",
            "True | False     | False | none      |  87.30%\n",
            "True | False     | False | none      |  87.74%\n",
            "True | False     | False | none      |  88.03%\n",
            "True | False     | False | none      |  89.40%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# transforms\n",
        "base_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "])\n",
        "auga = [ transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(k,1.0)),\n",
        "    #transforms.RandomHorizontalFlip(),\n",
        "    #transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "]) for k in [0.5, 0.6, 0.8 ]]\n",
        "\n",
        "augb = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    #transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "augc = [ transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    #transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(k),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "]) for k in [10, 15, 25, 40]]\n",
        "\n",
        "# model\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "\n",
        "# fixed unfreeze rate\n",
        "fixed_rate = 2.0\n",
        "\n",
        "# grid definitions\n",
        "augmentations = [True]\n",
        "freeze_bns    = [False]\n",
        "use_l2s       = [False]\n",
        "schedulers    = ['none']\n",
        "augies = [base_tf]\n",
        "# augies += auga\n",
        "# augies += [augb]\n",
        "augies = augc\n",
        "augies += [augb]\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "# running the grid\n",
        "for use_aug in augmentations:\n",
        "    for freeze_bn in freeze_bns:\n",
        "        for use_l2 in use_l2s:\n",
        "            for sched in schedulers:\n",
        "              for aug in augies:\n",
        "                  # update train transform\n",
        "                  train_ds.dataset.transform = aug if use_aug else base_tf\n",
        "                  train_loader = DataLoader(\n",
        "                      train_ds,\n",
        "                      batch_size=32,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4,\n",
        "                      pin_memory=True\n",
        "                  )\n",
        "                  print(f\"\\n>>> aug={use_aug}, freeze_bn={freeze_bn}, L2={use_l2}, sched={sched}\")\n",
        "\n",
        "                  # a) Instantiate with gradual unfreezing\n",
        "                  params = {'gradual_unfreezing': True, 'unfreezing_rate': fixed_rate}\n",
        "                  model = NeuralNetwork(\n",
        "                      basemodel,\n",
        "                      37,\n",
        "                      train_loader,\n",
        "                      val_loader,\n",
        "                      test_loader,\n",
        "                      unfreeze=1,\n",
        "                      parameters=params\n",
        "                  )\n",
        "                  model.model.to(device)\n",
        "\n",
        "                  # b) Optionally freeze BatchNorm layers\n",
        "                  if freeze_bn:\n",
        "                      for m in model.model.modules():\n",
        "                          if isinstance(m, nn.BatchNorm2d):\n",
        "                              m.eval()\n",
        "                              for p in m.parameters():\n",
        "                                  p.requires_grad = False\n",
        "\n",
        "                  # c) Build optimizer (head @1e-3, backbone @1e-4), optional L2\n",
        "                  wd = 1e-2 if use_l2 else 0.0\n",
        "                  head_p = list(model.model.fc.parameters())\n",
        "                  back_p = [\n",
        "                      p for n,p in model.model.named_parameters()\n",
        "                      if p.requires_grad and not n.startswith(\"fc\")\n",
        "                  ]\n",
        "                  model.optimizer = optim.AdamW([\n",
        "                      {'params': head_p, 'lr':1e-3, 'weight_decay':wd},\n",
        "                      {'params': back_p, 'lr':1e-4, 'weight_decay':wd},\n",
        "                  ])\n",
        "\n",
        "                  # d) Attach scheduler if desired\n",
        "                  if sched == 'steplr':\n",
        "                      model.scheduler = optim.lr_scheduler.StepLR(\n",
        "                          model.optimizer,\n",
        "                          step_size=5,\n",
        "                          gamma=0.1\n",
        "                      )\n",
        "                  elif sched == 'onecycle':\n",
        "                      total_steps = len(train_loader) * 10\n",
        "                      model.scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "                          model.optimizer,\n",
        "                          max_lr=[1e-3,1e-4],\n",
        "                          total_steps=total_steps,\n",
        "                          pct_start=0.3,\n",
        "                          anneal_strategy='cos'\n",
        "                      )\n",
        "                  else:\n",
        "                      model.scheduler = None\n",
        "\n",
        "                  # e) Train & record\n",
        "                  acc = model.train2(epochs=15)\n",
        "                  results.append((use_aug, freeze_bn, use_l2, sched, acc))\n",
        "\n",
        "# Summary for comparison\n",
        "print(\"\\n=== Strategy 2 Grid Search Results ===\")\n",
        "print(\"aug | freeze_bn | L2   | scheduler | TestAcc\")\n",
        "print(\"----|-----------|------|-----------|--------\")\n",
        "for aug, fb, l2, sch, acc in results:\n",
        "    print(f\"{str(aug):<3} | {str(fb):<9} | {str(l2):<4} | {sch:<9} | {acc:6.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f013e172-d1f0-43e0-969b-ada6fb408829",
      "metadata": {
        "id": "f013e172-d1f0-43e0-969b-ada6fb408829"
      },
      "source": [
        "## Imbalanced classes\n",
        "\n",
        "1. Load the annotations/trainval.txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5d5f38e-a763-4d5d-8d79-343db8b33475",
      "metadata": {
        "id": "e5d5f38e-a763-4d5d-8d79-343db8b33475"
      },
      "outputs": [],
      "source": [
        "# 0) Prepare names and label maps\n",
        "names = []\n",
        "breeds_map = {}\n",
        "\n",
        "with open(\"data/oxford-iiit-pet/annotations/trainval.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        name = parts[0]\n",
        "        class_id = int(parts[1]) - 1  # 0-indexed\n",
        "        names.append(name)\n",
        "        breeds_map[name] = class_id\n",
        "\n",
        "breed_to_id = {i: i for i in set(breeds_map.values())}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a77baf1",
      "metadata": {
        "id": "3a77baf1"
      },
      "source": [
        "Training with normal cross-entropy loss with limited data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9253ea5c",
      "metadata": {
        "id": "9253ea5c",
        "outputId": "885c7832-6eb5-4462-f18f-6664e2b0e6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Total samples in imbalanced dataset: 734\n",
            "Class distribution (samples, total, percentage):\n",
            "Abyssinian: 20/100 (20.0%)\n",
            "Bengal: 20/100 (20.0%)\n",
            "Birman: 20/100 (20.0%)\n",
            "Bombay: 19/96 (19.8%)\n",
            "British_Shorthair: 20/100 (20.0%)\n",
            "Egyptian_Mau: 18/93 (19.4%)\n",
            "Maine_Coon: 20/100 (20.0%)\n",
            "Persian: 20/100 (20.0%)\n",
            "Ragdoll: 20/100 (20.0%)\n",
            "Russian_Blue: 20/100 (20.0%)\n",
            "Siamese: 19/99 (19.2%)\n",
            "Sphynx: 20/100 (20.0%)\n",
            "american_bulldog: 20/100 (20.0%)\n",
            "american_pit_bull_terrier: 20/100 (20.0%)\n",
            "basset_hound: 20/100 (20.0%)\n",
            "beagle: 20/100 (20.0%)\n",
            "boxer: 20/100 (20.0%)\n",
            "chihuahua: 20/100 (20.0%)\n",
            "english_cocker_spaniel: 19/96 (19.8%)\n",
            "english_setter: 20/100 (20.0%)\n",
            "german_shorthaired: 20/100 (20.0%)\n",
            "great_pyrenees: 20/100 (20.0%)\n",
            "havanese: 20/100 (20.0%)\n",
            "japanese_chin: 20/100 (20.0%)\n",
            "keeshond: 20/100 (20.0%)\n",
            "leonberger: 20/100 (20.0%)\n",
            "miniature_pinscher: 20/100 (20.0%)\n",
            "newfoundland: 19/96 (19.8%)\n",
            "pomeranian: 20/100 (20.0%)\n",
            "pug: 20/100 (20.0%)\n",
            "saint_bernard: 20/100 (20.0%)\n",
            "samoyed: 20/100 (20.0%)\n",
            "scottish_terrier: 20/100 (20.0%)\n",
            "shiba_inu: 20/100 (20.0%)\n",
            "staffordshire_bull_terrier: 20/100 (20.0%)\n",
            "wheaten_terrier: 20/100 (20.0%)\n",
            "yorkshire_terrier: 20/100 (20.0%)\n",
            "\n",
            "==== Training Baseline Model with Standard Cross-Entropy Loss ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^    ^self = reduction.pickle.load(from_parent)^\n",
            "^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'MultiClassPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'MultiClassPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'MultiClassPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'MultiClassPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "DataLoader worker (pid(s) 2885) exited unexpectedly",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_queue\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m   1285\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39m], timeout)\n\u001b[1;32m    441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/connection.py:1135\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39mselect(timeout)\n\u001b[1;32m   1136\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     71\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 2885) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m==== Training Baseline Model with Standard Cross-Entropy Loss ====\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m model_base \u001b[39m=\u001b[39m make_model(unfreeze_layers\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m base_acc \u001b[39m=\u001b[39m model_base\u001b[39m.\u001b[39mtrain(epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m⮞ Baseline (last 5 layers) Test Acc: \u001b[39m\u001b[39m{\u001b[39;00mbase_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39m# Analyze the results - impact on the classes with limited data\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[4], line 78\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, epochs, path)\u001b[0m\n\u001b[1;32m     75\u001b[0m         L \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munfreeze_layers(L)\n\u001b[0;32m---> 78\u001b[0m tr_loss, tr_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_epoch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m val_loss, val_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_epoch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_loader, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m2d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Train: \u001b[39m\u001b[39m{\u001b[39;00mtr_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% | Val: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mNeuralNetwork.run_epoch\u001b[0;34m(self, loader, train)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain() \u001b[39mif\u001b[39;00m train \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m     44\u001b[0m total_loss, correct, total \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m---> 45\u001b[0m \u001b[39mfor\u001b[39;00m imgs, labs \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     46\u001b[0m     imgs, labs \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(device), labs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m train:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    734\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n\u001b[1;32m   1492\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1453\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1453\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_get_data()\n\u001b[1;32m   1454\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1455\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1297\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1296\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1297\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{\u001b[39;00mpids_str\u001b[39m}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1301\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2885) exited unexpectedly"
          ]
        }
      ],
      "source": [
        "## Train only using 20%\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        "    SubsetRandomSampler,\n",
        "    WeightedRandomSampler\n",
        ")\n",
        "\n",
        "# --- Ensure device is defined ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load trainval metadata\n",
        "tmp_train = OxfordIIITPet(root=\"data\", split=\"trainval\", target_types=\"category\", download=True)\n",
        "# Extract image stems: e.g. \"Abyssinian_1\"\n",
        "names = [p.stem for p in tmp_train._images]\n",
        "\n",
        "# Build mapping from stem → breed_name\n",
        "breeds_map = {n: n.rsplit(\"_\", 1)[0] for n in names}\n",
        "breed_names = sorted(set(breeds_map.values()))   # 37 unique breed strings\n",
        "breed_to_id = {b: i for i, b in enumerate(breed_names)}\n",
        "\n",
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nm = self.names[idx]\n",
        "        img_path = os.path.join(self.root, \"oxford-iiit-pet\", \"images\", nm + \".jpg\")\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[nm]]\n",
        "        return img, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "root = \"data\"\n",
        "# Full train/val dataset\n",
        "full_dataset = MultiClassPet(root, names, breeds_map, transform=transform)\n",
        "\n",
        "# Build 20%-per-class imbalanced index list\n",
        "class_idxs = defaultdict(list)\n",
        "for idx, nm in enumerate(names):\n",
        "    lbl = breed_to_id[breeds_map[nm]]\n",
        "    class_idxs[lbl].append(idx)\n",
        "\n",
        "# Create an artificially imbalanced dataset with some breeds at 20%\n",
        "imbalanced = []\n",
        "class_percentages = {}  # To track how many samples are used from each class\n",
        "\n",
        "for lbl, idxs in class_idxs.items():\n",
        "    # Use 20% of data for each breed\n",
        "    k = max(1, int(0.2 * len(idxs)))\n",
        "    selected_idxs = random.sample(idxs, k)\n",
        "    imbalanced += selected_idxs\n",
        "    class_percentages[breed_names[lbl]] = (k, len(idxs), k/len(idxs)*100)\n",
        "\n",
        "# Print dataset stats\n",
        "print(f\"Total samples in imbalanced dataset: {len(imbalanced)}\")\n",
        "print(\"Class distribution (samples, total, percentage):\")\n",
        "for breed, (count, total, percentage) in sorted(class_percentages.items()):\n",
        "    print(f\"{breed}: {count}/{total} ({percentage:.1f}%)\")\n",
        "\n",
        "# Split imbalanced list into train/val (80/20)\n",
        "random.shuffle(imbalanced)\n",
        "split = int(0.8 * len(imbalanced))\n",
        "train_idxs = imbalanced[:split]\n",
        "val_idxs = imbalanced[split:]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Test loader via torchvision to avoid missing stems\n",
        "test_ds = OxfordIIITPet(\n",
        "    root=root,\n",
        "    split=\"test\",\n",
        "    target_types=\"category\",\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define the NeuralNetwork class for training and evaluation\n",
        "def make_model(unfreeze_layers=5):\n",
        "    \"\"\"\n",
        "    Returns a NeuralNetwork instance fine-tuned on the\n",
        "    imbalanced train_loader/val_loader/test_loader.\n",
        "    \"\"\"\n",
        "    basemodel = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    m = NeuralNetwork(\n",
        "        basemodel,\n",
        "        len(breed_names),\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        unfreeze=unfreeze_layers\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# Train baseline model with normal cross-entropy loss\n",
        "print(\"\\n==== Training Baseline Model with Standard Cross-Entropy Loss ====\")\n",
        "model_base = make_model(unfreeze_layers=5)\n",
        "base_acc = model_base.train(epochs=10)\n",
        "print(f\"⮞ Baseline (last 5 layers) Test Acc: {base_acc:.2f}%\")\n",
        "\n",
        "# Analyze the results - impact on the classes with limited data\n",
        "print(\"\\n==== Analysis of Impact on Classes with Limited Data ====\")\n",
        "test_acc, per_class_acc, class_counts = model_base.evaluate()\n",
        "\n",
        "# Calculate correlation between class sample counts and accuracy\n",
        "class_samples = [class_percentages[breed][0] for breed in breed_names]\n",
        "correlation = np.corrcoef(class_samples, per_class_acc)[0, 1]\n",
        "print(f\"Correlation between class sample count and accuracy: {correlation:.4f}\")\n",
        "\n",
        "# Compare accuracy of classes with fewer samples vs classes with more samples\n",
        "# (Since all classes are at 20%, this might not show significant differences)\n",
        "print(\"\\nAverage accuracy across all classes: {:.2f}%\".format(sum(per_class_acc) / len(per_class_acc)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb56283",
      "metadata": {
        "id": "4bb56283"
      },
      "source": [
        "Strategy using weighted cross-entropy and over-sampling of the minority classes to compensate for the imbalanced training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6a519b9",
      "metadata": {
        "id": "f6a519b9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        "    SubsetRandomSampler,\n",
        "    WeightedRandomSampler\n",
        ")\n",
        "\n",
        "# --- Ensure device is defined ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load trainval metadata\n",
        "tmp_train = OxfordIIITPeFalse | True      | True | steplr    |  90.24%t(root=\"data\", split=\"trainval\", target_types=\"category\", download=True)\n",
        "# Extract image stems: e.g. \"Abyssinian_1\"\n",
        "names = [p.stem for p in tmp_train._images]\n",
        "\n",
        "# Build mapping from stem → breed_name\n",
        "breeds_map = {n: n.rsplit(\"_\", 1)[0] for n in names}\n",
        "breed_names = sorted(set(breeds_map.values()))   # 37 unique breed strings\n",
        "breed_to_id = {b: i for i, b in enumerate(breed_names)}\n",
        "\n",
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nm = self.names[idx]\n",
        "        img_path = os.path.join(self.root, \"oxford-iiit-pet\", \"images\", nm + \".jpg\")\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[nm]]\n",
        "        return img, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "root = \"data\"\n",
        "# Full train/val dataset\n",
        "full_dataset = MultiClassPet(root, names, breeds_map, transform=transform)\n",
        "\n",
        "# Build 20%-per-class imbalanced index list\n",
        "class_idxs = defaultdict(list)\n",
        "for idx, nm in enumerate(names):\n",
        "    lbl = breed_to_id[breeds_map[nm]]\n",
        "    class_idxs[lbl].append(idx)\n",
        "\n",
        "# Create an artificially imbalanced dataset with some breeds at 20%\n",
        "imbalanced = []\n",
        "class_percentages = {}  # To track how many samples are used from each class\n",
        "\n",
        "for lbl, idxs in class_idxs.items():\n",
        "    # Use 20% of data for each breed\n",
        "    k = max(1, int(0.2 * len(idxs)))\n",
        "    selected_idxs = random.sample(idxs, k)\n",
        "    imbalanced += selected_idxs\n",
        "    class_percentages[breed_names[lbl]] = (k, len(idxs), k/len(idxs)*100)\n",
        "\n",
        "# Print dataset stats\n",
        "print(f\"Total samples in imbalanced dataset: {len(imbalanced)}\")\n",
        "print(\"Class distribution (samples, total, percentage):\")\n",
        "for breed, (count, total, percentage) in sorted(class_percentages.items()):\n",
        "    print(f\"{breed}: {count}/{total} ({percentage:.1f}%)\")\n",
        "\n",
        "# Split imbalanced list into train/val (80/20)\n",
        "random.shuffle(imbalanced)\n",
        "split = int(0.8 * len(imbalanced))\n",
        "train_idxs = imbalanced[:split]\n",
        "val_idxs = imbalanced[split:]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Test loader via torchvision to avoid missing stems\n",
        "test_ds = OxfordIIITPet(\n",
        "    root=root,\n",
        "    split=\"test\",\n",
        "    target_types=\"category\",\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define the NeuralNetwork class for training and evaluation\n",
        "def make_model(unfreeze_layers=5):\n",
        "    \"\"\"\n",
        "    Returns a NeuralNetwork instance fine-tuned on the\n",
        "    imbalanced train_loader/val_loader/test_loader.\n",
        "    \"\"\"\n",
        "    basemodel = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    m = NeuralNetwork(\n",
        "        basemodel,\n",
        "        len(breed_names),\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        unfreeze=unfreeze_layers\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# Train baseline model with normal cross-entropy loss\n",
        "print(\"\\n==== Training Baseline Model with Standard Cross-Entropy Loss ====\")\n",
        "model_base = make_model(unfreeze_layers=5)\n",
        "base_acc = model_base.train(epochs=10)\n",
        "print(f\"⮞ Baseline (last 5 layers) Test Acc: {base_acc:.2f}%\")\n",
        "\n",
        "# Analyze the results - impact on the classes with limited data\n",
        "print(\"\\n==== Analysis of Impact on Classes with Limited Data ====\")\n",
        "test_acc, per_class_acc, class_counts = model_base.evaluate()\n",
        "baseline_per_class_acc = per_class_acc.copy()  # Store for comparison\n",
        "\n",
        "# Calculate correlation between class sample counts and accuracy\n",
        "class_samples = [class_percentages[breed][0] for breed in breed_names]\n",
        "correlation = np.corrcoef(class_samples, per_class_acc)[0, 1]\n",
        "print(f\"Correlation between class sample count and accuracy: {correlation:.4f}\")\n",
        "\n",
        "# Compare accuracy of classes with fewer samples vs classes with more samples\n",
        "# (Since all classes are at 20%, this might not show significant differences)\n",
        "print(\"\\nAverage accuracy across all classes: {:.2f}%\".format(sum(per_class_acc) / len(per_class_acc)))\n",
        "\n",
        "# ===== WEIGHTED CROSS-ENTROPY APPROACH =====\n",
        "print(\"\\n==== Training with Weighted Cross-Entropy Loss ====\")\n",
        "\n",
        "# Compute class weights inversely proportional to class frequencies\n",
        "# First, count samples per class in training set\n",
        "per_labels = [breed_to_id[breeds_map[names[i]]] for i in train_idxs]\n",
        "class_counts = torch.tensor([per_labels.count(c) for c in range(len(breed_names))], dtype=torch.float)\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * len(class_counts)  # Normalize\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "print(\"Class weights:\")\n",
        "for i, (breed, weight) in enumerate(zip(breed_names, class_weights.cpu().numpy())):\n",
        "    samples = per_labels.count(i)\n",
        "    print(f\"{breed}: {weight:.4f} (samples: {samples})\")\n",
        "\n",
        "# Train with weighted cross-entropy\n",
        "model_w = make_model(unfreeze_layers=5)\n",
        "model_w.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "model_w.optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_w.model.parameters()),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "w_acc = model_w.train(epochs=10)\n",
        "print(f\"⮞ Weighted CE (last 5 layers) Test Acc: {w_acc:.2f}%\")\n",
        "\n",
        "# Analyze per-class improvements\n",
        "_, w_per_class_acc, _ = model_w.evaluate()\n",
        "print(\"\\nPer-class accuracy changes (Weighted CE vs Baseline):\")\n",
        "for i, (breed, base_acc, w_acc) in enumerate(zip(breed_names, baseline_per_class_acc, w_per_class_acc)):\n",
        "    diff = w_acc - base_acc\n",
        "    print(f\"{breed}: {base_acc:.2f}% → {w_acc:.2f}% ({diff:+.2f}%)\")\n",
        "\n",
        "# ===== OVERSAMPLING APPROACH =====\n",
        "print(\"\\n==== Training with Oversampling of Minority Classes ====\")\n",
        "\n",
        "# Implement weighted random sampling to oversample minority classes\n",
        "sample_weights = [1.0 / class_counts[per_labels[i]].item() for i in range(len(train_idxs))]\n",
        "oversampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights) * 2, replacement=True)\n",
        "\n",
        "# Create a new dataloader with oversampling\n",
        "oversampled_train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=oversampler,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Train with oversampling\n",
        "model_o = make_model(unfreeze_layers=5)\n",
        "model_o.train_loader = oversampled_train_loader\n",
        "model_o.optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_o.model.parameters()),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "o_acc = model_o.train(epochs=10)\n",
        "print(f\"⮞ Oversampling (last 5 layers) Test Acc: {o_acc:.2f}%\")\n",
        "\n",
        "# Analyze per-class improvements\n",
        "_, o_per_class_acc, _ = model_o.evaluate()\n",
        "print(\"\\nPer-class accuracy changes (Oversampling vs Baseline):\")\n",
        "for i, (breed, base_acc, o_acc) in enumerate(zip(breed_names, baseline_per_class_acc, o_per_class_acc)):\n",
        "    diff = o_acc - base_acc\n",
        "    print(f\"{breed}: {base_acc:.2f}% → {o_acc:.2f}% ({diff:+.2f}%)\")\n",
        "\n",
        "# ===== COMPARE ALL APPROACHES =====\n",
        "print(\"\\n==== Overall Comparison of Approaches ====\")\n",
        "print(f\"Baseline Test Accuracy: {base_acc:.2f}%\")\n",
        "print(f\"Weighted CE Test Accuracy: {w_acc:.2f}%\")\n",
        "print(f\"Oversampling Test Accuracy: {o_acc:.2f}%\")\n",
        "\n",
        "# Plot comparison of per-class accuracies across methods\n",
        "plt.figure(figsize=(15, 10))\n",
        "x = np.arange(len(breed_names))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, baseline_per_class_acc, width, label='Baseline')\n",
        "plt.bar(x, w_per_class_acc, width, label='Weighted CE')\n",
        "plt.bar(x + width, o_per_class_acc, width, label='Oversampling')\n",
        "\n",
        "plt.xlabel('Breed')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Per-class Accuracy Comparison Across Methods')\n",
        "plt.xticks(x, breed_names, rotation=90)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('comparison_per_class.png')\n",
        "plt.close()\n",
        "\n",
        "# Calculate average improvement across all classes\n",
        "w_avg_improvement = sum(w - b for w, b in zip(w_per_class_acc, baseline_per_class_acc)) / len(breed_names)\n",
        "o_avg_improvement = sum(o - b for o, b in zip(o_per_class_acc, baseline_per_class_acc)) / len(breed_names)\n",
        "\n",
        "print(f\"\\nAverage per-class improvement with Weighted CE: {w_avg_improvement:.2f}%\")\n",
        "print(f\"Average per-class improvement with Oversampling: {o_avg_improvement:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7346dd-0698-4868-8b3b-4d0b3ba9bb15",
      "metadata": {
        "id": "ae7346dd-0698-4868-8b3b-4d0b3ba9bb15"
      },
      "source": [
        "# Extension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80eefc3e-2137-4ffe-a2bf-6a0da7ac2eeb",
      "metadata": {
        "id": "80eefc3e-2137-4ffe-a2bf-6a0da7ac2eeb"
      },
      "source": [
        "## Catastrophic Forgetting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392bb337-0e5c-4362-a55f-07cf3262525c",
      "metadata": {
        "id": "392bb337-0e5c-4362-a55f-07cf3262525c"
      },
      "outputs": [],
      "source": [
        "class Flowers102Dataset(Dataset):\n",
        "    def __init__(self, root, split='train', transform=None, download=False):\n",
        "        self.dataset = Flowers102(root=root, split=split, transform=transform, download=download)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb7366f-a05c-4262-88a3-ae7cf587615a",
      "metadata": {
        "id": "dbb7366f-a05c-4262-88a3-ae7cf587615a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553b48ec-32bb-48fd-e36f-57e193cb50ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 345M/345M [00:18<00:00, 19.1MB/s]\n",
            "100%|██████████| 502/502 [00:00<00:00, 1.19MB/s]\n",
            "100%|██████████| 15.0k/15.0k [00:00<00:00, 32.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_ds = Flowers102Dataset(\"data\", split='train', download=True, transform=transformIMG)\n",
        "val_ds = Flowers102Dataset(\"data\", split='val', download=True, transform=transformIMG)\n",
        "test_ds = Flowers102Dataset(\"data\", split='test', download=True, transform=transformIMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85819eb8-928a-4a4f-af05-11d6ca9f1c1c",
      "metadata": {
        "id": "85819eb8-928a-4a4f-af05-11d6ca9f1c1c"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6ba88d2-dc78-4926-9d7b-d076d93ba1de",
      "metadata": {
        "id": "a6ba88d2-dc78-4926-9d7b-d076d93ba1de"
      },
      "outputs": [],
      "source": [
        "\n",
        "def filter_first_n_classes(dataset, n_classes):\n",
        "\n",
        "    indices = [i for i, (_, label) in enumerate(dataset) if label < n_classes]\n",
        "    return Subset(dataset, indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e852fb42-0b60-4f37-8996-ffff5d9a0a5c",
      "metadata": {
        "id": "e852fb42-0b60-4f37-8996-ffff5d9a0a5c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "# Filter to only first 37 classes\n",
        "train_ds_flower = filter_first_n_classes(train_ds, 37)\n",
        "val_ds_flower = filter_first_n_classes(val_ds, 37)\n",
        "test_ds_flower = filter_first_n_classes(test_ds, 37)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84fad05-6c7b-444a-b7b5-5eb0a82b2bd3",
      "metadata": {
        "id": "c84fad05-6c7b-444a-b7b5-5eb0a82b2bd3"
      },
      "outputs": [],
      "source": [
        "#False | True      | True | steplr    |  90.24%\n",
        "use_aug = False\n",
        "freeze_bn    = True\n",
        "use_l2       = True\n",
        "sched    = 'steplr'\n",
        "fixed_rate = 2.0\n",
        "breed_names = sorted(set(breeds_map.values()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annnotations_dir = os.path.join(\"data\", \"oxford-iiit-pet\", \"annotations\")\n",
        "lines_for_files = open(os.path.join(annnotations_dir, \"list.txt\")).read().splitlines()[6:]\n",
        "breeds_map = {l.split()[0]:re.split(r'_\\d+', l.split()[0])[0] for l in lines_for_files}\n",
        "breed_to_id = {val: i for i, val in enumerate(sorted(set(breeds_map.values())))}\n",
        "id_to_breed = {v: k for k, v in breed_to_id.items()}\n",
        "\n",
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        img_path = os.path.join(\n",
        "            self.root, \"oxford-iiit-pet\", \"images\", name + \".jpg\"\n",
        "        )\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[name]]\n",
        "        return img, label\n",
        "\n",
        "full = MultiClassPet(\"data\", trainval_names, breeds_map, transform=transformIMG)\n",
        "n_val = int(0.1 * len(full))\n",
        "train_ds, val_ds = random_split(full, [len(full)-n_val, n_val])\n",
        "test_ds = MultiClassPet(\"data\", test_names, breeds_map, transform=transformIMG)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "OZBTi2LsPkrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db57598f-af5b-4ab7-83f1-e9b5ac17917e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "id": "OZBTi2LsPkrK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0997d69-6049-45d8-88bc-1911e921c503",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0997d69-6049-45d8-88bc-1911e921c503",
        "outputId": "6371332e-6374-43ca-87c9-c7e4defdad46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=steplr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train: 73.82% | Val: 89.67%\n",
            "Epoch  2 | Train: 94.17% | Val: 89.67%\n",
            "Epoch  3 | Train: 97.86% | Val: 91.30%\n",
            "Epoch  4 | Train: 99.21% | Val: 91.30%\n",
            "Epoch  5 | Train: 99.64% | Val: 91.03%\n",
            "Epoch  6 | Train: 99.79% | Val: 90.49%\n",
            "Epoch  7 | Train: 99.91% | Val: 91.58%\n",
            "Epoch  8 | Train: 99.97% | Val: 90.22%\n",
            "Epoch  9 | Train: 99.97% | Val: 91.30%\n",
            "Epoch 10 | Train: 100.00% | Val: 91.58%\n",
            "Epoch 11 | Train: 100.00% | Val: 91.03%\n",
            "Epoch 12 | Train: 99.97% | Val: 91.03%\n",
            "Epoch 13 | Train: 99.94% | Val: 90.49%\n",
            "Epoch 14 | Train: 99.97% | Val: 91.30%\n",
            "Epoch 15 | Train: 99.97% | Val: 90.49%\n",
            "{'primary': [], 'secondary': []}\n"
          ]
        }
      ],
      "source": [
        "# Train best model\n",
        "print(f\"\\n>>> aug={use_aug}, freeze_bn={freeze_bn}, L2={use_l2}, sched={sched}\")\n",
        "\n",
        "# a) Instantiate with gradual unfreezing\n",
        "params = {'gradual_unfreezing': False, 'unfreezing_rate': fixed_rate}\n",
        "model = NeuralNetwork(\n",
        "    basemodel,\n",
        "    len(breed_names),\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    unfreeze=6,\n",
        "    parameters=params\n",
        ")\n",
        "model.model.to(device)\n",
        "\n",
        "# b) Optionally freeze BatchNorm layers\n",
        "if freeze_bn:\n",
        "    for m in model.model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            m.eval()\n",
        "            for p in m.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "# c) Build optimizer (head @1e-3, backbone @1e-4), optional L2\n",
        "wd = 1e-2 if use_l2 else 0.0\n",
        "head_p = list(model.model.fc.parameters())\n",
        "back_p = [\n",
        "    p for n,p in model.model.named_parameters()\n",
        "    if p.requires_grad and not n.startswith(\"fc\")\n",
        "]\n",
        "model.optimizer = optim.AdamW([\n",
        "    {'params': head_p, 'lr':1e-3, 'weight_decay':wd},\n",
        "    {'params': back_p, 'lr':1e-4, 'weight_decay':wd},\n",
        "])\n",
        "\n",
        "# d) Attach scheduler if desired\n",
        "if sched == 'steplr':\n",
        "    model.scheduler = optim.lr_scheduler.StepLR(\n",
        "        model.optimizer,\n",
        "        step_size=5,\n",
        "        gamma=0.1\n",
        "    )\n",
        "elif sched == 'onecycle':\n",
        "    total_steps = len(train_loader) * 10\n",
        "    model.scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        model.optimizer,\n",
        "        max_lr=[1e-3,1e-4],\n",
        "        total_steps=total_steps,\n",
        "        pct_start=0.3,\n",
        "        anneal_strategy='cos'\n",
        "    )\n",
        "else:\n",
        "    model.scheduler = None\n",
        "\n",
        "# e) Train & record\n",
        "acc = model.train_catastrophic(epochs=15, tee=False)\n",
        "print(acc)\n",
        "bestmodel = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036d7ee0-7b43-4361-a341-9fc78e1c84d0",
      "metadata": {
        "id": "036d7ee0-7b43-4361-a341-9fc78e1c84d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169642fb-e077-4ff2-826c-40db53f83fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_loader_flower = DataLoader(train_ds_flower, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader_flower   = DataLoader(val_ds_flower,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader_flower  = DataLoader(test_ds_flower,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "back = copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "FAyoDl9fHQ7O"
      },
      "id": "FAyoDl9fHQ7O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train_loader = train_loader_flower\n",
        "model.val_loader = val_loader_flower\n",
        "model.test_loader = test_loader_flower"
      ],
      "metadata": {
        "id": "LnAdRw5iL-sh"
      },
      "id": "LnAdRw5iL-sh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ed37fd-be71-471d-8f65-55f6c6a6fdbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "f8ed37fd-be71-471d-8f65-55f6c6a6fdbf",
        "outputId": "58cd6e49-e619-4b9a-a9cd-d3b222b77651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train: 10.81% | Val: 8.11%\n",
            "Test Accuracy: 11.37%\n",
            "Test Accuracy: 4.09%\n",
            "Epoch  2 | Train: 30.27% | Val: 35.14%\n",
            "Test Accuracy: 26.65%\n",
            "Test Accuracy: 4.50%\n",
            "Epoch  3 | Train: 41.89% | Val: 34.59%\n",
            "Test Accuracy: 36.18%\n",
            "Test Accuracy: 4.12%\n",
            "Epoch  4 | Train: 52.16% | Val: 57.30%\n",
            "Test Accuracy: 61.83%\n",
            "Test Accuracy: 4.06%\n",
            "Epoch  5 | Train: 74.86% | Val: 74.86%\n",
            "Test Accuracy: 70.36%\n",
            "Test Accuracy: 4.72%\n",
            "Epoch  6 | Train: 84.32% | Val: 72.16%\n",
            "Test Accuracy: 73.06%\n",
            "Test Accuracy: 4.28%\n",
            "Epoch  7 | Train: 90.00% | Val: 73.24%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-0cd32abfd814>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_catastrophic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m model.optimizer = optim.AdamW([\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhead_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-18dd3f1dcaed>\u001b[0m in \u001b[0;36mtrain_catastrophic\u001b[0;34m(self, epochs, path, tee, test_loader)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtee\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"primary\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"secondary\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-18dd3f1dcaed>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(self, test_loader)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy: {test_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-18dd3f1dcaed>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, loader, train)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.optimizer = optim.AdamW([\n",
        "    {'params': head_p, 'lr':1e-1, 'weight_decay':wd},\n",
        "    {'params': back_p, 'lr':1e-2, 'weight_decay':wd},\n",
        "])\n",
        "model.scheduler = None\n",
        "model.train_catastrophic(epochs=10, test_loader=test_loader)\n",
        "model.optimizer = optim.AdamW([\n",
        "    {'params': head_p, 'lr':1e-3, 'weight_decay':wd},\n",
        "    {'params': back_p, 'lr':1e-4, 'weight_decay':wd},\n",
        "])\n",
        "model.scheduler = optim.lr_scheduler.StepLR(\n",
        "        model.optimizer,\n",
        "        step_size=5,\n",
        "        gamma=0.1\n",
        "    )\n",
        "model.train_catastrophic(epochs=20, test_loader=test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train_loader = train_loader\n",
        "model.val_loader = val_loader\n",
        "model.test_loader = test_loader"
      ],
      "metadata": {
        "id": "6bR5YgSH0d3k"
      },
      "id": "6bR5YgSH0d3k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.test_model()"
      ],
      "metadata": {
        "id": "-DSmT9z-3Wiu"
      },
      "id": "-DSmT9z-3Wiu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkn-3T6m3gU6"
      },
      "id": "zkn-3T6m3gU6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}