{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b501857-78ba-481b-ab7a-3f5b4bc144a4",
      "metadata": {
        "id": "5b501857-78ba-481b-ab7a-3f5b4bc144a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.datasets import OxfordIIITPet, Flowers102\n",
        "import scipy\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a73f1dd-2fc0-45cb-a11c-1c0cc532a9a0",
      "metadata": {
        "id": "3a73f1dd-2fc0-45cb-a11c-1c0cc532a9a0"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5b801c40-5114-4193-8892-16c62225204f",
      "metadata": {
        "id": "5b801c40-5114-4193-8892-16c62225204f"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self, basemodel, output, train_loader, val_loader, test_loader, unfreeze=0, parameters=None):\n",
        "        # Init model\n",
        "        self.model = copy.deepcopy(basemodel)\n",
        "        # changing the fully connected layer\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, output)\n",
        "        # Unfreeze the L last layers and fully connected last layer\n",
        "        self.unfreeze_layers(unfreeze)\n",
        "        self.model = self.model.to(device)\n",
        "\n",
        "        self.optimizer = optim.Adam([{\"params\": self.model.fc.parameters(),\"lr\": 1e-3, \"weight_decay\": 1e-4},])\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        self.parameters = parameters if parameters is not None else {}\n",
        "\n",
        "\n",
        "    def unfreeze_layers(self, L):\n",
        "      # freezing all layers\n",
        "      for p in self.model.parameters():\n",
        "          p.requires_grad = False\n",
        "\n",
        "      layer = 0\n",
        "      # unfreeze last L layers and fully connected layer\n",
        "      for name, p in reversed(list(self.model.named_parameters())):\n",
        "        if layer < L+1:\n",
        "          if not name.endswith(\"bias\"):\n",
        "            layer += 1\n",
        "          p.requires_grad = True\n",
        "\n",
        "    def check_trainable_layers(self):\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(f\"{name} requires grad\")\n",
        "            else:\n",
        "                print(f\"{name} does NOT require grad\")\n",
        "\n",
        "\n",
        "    def run_epoch(self, loader, train=True):\n",
        "        self.model.train() if train else self.model.eval()\n",
        "        total_loss, correct, total = 0.0, 0, 0\n",
        "        for imgs, labs in loader:\n",
        "            imgs, labs = imgs.to(device), labs.to(device)\n",
        "            if train:\n",
        "                self.optimizer.zero_grad()\n",
        "            logits = self.model(imgs)\n",
        "            loss   = self.criterion(logits, labs)\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            preds      = logits.argmax(dim=1)\n",
        "            correct   += (preds == labs).sum().item()\n",
        "            total     += imgs.size(0)\n",
        "        return total_loss/total, correct/total*100\n",
        "\n",
        "\n",
        "    def test_model(self):\n",
        "      test_loss, test_acc = self.run_epoch(self.test_loader, train=False)\n",
        "      print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "      return test_acc\n",
        "\n",
        "    def train(self, epochs, path=\"model.pth\"):\n",
        "      best_val_acc = 0.0\n",
        "      for epoch in range(1,epochs+1):\n",
        "\n",
        "        # gradually unfreeze layers for strategy 2 according to rate parameter\n",
        "        if 'gradual_unfreezing' in self.parameters:\n",
        "            uf_rate = 1 if not 'unfreezing_rate' in self.parameters else parameters['unfreezing_rate']\n",
        "            L = np.floor(uf_rate*(1+epoch)) # allow for rates < 1\n",
        "            if L < 1:\n",
        "                L = 1\n",
        "            self.unfreeze_layers(L)\n",
        "\n",
        "        tr_loss, tr_acc = self.run_epoch(self.train_loader, train=True)\n",
        "        val_loss, val_acc = self.run_epoch(self.val_loader, train=False)\n",
        "        print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(self.model.state_dict(), path)\n",
        "\n",
        "      test_acc = self.test_model()\n",
        "      return test_acc\n",
        "\n",
        "    def train2(self, epochs, path=\"model.pth\"):\n",
        "        best_val_acc = 0.0\n",
        "        for epoch in range(1, epochs+1):\n",
        "            # Gradual unfreezing\n",
        "            if self.parameters.get('gradual_unfreezing', False):\n",
        "                uf_rate = self.parameters.get('unfreezing_rate', 1)\n",
        "                L = int(np.floor(uf_rate * (epoch + 1)))\n",
        "                if L < 1:\n",
        "                    L = 1\n",
        "                self.unfreeze_layers(L)\n",
        "\n",
        "            tr_loss, tr_acc = self.run_epoch(self.train_loader, train=True)\n",
        "            val_loss, val_acc = self.run_epoch(self.val_loader, train=False)\n",
        "            print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "\n",
        "            # Save best\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(self.model.state_dict(), path)\n",
        "\n",
        "            # Step scheduler if present\n",
        "            if hasattr(self, 'scheduler') and self.scheduler is not None:\n",
        "                self.scheduler.step()\n",
        "\n",
        "        return self.test_model()\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Track per-class accuracy\n",
        "        class_correct = [0] * len(breed_names)\n",
        "        class_total = [0] * len(breed_names)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in self.test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                # Overall accuracy\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "                # Per-class accuracy\n",
        "                for i in range(len(targets)):\n",
        "                    label = targets[i].item()\n",
        "                    class_total[label] += 1\n",
        "                    if predicted[i] == targets[i]:\n",
        "                        class_correct[label] += 1\n",
        "\n",
        "        overall_acc = 100.0 * correct / total\n",
        "        per_class_acc = [(100.0 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0.0)\n",
        "                          for i in range(len(breed_names))]\n",
        "\n",
        "        return overall_acc, per_class_acc, class_total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7479cf3f-4699-4cb4-ab82-010e8ddb2635",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7479cf3f-4699-4cb4-ab82-010e8ddb2635",
        "outputId": "335eb653-0d4d-4917-f786-81ba6faad518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:35<00:00, 22.1MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 11.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset OxfordIIITPet\n",
              "    Number of datapoints: 3680\n",
              "    Root location: data"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "OxfordIIITPet(root=\"data\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6d431898-55ce-49dc-91f9-7dceed1fec13",
      "metadata": {
        "id": "6d431898-55ce-49dc-91f9-7dceed1fec13"
      },
      "outputs": [],
      "source": [
        "annnotations_dir = os.path.join(\"data\", \"oxford-iiit-pet\", \"annotations\")\n",
        "lines_for_files = open(os.path.join(annnotations_dir, \"list.txt\")).read().splitlines()[6:]\n",
        "species_map = {l.split()[0]: int(l.split()[2]) for l in lines_for_files}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "66c852e4-7055-4c82-97c9-3e99e736d052",
      "metadata": {
        "id": "66c852e4-7055-4c82-97c9-3e99e736d052"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(annnotations_dir, \"trainval.txt\")) as f:\n",
        "    trainval_names = [l.split()[0] for l in f if l.strip()]\n",
        "with open(os.path.join(annnotations_dir, \"test.txt\")) as f:\n",
        "    test_names = [l.split()[0] for l in f if l.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "145827fc-38aa-4e39-8049-e5640ed7cbe0",
      "metadata": {
        "id": "145827fc-38aa-4e39-8049-e5640ed7cbe0"
      },
      "outputs": [],
      "source": [
        "class BinaryPet(Dataset):\n",
        "    def __init__(self, root, names, species_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.species_map = species_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        img_path = os.path.join(\n",
        "            self.root, \"oxford-iiit-pet\", \"images\", name + \".jpg\"\n",
        "        )\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.species_map[name] - 1  # 1→cat→0, 2→dog→1\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c36d1a7d-78bc-4a58-88fa-d26a037d9f99",
      "metadata": {
        "id": "c36d1a7d-78bc-4a58-88fa-d26a037d9f99"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2832243b-6442-4bc5-9926-f690647a5658",
      "metadata": {
        "id": "2832243b-6442-4bc5-9926-f690647a5658"
      },
      "outputs": [],
      "source": [
        "transformIMG = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "036a6c76-bc3b-44b8-acf1-50893a352c62",
      "metadata": {
        "id": "036a6c76-bc3b-44b8-acf1-50893a352c62"
      },
      "outputs": [],
      "source": [
        "full = BinaryPet(\"data\", trainval_names, species_map, transform=transformIMG)\n",
        "n_val = int(0.1 * len(full))\n",
        "train_ds, val_ds = random_split(full, [len(full)-n_val, n_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "55a8eecd-7f70-4223-9218-6023fff72e3d",
      "metadata": {
        "id": "55a8eecd-7f70-4223-9218-6023fff72e3d"
      },
      "outputs": [],
      "source": [
        "test_ds = BinaryPet(\"data\", test_names, species_map, transform=transformIMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6d2e5899-3a81-461a-bd4a-b1a5c850cb8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d2e5899-3a81-461a-bd4a-b1a5c850cb8a",
        "outputId": "389ce956-38eb-4e45-bed9-3eb9dfd4d87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0260f07f-a459-4d27-9f5d-bb6c1eee575f",
      "metadata": {
        "id": "0260f07f-a459-4d27-9f5d-bb6c1eee575f"
      },
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0460ecda-9f16-4270-b7e8-a988442797c5",
      "metadata": {
        "id": "0460ecda-9f16-4270-b7e8-a988442797c5"
      },
      "source": [
        "## Model Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7ed618ac-37af-464d-a735-3223b0dbc071",
      "metadata": {
        "id": "7ed618ac-37af-464d-a735-3223b0dbc071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb9afe7-af6c-4625-9375-d42fd8d6b0dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 151MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "# freezing all\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "# changing the fully connected layer\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "# Unfreeze the fully connected last layer\n",
        "for name, p in model.named_parameters():\n",
        "    if name.startswith(\"fc\"):\n",
        "        p.requires_grad = True\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c32651b9-0f2c-4736-b3db-10fbb6486f70",
      "metadata": {
        "id": "c32651b9-0f2c-4736-b3db-10fbb6486f70"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "55100d27-1851-43fb-8039-3d1cd7ab6b6c",
      "metadata": {
        "id": "55100d27-1851-43fb-8039-3d1cd7ab6b6c"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam([\n",
        "    {\"params\": model.fc.parameters(),     \"lr\": 1e-3, \"weight_decay\": 1e-4},\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "428edba5-4df2-4d37-9f61-18da01050f30",
      "metadata": {
        "id": "428edba5-4df2-4d37-9f61-18da01050f30",
        "outputId": "491b6bf2-6d45-4fa0-a658-7412b0d85015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d1cdba-bc33-42a1-8f75-3dd5de75288e",
      "metadata": {
        "id": "f0d1cdba-bc33-42a1-8f75-3dd5de75288e"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1dcabae-3911-4cd2-96ac-52e4c0158183",
      "metadata": {
        "id": "d1dcabae-3911-4cd2-96ac-52e4c0158183"
      },
      "outputs": [],
      "source": [
        "def run_epoch(model, loader, train=True, criterion=criterion, optimizer=optimizer): # TODO: Include criterion and optimizer in a neater way\n",
        "    model.train() if train else model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    for imgs, labs in loader:\n",
        "        imgs, labs = imgs.to(device), labs.to(device)\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss   = criterion(logits, labs)\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "        preds      = logits.argmax(dim=1)\n",
        "        correct   += (preds == labs).sum().item()\n",
        "        total     += imgs.size(0)\n",
        "    return total_loss/total, correct/total*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e5a381-42b4-4676-8d65-1d1a7e8bebc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30e5a381-42b4-4676-8d65-1d1a7e8bebc7",
        "outputId": "22c5b5eb-ff84-4a2d-f23a-e4d8e586a618"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/youngbinpyo/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'BinaryPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m best_val_acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m25\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     tr_loss, tr_acc \u001b[39m=\u001b[39m run_epoch(model, train_loader, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     val_loss, val_acc \u001b[39m=\u001b[39m run_epoch(model, val_loader, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m2d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Train: \u001b[39m\u001b[39m{\u001b[39;00mtr_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% | Val: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(model, loader, train, criterion, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mtrain() \u001b[39mif\u001b[39;00m train \u001b[39melse\u001b[39;00m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m total_loss, correct, total \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m imgs, labs \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m      5\u001b[0m     imgs, labs \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(device), labs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m train:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:493\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    492\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_iterator()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:424\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 424\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1171\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1164\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1171\u001b[0m w\u001b[39m.\u001b[39mstart()\n\u001b[1;32m   1172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Popen(\u001b[39mself\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39mget_context()\u001b[39m.\u001b[39mProcess\u001b[39m.\u001b[39m_Popen(process_obj)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/context.py:289\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    288\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(process_obj)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_launch(process_obj)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39mwrite(fp\u001b[39m.\u001b[39mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_val_acc = 0.0\n",
        "for epoch in range(1, 25):\n",
        "    tr_loss, tr_acc = run_epoch(model, train_loader, train=True)\n",
        "    val_loss, val_acc = run_epoch(model, val_loader, train=False)\n",
        "    print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_binary_resnet34.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32b86600-f7a0-4cc0-afb1-3e954c369c90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32b86600-f7a0-4cc0-afb1-3e954c369c90",
        "outputId": "f6752014-bd4b-4e6c-e54e-88b08ee65910"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best_binary_resnet34.pth'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mbest_binary_resnet34.pth\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      2\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m run_epoch(model, test_loader, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _opener[IO[\u001b[39mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    760\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike[\u001b[39mstr\u001b[39m]], mode: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39m(name, mode))\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_binary_resnet34.pth'"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_binary_resnet34.pth\"))\n",
        "test_loss, test_acc = run_epoch(model, test_loader, train=False)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d5105c-c2ad-4f6c-9691-8a633635463e",
      "metadata": {
        "id": "96d5105c-c2ad-4f6c-9691-8a633635463e"
      },
      "source": [
        "# Multi Class Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a105be8d-b6d6-469d-a4df-4b5b02ef6bc8",
      "metadata": {
        "id": "a105be8d-b6d6-469d-a4df-4b5b02ef6bc8"
      },
      "source": [
        "TODO:\n",
        "* different learning rates/learning rate schedulers for different layers\n",
        "* data augmentation\n",
        "* Effect of fine-tuning batch-norm parameters\n",
        "* Train with Imbalanced Dataset\n",
        "* Testing and logging of the above\n",
        "* gradual_unfreezing testing\n",
        "* unfreezing l layers at a time testing\n",
        "  \n",
        "DONE:\n",
        "* gradual_unfreezing\n",
        "* unfreezing l layers at a time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60b2b63a-6c41-4a5b-b02d-f978f488fc29",
      "metadata": {
        "id": "60b2b63a-6c41-4a5b-b02d-f978f488fc29"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cef39a61-b139-4313-8f38-abdd1179c503",
      "metadata": {
        "id": "cef39a61-b139-4313-8f38-abdd1179c503"
      },
      "outputs": [],
      "source": [
        "annnotations_dir = os.path.join(\"data\", \"oxford-iiit-pet\", \"annotations\")\n",
        "lines_for_files = open(os.path.join(annnotations_dir, \"list.txt\")).read().splitlines()[6:]\n",
        "breeds_map = {l.split()[0]:re.split(r'_\\d+', l.split()[0])[0] for l in lines_for_files}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "899dfeff-7a12-4688-8387-0c1f366ee339",
      "metadata": {
        "id": "899dfeff-7a12-4688-8387-0c1f366ee339"
      },
      "outputs": [],
      "source": [
        "breed_to_id = {val: i for i, val in enumerate(sorted(set(breeds_map.values())))}\n",
        "id_to_breed = {v: k for k, v in breed_to_id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "eebff8d5-3e15-4157-a97d-4ba02ee3c76a",
      "metadata": {
        "id": "eebff8d5-3e15-4157-a97d-4ba02ee3c76a"
      },
      "outputs": [],
      "source": [
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names[idx]\n",
        "        img_path = os.path.join(\n",
        "            self.root, \"oxford-iiit-pet\", \"images\", name + \".jpg\"\n",
        "        )\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[name]]\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1c7ff718-7080-4814-8bbd-ff42a8f04f85",
      "metadata": {
        "id": "1c7ff718-7080-4814-8bbd-ff42a8f04f85"
      },
      "outputs": [],
      "source": [
        "full = MultiClassPet(\"data\", trainval_names, breeds_map, transform=transformIMG)\n",
        "n_val = int(0.1 * len(full))\n",
        "train_ds, val_ds = random_split(full, [len(full)-n_val, n_val])\n",
        "test_ds = MultiClassPet(\"data\", test_names, breeds_map, transform=transformIMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f3de2fcd-22e5-4c98-8cb4-0bc40dd99953",
      "metadata": {
        "id": "f3de2fcd-22e5-4c98-8cb4-0bc40dd99953"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb96530-c12c-44f0-ac11-a2c554314e5d",
      "metadata": {
        "id": "2fb96530-c12c-44f0-ac11-a2c554314e5d"
      },
      "source": [
        "## Model Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b159b267-e687-41fc-b7f9-066b5d96848c",
      "metadata": {
        "id": "b159b267-e687-41fc-b7f9-066b5d96848c"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27d260d-a15a-4003-b0f2-a2ecbc50297b",
      "metadata": {
        "id": "d27d260d-a15a-4003-b0f2-a2ecbc50297b"
      },
      "source": [
        "-> Strategy 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WJbuKDtJaKgA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "WJbuKDtJaKgA",
        "outputId": "ff511d4f-f7eb-4044-d96f-01e38c72818c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training model with 1 last layers trainable\n",
            "Epoch  1 | Train: 59.81% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.04% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.43% | Val: 90.22%\n",
            "Epoch  4 | Train: 93.39% | Val: 91.03%\n",
            "Epoch  5 | Train: 93.99% | Val: 92.12%\n",
            "Epoch  6 | Train: 94.69% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.20% | Val: 91.03%\n",
            "Epoch  8 | Train: 96.07% | Val: 90.76%\n",
            "Epoch  9 | Train: 96.68% | Val: 91.58%\n",
            "Epoch 10 | Train: 96.92% | Val: 92.39%\n",
            "Test Accuracy: 89.45%\n",
            "Start training model with 2 last layers trainable\n",
            "Epoch  1 | Train: 60.90% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.41% | Val: 88.32%\n",
            "Epoch  3 | Train: 91.52% | Val: 90.22%\n",
            "Epoch  4 | Train: 91.94% | Val: 89.13%\n",
            "Epoch  5 | Train: 94.41% | Val: 90.49%\n",
            "Epoch  6 | Train: 94.63% | Val: 91.30%\n",
            "Epoch  7 | Train: 95.95% | Val: 90.22%\n",
            "Epoch  8 | Train: 95.83% | Val: 91.85%\n",
            "Epoch  9 | Train: 96.53% | Val: 89.95%\n",
            "Epoch 10 | Train: 97.31% | Val: 89.40%\n",
            "Test Accuracy: 89.32%\n",
            "Start training model with 3 last layers trainable\n",
            "Epoch  1 | Train: 60.75% | Val: 85.60%\n",
            "Epoch  2 | Train: 88.35% | Val: 88.32%\n",
            "Epoch  3 | Train: 91.39% | Val: 88.32%\n",
            "Epoch  4 | Train: 92.54% | Val: 88.86%\n",
            "Epoch  5 | Train: 94.54% | Val: 89.13%\n",
            "Epoch  6 | Train: 95.02% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.26% | Val: 89.40%\n",
            "Epoch  8 | Train: 96.14% | Val: 89.40%\n",
            "Epoch  9 | Train: 96.32% | Val: 90.49%\n",
            "Epoch 10 | Train: 96.62% | Val: 89.40%\n",
            "Test Accuracy: 89.70%\n",
            "Start training model with 4 last layers trainable\n",
            "Epoch  1 | Train: 61.20% | Val: 85.05%\n",
            "Epoch  2 | Train: 87.29% | Val: 88.32%\n",
            "Epoch  3 | Train: 91.43% | Val: 90.76%\n",
            "Epoch  4 | Train: 92.51% | Val: 91.58%\n",
            "Epoch  5 | Train: 94.38% | Val: 89.95%\n",
            "Epoch  6 | Train: 94.75% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.41% | Val: 92.12%\n",
            "Epoch  8 | Train: 95.71% | Val: 91.58%\n",
            "Epoch  9 | Train: 96.62% | Val: 90.49%\n",
            "Epoch 10 | Train: 96.50% | Val: 89.95%\n",
            "Test Accuracy: 89.42%\n",
            "Start training model with 5 last layers trainable\n",
            "Epoch  1 | Train: 60.18% | Val: 86.68%\n",
            "Epoch  2 | Train: 88.56% | Val: 88.59%\n",
            "Epoch  3 | Train: 91.70% | Val: 89.40%\n",
            "Epoch  4 | Train: 93.15% | Val: 88.59%\n",
            "Epoch  5 | Train: 93.36% | Val: 89.40%\n",
            "Epoch  6 | Train: 94.99% | Val: 89.40%\n",
            "Epoch  7 | Train: 94.99% | Val: 90.76%\n",
            "Epoch  8 | Train: 96.26% | Val: 89.67%\n",
            "Epoch  9 | Train: 97.16% | Val: 91.30%\n",
            "Epoch 10 | Train: 97.16% | Val: 90.22%\n",
            "Test Accuracy: 89.70%\n",
            "Start training model with 6 last layers trainable\n",
            "Epoch  1 | Train: 62.71% | Val: 85.33%\n",
            "Epoch  2 | Train: 88.22% | Val: 86.14%\n",
            "Epoch  3 | Train: 91.43% | Val: 91.03%\n",
            "Epoch  4 | Train: 92.39% | Val: 91.03%\n",
            "Epoch  5 | Train: 94.02% | Val: 91.58%\n",
            "Epoch  6 | Train: 94.84% | Val: 92.12%\n",
            "Epoch  7 | Train: 95.47% | Val: 89.67%\n",
            "Epoch  8 | Train: 95.92% | Val: 89.40%\n",
            "Epoch  9 | Train: 96.32% | Val: 89.95%\n",
            "Epoch 10 | Train: 96.80% | Val: 90.49%\n",
            "Test Accuracy: 90.24%\n",
            "Start training model with 7 last layers trainable\n",
            "Epoch  1 | Train: 60.08% | Val: 83.97%\n",
            "Epoch  2 | Train: 88.83% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.55% | Val: 89.40%\n",
            "Epoch  4 | Train: 93.18% | Val: 89.13%\n",
            "Epoch  5 | Train: 94.11% | Val: 90.49%\n",
            "Epoch  6 | Train: 94.72% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.50% | Val: 89.95%\n",
            "Epoch  8 | Train: 95.65% | Val: 90.22%\n",
            "Epoch  9 | Train: 96.65% | Val: 88.59%\n",
            "Epoch 10 | Train: 96.83% | Val: 89.95%\n",
            "Test Accuracy: 89.26%\n",
            "Start training model with 8 last layers trainable\n",
            "Epoch  1 | Train: 58.91% | Val: 83.15%\n",
            "Epoch  2 | Train: 87.98% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.46% | Val: 88.32%\n",
            "Epoch  4 | Train: 92.63% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.99% | Val: 92.39%\n",
            "Epoch  6 | Train: 94.81% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.41% | Val: 90.76%\n",
            "Epoch  8 | Train: 96.41% | Val: 90.49%\n",
            "Epoch  9 | Train: 96.86% | Val: 90.22%\n",
            "Epoch 10 | Train: 96.89% | Val: 90.22%\n",
            "Test Accuracy: 89.37%\n",
            "Start training model with 9 last layers trainable\n",
            "Epoch  1 | Train: 59.75% | Val: 84.51%\n",
            "Epoch  2 | Train: 87.83% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.18% | Val: 89.13%\n",
            "Epoch  4 | Train: 92.84% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.96% | Val: 91.03%\n",
            "Epoch  6 | Train: 94.35% | Val: 90.49%\n",
            "Epoch  7 | Train: 95.71% | Val: 91.58%\n",
            "Epoch  8 | Train: 96.44% | Val: 91.85%\n",
            "Epoch  9 | Train: 96.44% | Val: 89.40%\n",
            "Epoch 10 | Train: 96.74% | Val: 90.76%\n",
            "Test Accuracy: 89.72%\n"
          ]
        }
      ],
      "source": [
        "# Strategy 1: train with l layers unfrozen simultaneously\n",
        "accs = []\n",
        "for L in range(1, 10):\n",
        "  print(f\"Start training model with {L} last layers trainable\")\n",
        "  modelmulti = NeuralNetwork(basemodel, 37, train_loader, val_loader, test_loader, unfreeze=L)\n",
        "  accs.append(modelmulti.train(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c430ee-62c5-4d22-8ee1-2692741d9810",
      "metadata": {
        "id": "05c430ee-62c5-4d22-8ee1-2692741d9810",
        "outputId": "c3acdbcb-7345-47c6-dfaf-a0dd72614c00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=False\n",
            "Epoch  1 | Train: 74.61% | Val: 86.14%\n",
            "Epoch  2 | Train: 94.11% | Val: 89.95%\n",
            "Epoch  3 | Train: 97.49% | Val: 89.40%\n",
            "Epoch  4 | Train: 99.49% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.61% | Val: 89.95%\n",
            "Epoch  6 | Train: 99.64% | Val: 90.49%\n",
            "Epoch  7 | Train: 99.88% | Val: 90.22%\n",
            "Epoch  8 | Train: 99.94% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.82% | Val: 89.13%\n",
            "Epoch 10 | Train: 99.91% | Val: 89.40%\n",
            "Test Accuracy: 89.62%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=True\n",
            "Epoch  1 | Train: 75.91% | Val: 88.86%\n",
            "Epoch  2 | Train: 94.75% | Val: 88.59%\n",
            "Epoch  3 | Train: 97.83% | Val: 88.32%\n",
            "Epoch  4 | Train: 99.12% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.55% | Val: 89.67%\n",
            "Epoch  6 | Train: 99.85% | Val: 90.22%\n",
            "Epoch  7 | Train: 99.91% | Val: 89.40%\n",
            "Epoch  8 | Train: 99.97% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.97% | Val: 89.95%\n",
            "Epoch 10 | Train: 99.97% | Val: 90.22%\n",
            "Test Accuracy: 90.87%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=False\n",
            "Epoch  1 | Train: 74.12% | Val: 88.86%\n",
            "Epoch  2 | Train: 94.14% | Val: 90.49%\n",
            "Epoch  3 | Train: 97.77% | Val: 89.95%\n",
            "Epoch  4 | Train: 99.09% | Val: 88.86%\n",
            "Epoch  5 | Train: 99.70% | Val: 90.49%\n",
            "Epoch  6 | Train: 99.85% | Val: 91.30%\n",
            "Epoch  7 | Train: 99.88% | Val: 90.76%\n",
            "Epoch  8 | Train: 99.94% | Val: 89.13%\n",
            "Epoch  9 | Train: 99.91% | Val: 90.49%\n",
            "Epoch 10 | Train: 99.82% | Val: 90.22%\n",
            "Test Accuracy: 90.38%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=True\n",
            "Epoch  1 | Train: 74.43% | Val: 87.23%\n",
            "Epoch  2 | Train: 93.78% | Val: 86.41%\n",
            "Epoch  3 | Train: 97.68% | Val: 89.40%\n",
            "Epoch  4 | Train: 98.94% | Val: 90.76%\n",
            "Epoch  5 | Train: 99.61% | Val: 89.95%\n",
            "Epoch  6 | Train: 99.88% | Val: 90.76%\n",
            "Epoch  7 | Train: 99.97% | Val: 91.03%\n",
            "Epoch  8 | Train: 99.97% | Val: 90.76%\n",
            "Epoch  9 | Train: 99.94% | Val: 91.30%\n",
            "Epoch 10 | Train: 100.00% | Val: 90.49%\n",
            "Test Accuracy: 90.57%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=False\n",
            "Epoch  1 | Train: 73.31% | Val: 86.96%\n",
            "Epoch  2 | Train: 94.08% | Val: 88.32%\n",
            "Epoch  3 | Train: 98.01% | Val: 86.68%\n",
            "Epoch  4 | Train: 99.06% | Val: 88.32%\n",
            "Epoch  5 | Train: 99.09% | Val: 88.32%\n",
            "Epoch  6 | Train: 99.91% | Val: 88.86%\n",
            "Epoch  7 | Train: 99.73% | Val: 88.59%\n",
            "Epoch  8 | Train: 99.97% | Val: 88.86%\n",
            "Epoch  9 | Train: 99.97% | Val: 87.77%\n",
            "Epoch 10 | Train: 99.91% | Val: 89.13%\n",
            "Test Accuracy: 90.30%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=True\n",
            "Epoch  1 | Train: 75.00% | Val: 87.77%\n",
            "Epoch  2 | Train: 94.11% | Val: 88.04%\n",
            "Epoch  3 | Train: 97.86% | Val: 90.76%\n",
            "Epoch  4 | Train: 98.82% | Val: 88.86%\n",
            "Epoch  5 | Train: 99.43% | Val: 89.67%\n",
            "Epoch  6 | Train: 99.91% | Val: 90.49%\n",
            "Epoch  7 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  8 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  9 | Train: 100.00% | Val: 89.40%\n",
            "Epoch 10 | Train: 99.94% | Val: 90.49%\n",
            "Test Accuracy: 91.11%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=False\n",
            "Epoch  1 | Train: 73.64% | Val: 87.50%\n",
            "Epoch  2 | Train: 94.11% | Val: 88.04%\n",
            "Epoch  3 | Train: 97.40% | Val: 89.67%\n",
            "Epoch  4 | Train: 98.97% | Val: 89.13%\n",
            "Epoch  5 | Train: 99.40% | Val: 88.32%\n",
            "Epoch  6 | Train: 99.85% | Val: 89.40%\n",
            "Epoch  7 | Train: 99.85% | Val: 91.03%\n",
            "Epoch  8 | Train: 99.79% | Val: 90.49%\n",
            "Epoch  9 | Train: 99.94% | Val: 89.40%\n",
            "Epoch 10 | Train: 99.97% | Val: 90.49%\n",
            "Test Accuracy: 90.24%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=True\n",
            "Epoch  1 | Train: 74.82% | Val: 86.68%\n",
            "Epoch  2 | Train: 93.96% | Val: 88.04%\n",
            "Epoch  3 | Train: 98.01% | Val: 89.40%\n",
            "Epoch  4 | Train: 98.97% | Val: 89.67%\n",
            "Epoch  5 | Train: 99.52% | Val: 90.22%\n",
            "Epoch  6 | Train: 99.88% | Val: 89.95%\n",
            "Epoch  7 | Train: 99.94% | Val: 90.49%\n",
            "Epoch  8 | Train: 100.00% | Val: 89.95%\n",
            "Epoch  9 | Train: 99.97% | Val: 89.95%\n",
            "Epoch 10 | Train: 99.94% | Val: 89.95%\n",
            "Test Accuracy: 90.54%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=False\n",
            "Epoch  1 | Train: 71.17% | Val: 85.05%\n",
            "Epoch  2 | Train: 90.07% | Val: 88.04%\n",
            "Epoch  3 | Train: 93.45% | Val: 88.04%\n",
            "Epoch  4 | Train: 95.56% | Val: 87.23%\n",
            "Epoch  5 | Train: 96.32% | Val: 89.13%\n",
            "Epoch  6 | Train: 97.04% | Val: 88.32%\n",
            "Epoch  7 | Train: 97.58% | Val: 88.59%\n",
            "Epoch  8 | Train: 98.22% | Val: 86.41%\n",
            "Epoch  9 | Train: 97.83% | Val: 84.78%\n",
            "Epoch 10 | Train: 98.25% | Val: 88.32%\n",
            "Test Accuracy: 88.14%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=True\n",
            "Epoch  1 | Train: 69.05% | Val: 86.96%\n",
            "Epoch  2 | Train: 89.19% | Val: 87.23%\n",
            "Epoch  3 | Train: 93.27% | Val: 88.32%\n",
            "Epoch  4 | Train: 95.29% | Val: 88.04%\n",
            "Epoch  5 | Train: 96.68% | Val: 87.23%\n",
            "Epoch  6 | Train: 98.16% | Val: 89.13%\n",
            "Epoch  7 | Train: 98.82% | Val: 91.03%\n",
            "Epoch  8 | Train: 98.67% | Val: 87.23%\n",
            "Epoch  9 | Train: 98.79% | Val: 89.67%\n",
            "Epoch 10 | Train: 99.06% | Val: 87.77%\n",
            "Test Accuracy: 89.70%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=False\n",
            "Epoch  1 | Train: 71.92% | Val: 86.14%\n",
            "Epoch  2 | Train: 90.25% | Val: 86.68%\n",
            "Epoch  3 | Train: 93.54% | Val: 86.68%\n",
            "Epoch  4 | Train: 95.08% | Val: 86.96%\n",
            "Epoch  5 | Train: 96.71% | Val: 85.33%\n",
            "Epoch  6 | Train: 97.40% | Val: 88.86%\n",
            "Epoch  7 | Train: 97.04% | Val: 88.86%\n",
            "Epoch  8 | Train: 97.89% | Val: 86.14%\n",
            "Epoch  9 | Train: 98.85% | Val: 88.86%\n",
            "Epoch 10 | Train: 98.61% | Val: 88.32%\n",
            "Test Accuracy: 87.33%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=True\n",
            "Epoch  1 | Train: 69.29% | Val: 85.05%\n",
            "Epoch  2 | Train: 90.43% | Val: 86.68%\n",
            "Epoch  3 | Train: 93.21% | Val: 89.13%\n",
            "Epoch  4 | Train: 94.96% | Val: 88.32%\n",
            "Epoch  5 | Train: 96.53% | Val: 85.87%\n",
            "Epoch  6 | Train: 98.04% | Val: 89.13%\n",
            "Epoch  7 | Train: 98.49% | Val: 90.22%\n",
            "Epoch  8 | Train: 98.37% | Val: 88.32%\n",
            "Epoch  9 | Train: 98.82% | Val: 91.03%\n",
            "Epoch 10 | Train: 99.18% | Val: 90.22%\n",
            "Test Accuracy: 89.70%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=False\n",
            "Epoch  1 | Train: 71.04% | Val: 83.70%\n",
            "Epoch  2 | Train: 90.28% | Val: 86.14%\n",
            "Epoch  3 | Train: 92.84% | Val: 87.23%\n",
            "Epoch  4 | Train: 95.77% | Val: 87.50%\n",
            "Epoch  5 | Train: 96.71% | Val: 87.23%\n",
            "Epoch  6 | Train: 97.28% | Val: 88.86%\n",
            "Epoch  7 | Train: 98.28% | Val: 86.68%\n",
            "Epoch  8 | Train: 97.40% | Val: 86.14%\n",
            "Epoch  9 | Train: 98.49% | Val: 87.50%\n",
            "Epoch 10 | Train: 98.52% | Val: 88.04%\n",
            "Test Accuracy: 88.28%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=True\n",
            "Epoch  1 | Train: 70.08% | Val: 86.96%\n",
            "Epoch  2 | Train: 90.37% | Val: 85.87%\n",
            "Epoch  3 | Train: 94.02% | Val: 88.04%\n",
            "Epoch  4 | Train: 95.38% | Val: 87.50%\n",
            "Epoch  5 | Train: 96.47% | Val: 88.32%\n",
            "Epoch  6 | Train: 97.89% | Val: 88.59%\n",
            "Epoch  7 | Train: 98.40% | Val: 88.32%\n",
            "Epoch  8 | Train: 98.67% | Val: 88.86%\n",
            "Epoch  9 | Train: 98.91% | Val: 89.40%\n",
            "Epoch 10 | Train: 98.85% | Val: 89.95%\n",
            "Test Accuracy: 89.56%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=False\n",
            "Epoch  1 | Train: 70.98% | Val: 85.87%\n",
            "Epoch  2 | Train: 89.49% | Val: 86.41%\n",
            "Epoch  3 | Train: 92.36% | Val: 88.04%\n",
            "Epoch  4 | Train: 94.90% | Val: 88.32%\n",
            "Epoch  5 | Train: 96.38% | Val: 88.32%\n",
            "Epoch  6 | Train: 96.86% | Val: 88.04%\n",
            "Epoch  7 | Train: 98.49% | Val: 85.87%\n",
            "Epoch  8 | Train: 98.22% | Val: 88.04%\n",
            "Epoch  9 | Train: 98.19% | Val: 89.13%\n",
            "Epoch 10 | Train: 98.01% | Val: 90.22%\n",
            "Test Accuracy: 86.43%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=True\n",
            "Epoch  1 | Train: 70.02% | Val: 86.14%\n",
            "Epoch  2 | Train: 89.98% | Val: 85.33%\n",
            "Epoch  3 | Train: 93.39% | Val: 87.77%\n",
            "Epoch  4 | Train: 95.35% | Val: 88.86%\n",
            "Epoch  5 | Train: 96.41% | Val: 89.13%\n",
            "Epoch  6 | Train: 97.92% | Val: 88.86%\n",
            "Epoch  7 | Train: 98.61% | Val: 89.95%\n",
            "Epoch  8 | Train: 98.88% | Val: 87.77%\n",
            "Epoch  9 | Train: 99.03% | Val: 89.13%\n",
            "Epoch 10 | Train: 99.31% | Val: 89.40%\n",
            "Test Accuracy: 89.45%\n",
            "\n",
            "=== Strategy 1 Extended Grid Results ===\n",
            "aug=False, freeze_bn=False, L2=False, sched=False → Test Acc: 89.62%\n",
            "aug=False, freeze_bn=False, L2=False, sched=True → Test Acc: 90.87%\n",
            "aug=False, freeze_bn=False, L2=True, sched=False → Test Acc: 90.38%\n",
            "aug=False, freeze_bn=False, L2=True, sched=True → Test Acc: 90.57%\n",
            "aug=False, freeze_bn=True, L2=False, sched=False → Test Acc: 90.30%\n",
            "aug=False, freeze_bn=True, L2=False, sched=True → Test Acc: 91.11%\n",
            "aug=False, freeze_bn=True, L2=True, sched=False → Test Acc: 90.24%\n",
            "aug=False, freeze_bn=True, L2=True, sched=True → Test Acc: 90.54%\n",
            "aug=True, freeze_bn=False, L2=False, sched=False → Test Acc: 88.14%\n",
            "aug=True, freeze_bn=False, L2=False, sched=True → Test Acc: 89.70%\n",
            "aug=True, freeze_bn=False, L2=True, sched=False → Test Acc: 87.33%\n",
            "aug=True, freeze_bn=False, L2=True, sched=True → Test Acc: 89.70%\n",
            "aug=True, freeze_bn=True, L2=False, sched=False → Test Acc: 88.28%\n",
            "aug=True, freeze_bn=True, L2=False, sched=True → Test Acc: 89.56%\n",
            "aug=True, freeze_bn=True, L2=True, sched=False → Test Acc: 86.43%\n",
            "aug=True, freeze_bn=True, L2=True, sched=True → Test Acc: 89.45%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Transforms\n",
        "base_tf = transforms.Compose([\n",
        "    transforms.Resize(256), transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "aug_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(), transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "# Create datasets and split 90/10\n",
        "full_ds = MultiClassPet(\"data\", trainval_names, breeds_map, transform=base_tf)\n",
        "n_val   = int(0.1 * len(full_ds))\n",
        "train_ds, val_ds = random_split(full_ds, [len(full_ds)-n_val, n_val])\n",
        "test_ds = MultiClassPet(\"data\", test_names, breeds_map, transform=base_tf)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 32\n",
        "val_loader  = DataLoader(val_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Strategy 1 grid\n",
        "results = []\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "\n",
        "for use_aug in [False, True]:\n",
        "    for freeze_bn in [False, True]:\n",
        "        for use_l2 in [False, True]:\n",
        "            for use_sched in [False, True]:\n",
        "                print(f\"\\n>>> aug={use_aug}, freeze_bn={freeze_bn}, L2={use_l2}, sched={use_sched}\")\n",
        "\n",
        "                # a) Set train transform\n",
        "                train_ds.dataset.transform = aug_tf if use_aug else base_tf\n",
        "\n",
        "                # b) Train loader\n",
        "                train_loader = DataLoader(\n",
        "                    train_ds, batch_size=batch_size, shuffle=True,\n",
        "                    num_workers=4, pin_memory=True\n",
        "                )\n",
        "\n",
        "                # c) Init model, fine-tune last 6 layers\n",
        "                model = NeuralNetwork(\n",
        "                    basemodel=basemodel,\n",
        "                    output=len(breed_names),\n",
        "                    train_loader=train_loader,\n",
        "                    val_loader=val_loader,\n",
        "                    test_loader=test_loader,\n",
        "                    unfreeze=6,\n",
        "                    parameters={}\n",
        "                )\n",
        "                model.model.to(device)\n",
        "\n",
        "                # d) Freeze batch-norm if requested\n",
        "                if freeze_bn:\n",
        "                    for m in model.model.modules():\n",
        "                        if isinstance(m, nn.BatchNorm2d):\n",
        "                            m.eval()\n",
        "                            for p in m.parameters():\n",
        "                                p.requires_grad = False\n",
        "\n",
        "                # e) Optimizer with two LR groups, optional L2 weight decay\n",
        "                wd = 1e-2 if use_l2 else 0.0\n",
        "                head_p = list(model.model.fc.parameters())\n",
        "                back_p = [p for n,p in model.model.named_parameters()\n",
        "                          if p.requires_grad and not n.startswith(\"fc\")]\n",
        "                model.optimizer = optim.AdamW([\n",
        "                    {\"params\": head_p, \"lr\":1e-3, \"weight_decay\":wd},\n",
        "                    {\"params\": back_p, \"lr\":1e-4, \"weight_decay\":wd}\n",
        "                ])\n",
        "\n",
        "                # f) Scheduler if requested\n",
        "                if use_sched:\n",
        "                    model.scheduler = optim.lr_scheduler.StepLR(model.optimizer, step_size=5, gamma=0.1)\n",
        "                else:\n",
        "                    model.scheduler = None\n",
        "\n",
        "                # g) Train and record test accuracy\n",
        "                acc = model.train(epochs=10)\n",
        "                results.append(((use_aug, freeze_bn, use_l2, use_sched), acc))\n",
        "\n",
        "# Summary for comparison\n",
        "print(\"\\n=== Strategy 1 Extended Grid Results ===\")\n",
        "for (aug, bn, l2, sched), acc in results:\n",
        "    print(f\"aug={aug}, freeze_bn={bn}, L2={l2}, sched={sched} → Test Acc: {acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "906198d5-6a25-4adb-b4cc-aaf32dc13b1c",
      "metadata": {
        "id": "906198d5-6a25-4adb-b4cc-aaf32dc13b1c"
      },
      "source": [
        "-> Strategy 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vQdtxDaSeTEd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "vQdtxDaSeTEd",
        "outputId": "18dc5d37-1421-411b-c3f7-38d9bd3021bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training model with uf_rate 0.3\n",
            "Epoch  1 | Train: 61.08% | Val: 83.97%\n",
            "Epoch  2 | Train: 88.68% | Val: 89.13%\n",
            "Epoch  3 | Train: 91.46% | Val: 90.76%\n",
            "Epoch  4 | Train: 92.39% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.75% | Val: 91.30%\n",
            "Epoch  6 | Train: 94.93% | Val: 90.22%\n",
            "Epoch  7 | Train: 95.77% | Val: 91.03%\n",
            "Epoch  8 | Train: 95.92% | Val: 90.22%\n",
            "Epoch  9 | Train: 96.71% | Val: 89.95%\n",
            "Epoch 10 | Train: 97.04% | Val: 90.22%\n",
            "Test Accuracy: 90.27%\n",
            "Start training model with uf_rate 0.5\n",
            "Epoch  1 | Train: 60.60% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.07% | Val: 87.23%\n",
            "Epoch  3 | Train: 91.70% | Val: 89.67%\n",
            "Epoch  4 | Train: 93.48% | Val: 89.95%\n",
            "Epoch  5 | Train: 93.72% | Val: 90.49%\n",
            "Epoch  6 | Train: 94.96% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.59% | Val: 90.49%\n",
            "Epoch  8 | Train: 95.59% | Val: 89.40%\n",
            "Epoch  9 | Train: 95.98% | Val: 89.13%\n",
            "Epoch 10 | Train: 96.68% | Val: 89.40%\n",
            "Test Accuracy: 89.07%\n",
            "Start training model with uf_rate 0.8\n",
            "Epoch  1 | Train: 59.48% | Val: 85.60%\n",
            "Epoch  2 | Train: 88.77% | Val: 88.86%\n",
            "Epoch  3 | Train: 90.73% | Val: 91.03%\n",
            "Epoch  4 | Train: 92.69% | Val: 90.22%\n",
            "Epoch  5 | Train: 94.47% | Val: 91.30%\n",
            "Epoch  6 | Train: 94.84% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.71% | Val: 91.03%\n",
            "Epoch  8 | Train: 96.01% | Val: 91.30%\n",
            "Epoch  9 | Train: 96.74% | Val: 90.76%\n",
            "Epoch 10 | Train: 96.89% | Val: 90.76%\n",
            "Test Accuracy: 89.37%\n",
            "Start training model with uf_rate 1\n",
            "Epoch  1 | Train: 58.97% | Val: 82.88%\n",
            "Epoch  2 | Train: 88.32% | Val: 87.50%\n",
            "Epoch  3 | Train: 92.09% | Val: 88.86%\n",
            "Epoch  4 | Train: 92.75% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.75% | Val: 89.13%\n",
            "Epoch  6 | Train: 94.84% | Val: 91.85%\n",
            "Epoch  7 | Train: 95.68% | Val: 89.13%\n",
            "Epoch  8 | Train: 96.29% | Val: 89.95%\n",
            "Epoch  9 | Train: 96.29% | Val: 89.67%\n",
            "Epoch 10 | Train: 96.71% | Val: 89.40%\n",
            "Test Accuracy: 89.67%\n",
            "Start training model with uf_rate 2\n",
            "Epoch  1 | Train: 61.29% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.16% | Val: 87.77%\n",
            "Epoch  3 | Train: 91.49% | Val: 88.86%\n",
            "Epoch  4 | Train: 92.75% | Val: 88.04%\n",
            "Epoch  5 | Train: 93.39% | Val: 88.86%\n",
            "Epoch  6 | Train: 95.11% | Val: 89.40%\n",
            "Epoch  7 | Train: 95.62% | Val: 90.49%\n",
            "Epoch  8 | Train: 95.29% | Val: 89.95%\n",
            "Epoch  9 | Train: 96.62% | Val: 89.95%\n",
            "Epoch 10 | Train: 96.32% | Val: 89.13%\n",
            "Test Accuracy: 90.27%\n",
            "Start training model with uf_rate 3\n",
            "Epoch  1 | Train: 60.99% | Val: 85.87%\n",
            "Epoch  2 | Train: 89.01% | Val: 88.59%\n",
            "Epoch  3 | Train: 90.88% | Val: 90.49%\n",
            "Epoch  4 | Train: 93.48% | Val: 90.22%\n",
            "Epoch  5 | Train: 93.84% | Val: 90.22%\n",
            "Epoch  6 | Train: 95.20% | Val: 91.58%\n",
            "Epoch  7 | Train: 95.62% | Val: 90.76%\n",
            "Epoch  8 | Train: 95.83% | Val: 89.40%\n",
            "Epoch  9 | Train: 96.41% | Val: 89.67%\n",
            "Epoch 10 | Train: 97.04% | Val: 88.86%\n",
            "Test Accuracy: 89.94%\n"
          ]
        }
      ],
      "source": [
        "# Strategy 2: train with gradual unfreezing\n",
        "parameters = {}\n",
        "parameters['gradual_unfreezing'] = True\n",
        "accs = []\n",
        "\n",
        "# test rates in steps of two\n",
        "for rate in [0.3, 0.5, 0.8, 1, 2, 3]:\n",
        "  print(f\"Start training model with uf_rate {rate}\")\n",
        "  parameters['unfreezing_rate'] = rate\n",
        "  modelmulti = NeuralNetwork(basemodel, 37, train_loader, val_loader, test_loader, unfreeze=1, parameters=parameters)   # start with only one unfrozen layer\n",
        "  accs.append(modelmulti.train(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd91e0d3-e161-4eaa-a1c6-963be4e032bb",
      "metadata": {
        "id": "bd91e0d3-e161-4eaa-a1c6-963be4e032bb",
        "outputId": "6963fb60-345e-4b79-f66b-97606e0eae7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=none\n",
            "Epoch  1 | Train: 60.63% | Val: 84.51%\n",
            "Epoch  2 | Train: 88.74% | Val: 86.41%\n",
            "Epoch  3 | Train: 91.24% | Val: 84.78%\n",
            "Epoch  4 | Train: 93.15% | Val: 88.59%\n",
            "Epoch  5 | Train: 94.50% | Val: 88.32%\n",
            "Epoch  6 | Train: 95.59% | Val: 89.40%\n",
            "Epoch  7 | Train: 95.44% | Val: 88.04%\n",
            "Epoch  8 | Train: 96.29% | Val: 90.22%\n",
            "Epoch  9 | Train: 97.16% | Val: 88.04%\n",
            "Epoch 10 | Train: 97.31% | Val: 88.59%\n",
            "Test Accuracy: 89.34%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=steplr\n",
            "Epoch  1 | Train: 59.51% | Val: 82.34%\n",
            "Epoch  2 | Train: 88.13% | Val: 86.68%\n",
            "Epoch  3 | Train: 91.82% | Val: 89.13%\n",
            "Epoch  4 | Train: 92.84% | Val: 89.13%\n",
            "Epoch  5 | Train: 93.90% | Val: 89.95%\n",
            "Epoch  6 | Train: 95.89% | Val: 91.30%\n",
            "Epoch  7 | Train: 96.01% | Val: 91.03%\n",
            "Epoch  8 | Train: 96.38% | Val: 91.30%\n",
            "Epoch  9 | Train: 96.35% | Val: 91.58%\n",
            "Epoch 10 | Train: 96.26% | Val: 91.03%\n",
            "Test Accuracy: 89.70%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=False, sched=onecycle\n",
            "Epoch  1 | Train: 3.83% | Val: 5.98%\n",
            "Epoch  2 | Train: 12.26% | Val: 16.03%\n",
            "Epoch  3 | Train: 24.09% | Val: 30.16%\n",
            "Epoch  4 | Train: 39.31% | Val: 44.84%\n",
            "Epoch  5 | Train: 52.51% | Val: 57.34%\n",
            "Epoch  6 | Train: 61.20% | Val: 64.13%\n",
            "Epoch  7 | Train: 68.30% | Val: 67.39%\n",
            "Epoch  8 | Train: 72.71% | Val: 72.01%\n",
            "Epoch  9 | Train: 74.79% | Val: 74.73%\n",
            "Epoch 10 | Train: 77.84% | Val: 76.63%\n",
            "Test Accuracy: 78.06%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=none\n",
            "Epoch  1 | Train: 63.29% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.22% | Val: 86.14%\n",
            "Epoch  3 | Train: 90.85% | Val: 88.04%\n",
            "Epoch  4 | Train: 93.15% | Val: 89.40%\n",
            "Epoch  5 | Train: 94.08% | Val: 89.13%\n",
            "Epoch  6 | Train: 95.20% | Val: 90.49%\n",
            "Epoch  7 | Train: 96.41% | Val: 89.67%\n",
            "Epoch  8 | Train: 95.59% | Val: 88.32%\n",
            "Epoch  9 | Train: 96.71% | Val: 90.22%\n",
            "Epoch 10 | Train: 97.34% | Val: 89.40%\n",
            "Test Accuracy: 89.72%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 59.60% | Val: 82.88%\n",
            "Epoch  2 | Train: 88.59% | Val: 87.77%\n",
            "Epoch  3 | Train: 91.85% | Val: 86.68%\n",
            "Epoch  4 | Train: 93.27% | Val: 88.32%\n",
            "Epoch  5 | Train: 94.29% | Val: 88.04%\n",
            "Epoch  6 | Train: 95.80% | Val: 88.86%\n",
            "Epoch  7 | Train: 96.23% | Val: 88.86%\n",
            "Epoch  8 | Train: 96.26% | Val: 88.86%\n",
            "Epoch  9 | Train: 96.29% | Val: 90.22%\n",
            "Epoch 10 | Train: 96.56% | Val: 90.22%\n",
            "Test Accuracy: 90.05%\n",
            "\n",
            ">>> aug=False, freeze_bn=False, L2=True, sched=onecycle\n",
            "Epoch  1 | Train: 5.40% | Val: 8.97%\n",
            "Epoch  2 | Train: 15.61% | Val: 19.84%\n",
            "Epoch  3 | Train: 28.59% | Val: 37.50%\n",
            "Epoch  4 | Train: 43.48% | Val: 48.91%\n",
            "Epoch  5 | Train: 54.59% | Val: 57.88%\n",
            "Epoch  6 | Train: 62.02% | Val: 65.76%\n",
            "Epoch  7 | Train: 68.66% | Val: 68.75%\n",
            "Epoch  8 | Train: 73.67% | Val: 71.47%\n",
            "Epoch  9 | Train: 77.26% | Val: 73.91%\n",
            "Epoch 10 | Train: 79.53% | Val: 76.36%\n",
            "Test Accuracy: 78.63%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=none\n",
            "Epoch  1 | Train: 59.90% | Val: 84.24%\n",
            "Epoch  2 | Train: 88.50% | Val: 89.13%\n",
            "Epoch  3 | Train: 91.91% | Val: 87.50%\n",
            "Epoch  4 | Train: 93.00% | Val: 89.13%\n",
            "Epoch  5 | Train: 93.69% | Val: 89.40%\n",
            "Epoch  6 | Train: 95.74% | Val: 89.40%\n",
            "Epoch  7 | Train: 95.92% | Val: 88.86%\n",
            "Epoch  8 | Train: 96.62% | Val: 90.22%\n",
            "Epoch  9 | Train: 97.19% | Val: 89.95%\n",
            "Epoch 10 | Train: 96.98% | Val: 90.76%\n",
            "Test Accuracy: 89.34%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=steplr\n",
            "Epoch  1 | Train: 60.39% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.41% | Val: 86.96%\n",
            "Epoch  3 | Train: 90.97% | Val: 87.23%\n",
            "Epoch  4 | Train: 92.63% | Val: 88.04%\n",
            "Epoch  5 | Train: 94.44% | Val: 87.77%\n",
            "Epoch  6 | Train: 95.74% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.80% | Val: 89.95%\n",
            "Epoch  8 | Train: 95.95% | Val: 89.95%\n",
            "Epoch  9 | Train: 95.95% | Val: 90.22%\n",
            "Epoch 10 | Train: 96.26% | Val: 90.22%\n",
            "Test Accuracy: 89.64%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=False, sched=onecycle\n",
            "Epoch  1 | Train: 4.83% | Val: 8.97%\n",
            "Epoch  2 | Train: 13.35% | Val: 21.47%\n",
            "Epoch  3 | Train: 26.15% | Val: 36.41%\n",
            "Epoch  4 | Train: 40.58% | Val: 48.91%\n",
            "Epoch  5 | Train: 50.94% | Val: 56.52%\n",
            "Epoch  6 | Train: 59.45% | Val: 61.96%\n",
            "Epoch  7 | Train: 66.79% | Val: 67.39%\n",
            "Epoch  8 | Train: 70.59% | Val: 72.55%\n",
            "Epoch  9 | Train: 74.94% | Val: 74.73%\n",
            "Epoch 10 | Train: 78.26% | Val: 78.53%\n",
            "Test Accuracy: 77.24%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=none\n",
            "Epoch  1 | Train: 60.60% | Val: 84.24%\n",
            "Epoch  2 | Train: 87.71% | Val: 88.59%\n",
            "Epoch  3 | Train: 91.58% | Val: 88.32%\n",
            "Epoch  4 | Train: 93.30% | Val: 87.50%\n",
            "Epoch  5 | Train: 93.57% | Val: 88.59%\n",
            "Epoch  6 | Train: 94.99% | Val: 88.86%\n",
            "Epoch  7 | Train: 95.80% | Val: 90.49%\n",
            "Epoch  8 | Train: 96.26% | Val: 89.67%\n",
            "Epoch  9 | Train: 96.47% | Val: 89.13%\n",
            "Epoch 10 | Train: 96.50% | Val: 90.22%\n",
            "Test Accuracy: 89.13%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 59.27% | Val: 83.15%\n",
            "Epoch  2 | Train: 88.25% | Val: 88.32%\n",
            "Epoch  3 | Train: 91.52% | Val: 87.77%\n",
            "Epoch  4 | Train: 93.24% | Val: 89.13%\n",
            "Epoch  5 | Train: 94.26% | Val: 90.22%\n",
            "Epoch  6 | Train: 95.89% | Val: 89.95%\n",
            "Epoch  7 | Train: 95.95% | Val: 89.95%\n",
            "Epoch  8 | Train: 95.89% | Val: 89.67%\n",
            "Epoch  9 | Train: 96.50% | Val: 89.40%\n",
            "Epoch 10 | Train: 96.44% | Val: 88.86%\n",
            "Test Accuracy: 90.24%\n",
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=onecycle\n",
            "Epoch  1 | Train: 5.43% | Val: 8.97%\n",
            "Epoch  2 | Train: 14.70% | Val: 19.84%\n",
            "Epoch  3 | Train: 28.59% | Val: 34.51%\n",
            "Epoch  4 | Train: 40.73% | Val: 46.47%\n",
            "Epoch  5 | Train: 52.14% | Val: 54.62%\n",
            "Epoch  6 | Train: 62.47% | Val: 64.13%\n",
            "Epoch  7 | Train: 67.57% | Val: 70.11%\n",
            "Epoch  8 | Train: 73.31% | Val: 73.91%\n",
            "Epoch  9 | Train: 77.39% | Val: 76.63%\n",
            "Epoch 10 | Train: 79.80% | Val: 78.26%\n",
            "Test Accuracy: 78.90%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=none\n",
            "Epoch  1 | Train: 53.47% | Val: 78.53%\n",
            "Epoch  2 | Train: 82.91% | Val: 84.51%\n",
            "Epoch  3 | Train: 87.71% | Val: 85.33%\n",
            "Epoch  4 | Train: 88.86% | Val: 85.33%\n",
            "Epoch  5 | Train: 90.13% | Val: 83.97%\n",
            "Epoch  6 | Train: 91.36% | Val: 84.78%\n",
            "Epoch  7 | Train: 91.94% | Val: 87.50%\n",
            "Epoch  8 | Train: 92.33% | Val: 88.04%\n",
            "Epoch  9 | Train: 91.67% | Val: 85.87%\n",
            "Epoch 10 | Train: 93.06% | Val: 87.77%\n",
            "Test Accuracy: 89.04%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=steplr\n",
            "Epoch  1 | Train: 56.43% | Val: 80.71%\n",
            "Epoch  2 | Train: 83.24% | Val: 84.24%\n",
            "Epoch  3 | Train: 87.83% | Val: 82.34%\n",
            "Epoch  4 | Train: 88.56% | Val: 87.23%\n",
            "Epoch  5 | Train: 89.46% | Val: 86.41%\n",
            "Epoch  6 | Train: 92.12% | Val: 87.50%\n",
            "Epoch  7 | Train: 93.06% | Val: 88.04%\n",
            "Epoch  8 | Train: 92.69% | Val: 88.04%\n",
            "Epoch  9 | Train: 92.93% | Val: 86.41%\n",
            "Epoch 10 | Train: 93.21% | Val: 86.96%\n",
            "Test Accuracy: 89.07%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=False, sched=onecycle\n",
            "Epoch  1 | Train: 3.26% | Val: 5.43%\n",
            "Epoch  2 | Train: 9.18% | Val: 15.76%\n",
            "Epoch  3 | Train: 19.44% | Val: 23.64%\n",
            "Epoch  4 | Train: 31.37% | Val: 37.50%\n",
            "Epoch  5 | Train: 42.48% | Val: 48.37%\n",
            "Epoch  6 | Train: 51.60% | Val: 52.99%\n",
            "Epoch  7 | Train: 59.24% | Val: 64.13%\n",
            "Epoch  8 | Train: 65.22% | Val: 67.12%\n",
            "Epoch  9 | Train: 70.17% | Val: 71.74%\n",
            "Epoch 10 | Train: 73.10% | Val: 72.55%\n",
            "Test Accuracy: 74.63%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=none\n",
            "Epoch  1 | Train: 56.25% | Val: 81.25%\n",
            "Epoch  2 | Train: 83.27% | Val: 84.51%\n",
            "Epoch  3 | Train: 87.65% | Val: 85.05%\n",
            "Epoch  4 | Train: 88.53% | Val: 86.41%\n",
            "Epoch  5 | Train: 90.28% | Val: 86.41%\n",
            "Epoch  6 | Train: 91.33% | Val: 85.87%\n",
            "Epoch  7 | Train: 92.00% | Val: 87.50%\n",
            "Epoch  8 | Train: 92.63% | Val: 87.50%\n",
            "Epoch  9 | Train: 92.54% | Val: 86.14%\n",
            "Epoch 10 | Train: 93.48% | Val: 88.32%\n",
            "Test Accuracy: 88.58%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 54.80% | Val: 79.35%\n",
            "Epoch  2 | Train: 83.36% | Val: 85.05%\n",
            "Epoch  3 | Train: 87.65% | Val: 87.50%\n",
            "Epoch  4 | Train: 89.40% | Val: 87.23%\n",
            "Epoch  5 | Train: 90.49% | Val: 87.77%\n",
            "Epoch  6 | Train: 92.36% | Val: 87.77%\n",
            "Epoch  7 | Train: 92.84% | Val: 86.68%\n",
            "Epoch  8 | Train: 92.42% | Val: 87.23%\n",
            "Epoch  9 | Train: 93.27% | Val: 88.04%\n",
            "Epoch 10 | Train: 92.51% | Val: 87.23%\n",
            "Test Accuracy: 88.93%\n",
            "\n",
            ">>> aug=True, freeze_bn=False, L2=True, sched=onecycle\n",
            "Epoch  1 | Train: 3.80% | Val: 5.43%\n",
            "Epoch  2 | Train: 10.30% | Val: 16.58%\n",
            "Epoch  3 | Train: 20.17% | Val: 27.45%\n",
            "Epoch  4 | Train: 32.97% | Val: 33.97%\n",
            "Epoch  5 | Train: 44.08% | Val: 45.65%\n",
            "Epoch  6 | Train: 51.87% | Val: 52.17%\n",
            "Epoch  7 | Train: 58.79% | Val: 59.78%\n",
            "Epoch  8 | Train: 64.37% | Val: 61.41%\n",
            "Epoch  9 | Train: 70.29% | Val: 68.21%\n",
            "Epoch 10 | Train: 71.86% | Val: 71.47%\n",
            "Test Accuracy: 73.18%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=none\n",
            "Epoch  1 | Train: 53.29% | Val: 77.99%\n",
            "Epoch  2 | Train: 84.30% | Val: 83.97%\n",
            "Epoch  3 | Train: 87.68% | Val: 84.51%\n",
            "Epoch  4 | Train: 88.98% | Val: 85.60%\n",
            "Epoch  5 | Train: 90.19% | Val: 87.77%\n",
            "Epoch  6 | Train: 90.49% | Val: 86.96%\n",
            "Epoch  7 | Train: 92.09% | Val: 89.40%\n",
            "Epoch  8 | Train: 92.78% | Val: 86.41%\n",
            "Epoch  9 | Train: 92.84% | Val: 86.96%\n",
            "Epoch 10 | Train: 92.66% | Val: 87.23%\n",
            "Test Accuracy: 88.39%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=steplr\n",
            "Epoch  1 | Train: 54.77% | Val: 80.43%\n",
            "Epoch  2 | Train: 83.09% | Val: 82.34%\n",
            "Epoch  3 | Train: 87.92% | Val: 85.87%\n",
            "Epoch  4 | Train: 89.01% | Val: 85.60%\n",
            "Epoch  5 | Train: 90.07% | Val: 86.96%\n",
            "Epoch  6 | Train: 91.64% | Val: 87.77%\n",
            "Epoch  7 | Train: 92.72% | Val: 86.68%\n",
            "Epoch  8 | Train: 92.75% | Val: 88.32%\n",
            "Epoch  9 | Train: 93.00% | Val: 88.04%\n",
            "Epoch 10 | Train: 92.84% | Val: 86.68%\n",
            "Test Accuracy: 89.37%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=False, sched=onecycle\n",
            "Epoch  1 | Train: 5.31% | Val: 10.60%\n",
            "Epoch  2 | Train: 13.10% | Val: 20.92%\n",
            "Epoch  3 | Train: 24.76% | Val: 32.34%\n",
            "Epoch  4 | Train: 38.32% | Val: 42.66%\n",
            "Epoch  5 | Train: 47.89% | Val: 53.53%\n",
            "Epoch  6 | Train: 57.52% | Val: 58.42%\n",
            "Epoch  7 | Train: 62.77% | Val: 63.86%\n",
            "Epoch  8 | Train: 66.52% | Val: 67.39%\n",
            "Epoch  9 | Train: 71.32% | Val: 70.11%\n",
            "Epoch 10 | Train: 73.85% | Val: 72.55%\n",
            "Test Accuracy: 75.28%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=none\n",
            "Epoch  1 | Train: 55.46% | Val: 79.89%\n",
            "Epoch  2 | Train: 85.30% | Val: 83.15%\n",
            "Epoch  3 | Train: 87.41% | Val: 83.70%\n",
            "Epoch  4 | Train: 89.52% | Val: 86.96%\n",
            "Epoch  5 | Train: 89.89% | Val: 84.24%\n",
            "Epoch  6 | Train: 90.94% | Val: 86.14%\n",
            "Epoch  7 | Train: 91.70% | Val: 86.41%\n",
            "Epoch  8 | Train: 92.42% | Val: 85.33%\n",
            "Epoch  9 | Train: 92.81% | Val: 85.87%\n",
            "Epoch 10 | Train: 92.66% | Val: 86.68%\n",
            "Test Accuracy: 87.90%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 56.31% | Val: 79.89%\n",
            "Epoch  2 | Train: 85.75% | Val: 82.61%\n",
            "Epoch  3 | Train: 87.98% | Val: 85.87%\n",
            "Epoch  4 | Train: 89.86% | Val: 85.33%\n",
            "Epoch  5 | Train: 90.61% | Val: 86.14%\n",
            "Epoch  6 | Train: 92.09% | Val: 86.68%\n",
            "Epoch  7 | Train: 92.63% | Val: 84.78%\n",
            "Epoch  8 | Train: 92.84% | Val: 85.33%\n",
            "Epoch  9 | Train: 92.39% | Val: 88.04%\n",
            "Epoch 10 | Train: 92.33% | Val: 86.68%\n",
            "Test Accuracy: 89.13%\n",
            "\n",
            ">>> aug=True, freeze_bn=True, L2=True, sched=onecycle\n",
            "Epoch  1 | Train: 4.44% | Val: 8.15%\n",
            "Epoch  2 | Train: 11.59% | Val: 19.57%\n",
            "Epoch  3 | Train: 22.16% | Val: 28.26%\n",
            "Epoch  4 | Train: 33.70% | Val: 39.13%\n",
            "Epoch  5 | Train: 44.63% | Val: 47.28%\n",
            "Epoch  6 | Train: 54.74% | Val: 52.99%\n",
            "Epoch  7 | Train: 58.82% | Val: 57.88%\n",
            "Epoch  8 | Train: 65.43% | Val: 64.13%\n",
            "Epoch  9 | Train: 68.39% | Val: 64.95%\n",
            "Epoch 10 | Train: 72.04% | Val: 69.57%\n",
            "Test Accuracy: 76.70%\n",
            "\n",
            "=== Strategy 2 Grid Search Results ===\n",
            "aug | freeze_bn | L2   | scheduler | TestAcc\n",
            "----|-----------|------|-----------|--------\n",
            "False | False     | False | none      |  89.34%\n",
            "False | False     | False | steplr    |  89.70%\n",
            "False | False     | False | onecycle  |  78.06%\n",
            "False | False     | True | none      |  89.72%\n",
            "False | False     | True | steplr    |  90.05%\n",
            "False | False     | True | onecycle  |  78.63%\n",
            "False | True      | False | none      |  89.34%\n",
            "False | True      | False | steplr    |  89.64%\n",
            "False | True      | False | onecycle  |  77.24%\n",
            "False | True      | True | none      |  89.13%\n",
            "False | True      | True | steplr    |  90.24%\n",
            "False | True      | True | onecycle  |  78.90%\n",
            "True | False     | False | none      |  89.04%\n",
            "True | False     | False | steplr    |  89.07%\n",
            "True | False     | False | onecycle  |  74.63%\n",
            "True | False     | True | none      |  88.58%\n",
            "True | False     | True | steplr    |  88.93%\n",
            "True | False     | True | onecycle  |  73.18%\n",
            "True | True      | False | none      |  88.39%\n",
            "True | True      | False | steplr    |  89.37%\n",
            "True | True      | False | onecycle  |  75.28%\n",
            "True | True      | True | none      |  87.90%\n",
            "True | True      | True | steplr    |  89.13%\n",
            "True | True      | True | onecycle  |  76.70%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# transforms\n",
        "base_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "])\n",
        "aug_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "# model\n",
        "basemodel = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "\n",
        "# fixed unfreeze rate\n",
        "fixed_rate = 2.0\n",
        "\n",
        "# grid definitions\n",
        "augmentations = [False, True]\n",
        "freeze_bns    = [False, True]\n",
        "use_l2s       = [False, True]\n",
        "schedulers    = ['none', 'steplr', 'onecycle']\n",
        "\n",
        "results = []\n",
        "\n",
        "# running the grid\n",
        "for use_aug in augmentations:\n",
        "    # update train transform\n",
        "    train_ds.dataset.transform = aug_tf if use_aug else base_tf\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    for freeze_bn in freeze_bns:\n",
        "        for use_l2 in use_l2s:\n",
        "            for sched in schedulers:\n",
        "                print(f\"\\n>>> aug={use_aug}, freeze_bn={freeze_bn}, L2={use_l2}, sched={sched}\")\n",
        "\n",
        "                # a) Instantiate with gradual unfreezing\n",
        "                params = {'gradual_unfreezing': True, 'unfreezing_rate': fixed_rate}\n",
        "                model = NeuralNetwork(\n",
        "                    basemodel,\n",
        "                    len(breed_names),\n",
        "                    train_loader,\n",
        "                    val_loader,\n",
        "                    test_loader,\n",
        "                    unfreeze=1,\n",
        "                    parameters=params\n",
        "                )\n",
        "                model.model.to(device)\n",
        "\n",
        "                # b) Optionally freeze BatchNorm layers\n",
        "                if freeze_bn:\n",
        "                    for m in model.model.modules():\n",
        "                        if isinstance(m, nn.BatchNorm2d):\n",
        "                            m.eval()\n",
        "                            for p in m.parameters():\n",
        "                                p.requires_grad = False\n",
        "\n",
        "                # c) Build optimizer (head @1e-3, backbone @1e-4), optional L2\n",
        "                wd = 1e-2 if use_l2 else 0.0\n",
        "                head_p = list(model.model.fc.parameters())\n",
        "                back_p = [\n",
        "                    p for n,p in model.model.named_parameters()\n",
        "                    if p.requires_grad and not n.startswith(\"fc\")\n",
        "                ]\n",
        "                model.optimizer = optim.AdamW([\n",
        "                    {'params': head_p, 'lr':1e-3, 'weight_decay':wd},\n",
        "                    {'params': back_p, 'lr':1e-4, 'weight_decay':wd},\n",
        "                ])\n",
        "\n",
        "                # d) Attach scheduler if desired\n",
        "                if sched == 'steplr':\n",
        "                    model.scheduler = optim.lr_scheduler.StepLR(\n",
        "                        model.optimizer,\n",
        "                        step_size=5,\n",
        "                        gamma=0.1\n",
        "                    )\n",
        "                elif sched == 'onecycle':\n",
        "                    total_steps = len(train_loader) * 10\n",
        "                    model.scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "                        model.optimizer,\n",
        "                        max_lr=[1e-3,1e-4],\n",
        "                        total_steps=total_steps,\n",
        "                        pct_start=0.3,\n",
        "                        anneal_strategy='cos'\n",
        "                    )\n",
        "                else:\n",
        "                    model.scheduler = None\n",
        "\n",
        "                # e) Train & record\n",
        "                acc = model.train2(epochs=10)\n",
        "                results.append((use_aug, freeze_bn, use_l2, sched, acc))\n",
        "\n",
        "# Summary for comparison\n",
        "print(\"\\n=== Strategy 2 Grid Search Results ===\")\n",
        "print(\"aug | freeze_bn | L2   | scheduler | TestAcc\")\n",
        "print(\"----|-----------|------|-----------|--------\")\n",
        "for aug, fb, l2, sch, acc in results:\n",
        "    print(f\"{str(aug):<3} | {str(fb):<9} | {str(l2):<4} | {sch:<9} | {acc:6.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f013e172-d1f0-43e0-969b-ada6fb408829",
      "metadata": {
        "id": "f013e172-d1f0-43e0-969b-ada6fb408829"
      },
      "source": [
        "## Imbalanced classes\n",
        "\n",
        "1. Load the annotations/trainval.txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5d5f38e-a763-4d5d-8d79-343db8b33475",
      "metadata": {
        "id": "e5d5f38e-a763-4d5d-8d79-343db8b33475"
      },
      "outputs": [],
      "source": [
        "# 0) Prepare names and label maps\n",
        "names = []\n",
        "breeds_map = {}\n",
        "\n",
        "with open(\"data/oxford-iiit-pet/annotations/trainval.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        name = parts[0]\n",
        "        class_id = int(parts[1]) - 1  # 0-indexed\n",
        "        names.append(name)\n",
        "        breeds_map[name] = class_id\n",
        "\n",
        "breed_to_id = {i: i for i in set(breeds_map.values())}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a77baf1",
      "metadata": {
        "id": "3a77baf1"
      },
      "source": [
        "Training with normal cross-entropy loss with limited data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9253ea5c",
      "metadata": {
        "id": "9253ea5c",
        "outputId": "885c7832-6eb5-4462-f18f-6664e2b0e6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Total samples in imbalanced dataset: 734\n",
            "Class distribution (samples, total, percentage):\n",
            "Abyssinian: 20/100 (20.0%)\n",
            "Bengal: 20/100 (20.0%)\n",
            "Birman: 20/100 (20.0%)\n",
            "Bombay: 19/96 (19.8%)\n",
            "British_Shorthair: 20/100 (20.0%)\n",
            "Egyptian_Mau: 18/93 (19.4%)\n",
            "Maine_Coon: 20/100 (20.0%)\n",
            "Persian: 20/100 (20.0%)\n",
            "Ragdoll: 20/100 (20.0%)\n",
            "Russian_Blue: 20/100 (20.0%)\n",
            "Siamese: 19/99 (19.2%)\n",
            "Sphynx: 20/100 (20.0%)\n",
            "american_bulldog: 20/100 (20.0%)\n",
            "american_pit_bull_terrier: 20/100 (20.0%)\n",
            "basset_hound: 20/100 (20.0%)\n",
            "beagle: 20/100 (20.0%)\n",
            "boxer: 20/100 (20.0%)\n",
            "chihuahua: 20/100 (20.0%)\n",
            "english_cocker_spaniel: 19/96 (19.8%)\n",
            "english_setter: 20/100 (20.0%)\n",
            "german_shorthaired: 20/100 (20.0%)\n",
            "great_pyrenees: 20/100 (20.0%)\n",
            "havanese: 20/100 (20.0%)\n",
            "japanese_chin: 20/100 (20.0%)\n",
            "keeshond: 20/100 (20.0%)\n",
            "leonberger: 20/100 (20.0%)\n",
            "miniature_pinscher: 20/100 (20.0%)\n",
            "newfoundland: 19/96 (19.8%)\n",
            "pomeranian: 20/100 (20.0%)\n",
            "pug: 20/100 (20.0%)\n",
            "saint_bernard: 20/100 (20.0%)\n",
            "samoyed: 20/100 (20.0%)\n",
            "scottish_terrier: 20/100 (20.0%)\n",
            "shiba_inu: 20/100 (20.0%)\n",
            "staffordshire_bull_terrier: 20/100 (20.0%)\n",
            "wheaten_terrier: 20/100 (20.0%)\n",
            "yorkshire_terrier: 20/100 (20.0%)\n",
            "\n",
            "==== Training Baseline Model with Standard Cross-Entropy Loss ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^    ^self = reduction.pickle.load(from_parent)^\n",
            "^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'MultiClassPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'MultiClassPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'MultiClassPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/youngbinpyo/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'MultiClassPet' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "DataLoader worker (pid(s) 2885) exited unexpectedly",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_queue\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m   1285\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m Empty\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39m], timeout)\n\u001b[1;32m    441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/connection.py:1135\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39mselect(timeout)\n\u001b[1;32m   1136\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selector\u001b[39m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     71\u001b[0m     \u001b[39m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[39m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     _error_if_any_worker_fails()\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m previous_handler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 2885) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m==== Training Baseline Model with Standard Cross-Entropy Loss ====\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m model_base \u001b[39m=\u001b[39m make_model(unfreeze_layers\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m base_acc \u001b[39m=\u001b[39m model_base\u001b[39m.\u001b[39mtrain(epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m    140\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m⮞ Baseline (last 5 layers) Test Acc: \u001b[39m\u001b[39m{\u001b[39;00mbase_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39m# Analyze the results - impact on the classes with limited data\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[4], line 78\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, epochs, path)\u001b[0m\n\u001b[1;32m     75\u001b[0m         L \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munfreeze_layers(L)\n\u001b[0;32m---> 78\u001b[0m tr_loss, tr_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_epoch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader, train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     79\u001b[0m val_loss, val_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_epoch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_loader, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m2d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Train: \u001b[39m\u001b[39m{\u001b[39;00mtr_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% | Val: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mNeuralNetwork.run_epoch\u001b[0;34m(self, loader, train)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain() \u001b[39mif\u001b[39;00m train \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m     44\u001b[0m total_loss, correct, total \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m---> 45\u001b[0m \u001b[39mfor\u001b[39;00m imgs, labs \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     46\u001b[0m     imgs, labs \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(device), labs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m train:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    734\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n\u001b[1;32m   1492\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1453\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1453\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_get_data()\n\u001b[1;32m   1454\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1455\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1297\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1296\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1297\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{\u001b[39;00mpids_str\u001b[39m}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[1;32m   1301\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 2885) exited unexpectedly"
          ]
        }
      ],
      "source": [
        "## Train only using 20%\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        "    SubsetRandomSampler,\n",
        "    WeightedRandomSampler\n",
        ")\n",
        "\n",
        "# --- Ensure device is defined ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load trainval metadata\n",
        "tmp_train = OxfordIIITPet(root=\"data\", split=\"trainval\", target_types=\"category\", download=True)\n",
        "# Extract image stems: e.g. \"Abyssinian_1\"\n",
        "names = [p.stem for p in tmp_train._images]\n",
        "\n",
        "# Build mapping from stem → breed_name\n",
        "breeds_map = {n: n.rsplit(\"_\", 1)[0] for n in names}\n",
        "breed_names = sorted(set(breeds_map.values()))   # 37 unique breed strings\n",
        "breed_to_id = {b: i for i, b in enumerate(breed_names)}\n",
        "\n",
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nm = self.names[idx]\n",
        "        img_path = os.path.join(self.root, \"oxford-iiit-pet\", \"images\", nm + \".jpg\")\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[nm]]\n",
        "        return img, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "root = \"data\"\n",
        "# Full train/val dataset\n",
        "full_dataset = MultiClassPet(root, names, breeds_map, transform=transform)\n",
        "\n",
        "# Build 20%-per-class imbalanced index list\n",
        "class_idxs = defaultdict(list)\n",
        "for idx, nm in enumerate(names):\n",
        "    lbl = breed_to_id[breeds_map[nm]]\n",
        "    class_idxs[lbl].append(idx)\n",
        "\n",
        "# Create an artificially imbalanced dataset with some breeds at 20%\n",
        "imbalanced = []\n",
        "class_percentages = {}  # To track how many samples are used from each class\n",
        "\n",
        "for lbl, idxs in class_idxs.items():\n",
        "    # Use 20% of data for each breed\n",
        "    k = max(1, int(0.2 * len(idxs)))\n",
        "    selected_idxs = random.sample(idxs, k)\n",
        "    imbalanced += selected_idxs\n",
        "    class_percentages[breed_names[lbl]] = (k, len(idxs), k/len(idxs)*100)\n",
        "\n",
        "# Print dataset stats\n",
        "print(f\"Total samples in imbalanced dataset: {len(imbalanced)}\")\n",
        "print(\"Class distribution (samples, total, percentage):\")\n",
        "for breed, (count, total, percentage) in sorted(class_percentages.items()):\n",
        "    print(f\"{breed}: {count}/{total} ({percentage:.1f}%)\")\n",
        "\n",
        "# Split imbalanced list into train/val (80/20)\n",
        "random.shuffle(imbalanced)\n",
        "split = int(0.8 * len(imbalanced))\n",
        "train_idxs = imbalanced[:split]\n",
        "val_idxs = imbalanced[split:]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Test loader via torchvision to avoid missing stems\n",
        "test_ds = OxfordIIITPet(\n",
        "    root=root,\n",
        "    split=\"test\",\n",
        "    target_types=\"category\",\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define the NeuralNetwork class for training and evaluation\n",
        "def make_model(unfreeze_layers=5):\n",
        "    \"\"\"\n",
        "    Returns a NeuralNetwork instance fine-tuned on the\n",
        "    imbalanced train_loader/val_loader/test_loader.\n",
        "    \"\"\"\n",
        "    basemodel = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    m = NeuralNetwork(\n",
        "        basemodel,\n",
        "        len(breed_names),\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        unfreeze=unfreeze_layers\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# Train baseline model with normal cross-entropy loss\n",
        "print(\"\\n==== Training Baseline Model with Standard Cross-Entropy Loss ====\")\n",
        "model_base = make_model(unfreeze_layers=5)\n",
        "base_acc = model_base.train(epochs=10)\n",
        "print(f\"⮞ Baseline (last 5 layers) Test Acc: {base_acc:.2f}%\")\n",
        "\n",
        "# Analyze the results - impact on the classes with limited data\n",
        "print(\"\\n==== Analysis of Impact on Classes with Limited Data ====\")\n",
        "test_acc, per_class_acc, class_counts = model_base.evaluate()\n",
        "\n",
        "# Calculate correlation between class sample counts and accuracy\n",
        "class_samples = [class_percentages[breed][0] for breed in breed_names]\n",
        "correlation = np.corrcoef(class_samples, per_class_acc)[0, 1]\n",
        "print(f\"Correlation between class sample count and accuracy: {correlation:.4f}\")\n",
        "\n",
        "# Compare accuracy of classes with fewer samples vs classes with more samples\n",
        "# (Since all classes are at 20%, this might not show significant differences)\n",
        "print(\"\\nAverage accuracy across all classes: {:.2f}%\".format(sum(per_class_acc) / len(per_class_acc)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb56283",
      "metadata": {
        "id": "4bb56283"
      },
      "source": [
        "Strategy using weighted cross-entropy and over-sampling of the minority classes to compensate for the imbalanced training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6a519b9",
      "metadata": {
        "id": "f6a519b9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import (\n",
        "    Dataset,\n",
        "    DataLoader,\n",
        "    SubsetRandomSampler,\n",
        "    WeightedRandomSampler\n",
        ")\n",
        "\n",
        "# --- Ensure device is defined ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load trainval metadata\n",
        "tmp_train = OxfordIIITPeFalse | True      | True | steplr    |  90.24%t(root=\"data\", split=\"trainval\", target_types=\"category\", download=True)\n",
        "# Extract image stems: e.g. \"Abyssinian_1\"\n",
        "names = [p.stem for p in tmp_train._images]\n",
        "\n",
        "# Build mapping from stem → breed_name\n",
        "breeds_map = {n: n.rsplit(\"_\", 1)[0] for n in names}\n",
        "breed_names = sorted(set(breeds_map.values()))   # 37 unique breed strings\n",
        "breed_to_id = {b: i for i, b in enumerate(breed_names)}\n",
        "\n",
        "class MultiClassPet(Dataset):\n",
        "    def __init__(self, root, names, breeds_map, transform=None):\n",
        "        self.root = root\n",
        "        self.names = names\n",
        "        self.breeds_map = breeds_map\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        nm = self.names[idx]\n",
        "        img_path = os.path.join(self.root, \"oxford-iiit-pet\", \"images\", nm + \".jpg\")\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = breed_to_id[self.breeds_map[nm]]\n",
        "        return img, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "root = \"data\"\n",
        "# Full train/val dataset\n",
        "full_dataset = MultiClassPet(root, names, breeds_map, transform=transform)\n",
        "\n",
        "# Build 20%-per-class imbalanced index list\n",
        "class_idxs = defaultdict(list)\n",
        "for idx, nm in enumerate(names):\n",
        "    lbl = breed_to_id[breeds_map[nm]]\n",
        "    class_idxs[lbl].append(idx)\n",
        "\n",
        "# Create an artificially imbalanced dataset with some breeds at 20%\n",
        "imbalanced = []\n",
        "class_percentages = {}  # To track how many samples are used from each class\n",
        "\n",
        "for lbl, idxs in class_idxs.items():\n",
        "    # Use 20% of data for each breed\n",
        "    k = max(1, int(0.2 * len(idxs)))\n",
        "    selected_idxs = random.sample(idxs, k)\n",
        "    imbalanced += selected_idxs\n",
        "    class_percentages[breed_names[lbl]] = (k, len(idxs), k/len(idxs)*100)\n",
        "\n",
        "# Print dataset stats\n",
        "print(f\"Total samples in imbalanced dataset: {len(imbalanced)}\")\n",
        "print(\"Class distribution (samples, total, percentage):\")\n",
        "for breed, (count, total, percentage) in sorted(class_percentages.items()):\n",
        "    print(f\"{breed}: {count}/{total} ({percentage:.1f}%)\")\n",
        "\n",
        "# Split imbalanced list into train/val (80/20)\n",
        "random.shuffle(imbalanced)\n",
        "split = int(0.8 * len(imbalanced))\n",
        "train_idxs = imbalanced[:split]\n",
        "val_idxs = imbalanced[split:]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(train_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=SubsetRandomSampler(val_idxs),\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Test loader via torchvision to avoid missing stems\n",
        "test_ds = OxfordIIITPet(\n",
        "    root=root,\n",
        "    split=\"test\",\n",
        "    target_types=\"category\",\n",
        "    transform=transform,\n",
        "    download=False\n",
        ")\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define the NeuralNetwork class for training and evaluation\n",
        "def make_model(unfreeze_layers=5):\n",
        "    \"\"\"\n",
        "    Returns a NeuralNetwork instance fine-tuned on the\n",
        "    imbalanced train_loader/val_loader/test_loader.\n",
        "    \"\"\"\n",
        "    basemodel = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    m = NeuralNetwork(\n",
        "        basemodel,\n",
        "        len(breed_names),\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        unfreeze=unfreeze_layers\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# Train baseline model with normal cross-entropy loss\n",
        "print(\"\\n==== Training Baseline Model with Standard Cross-Entropy Loss ====\")\n",
        "model_base = make_model(unfreeze_layers=5)\n",
        "base_acc = model_base.train(epochs=10)\n",
        "print(f\"⮞ Baseline (last 5 layers) Test Acc: {base_acc:.2f}%\")\n",
        "\n",
        "# Analyze the results - impact on the classes with limited data\n",
        "print(\"\\n==== Analysis of Impact on Classes with Limited Data ====\")\n",
        "test_acc, per_class_acc, class_counts = model_base.evaluate()\n",
        "baseline_per_class_acc = per_class_acc.copy()  # Store for comparison\n",
        "\n",
        "# Calculate correlation between class sample counts and accuracy\n",
        "class_samples = [class_percentages[breed][0] for breed in breed_names]\n",
        "correlation = np.corrcoef(class_samples, per_class_acc)[0, 1]\n",
        "print(f\"Correlation between class sample count and accuracy: {correlation:.4f}\")\n",
        "\n",
        "# Compare accuracy of classes with fewer samples vs classes with more samples\n",
        "# (Since all classes are at 20%, this might not show significant differences)\n",
        "print(\"\\nAverage accuracy across all classes: {:.2f}%\".format(sum(per_class_acc) / len(per_class_acc)))\n",
        "\n",
        "# ===== WEIGHTED CROSS-ENTROPY APPROACH =====\n",
        "print(\"\\n==== Training with Weighted Cross-Entropy Loss ====\")\n",
        "\n",
        "# Compute class weights inversely proportional to class frequencies\n",
        "# First, count samples per class in training set\n",
        "per_labels = [breed_to_id[breeds_map[names[i]]] for i in train_idxs]\n",
        "class_counts = torch.tensor([per_labels.count(c) for c in range(len(breed_names))], dtype=torch.float)\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * len(class_counts)  # Normalize\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "print(\"Class weights:\")\n",
        "for i, (breed, weight) in enumerate(zip(breed_names, class_weights.cpu().numpy())):\n",
        "    samples = per_labels.count(i)\n",
        "    print(f\"{breed}: {weight:.4f} (samples: {samples})\")\n",
        "\n",
        "# Train with weighted cross-entropy\n",
        "model_w = make_model(unfreeze_layers=5)\n",
        "model_w.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "model_w.optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_w.model.parameters()),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "w_acc = model_w.train(epochs=10)\n",
        "print(f\"⮞ Weighted CE (last 5 layers) Test Acc: {w_acc:.2f}%\")\n",
        "\n",
        "# Analyze per-class improvements\n",
        "_, w_per_class_acc, _ = model_w.evaluate()\n",
        "print(\"\\nPer-class accuracy changes (Weighted CE vs Baseline):\")\n",
        "for i, (breed, base_acc, w_acc) in enumerate(zip(breed_names, baseline_per_class_acc, w_per_class_acc)):\n",
        "    diff = w_acc - base_acc\n",
        "    print(f\"{breed}: {base_acc:.2f}% → {w_acc:.2f}% ({diff:+.2f}%)\")\n",
        "\n",
        "# ===== OVERSAMPLING APPROACH =====\n",
        "print(\"\\n==== Training with Oversampling of Minority Classes ====\")\n",
        "\n",
        "# Implement weighted random sampling to oversample minority classes\n",
        "sample_weights = [1.0 / class_counts[per_labels[i]].item() for i in range(len(train_idxs))]\n",
        "oversampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights) * 2, replacement=True)\n",
        "\n",
        "# Create a new dataloader with oversampling\n",
        "oversampled_train_loader = DataLoader(\n",
        "    full_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=oversampler,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "# Train with oversampling\n",
        "model_o = make_model(unfreeze_layers=5)\n",
        "model_o.train_loader = oversampled_train_loader\n",
        "model_o.optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_o.model.parameters()),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "o_acc = model_o.train(epochs=10)\n",
        "print(f\"⮞ Oversampling (last 5 layers) Test Acc: {o_acc:.2f}%\")\n",
        "\n",
        "# Analyze per-class improvements\n",
        "_, o_per_class_acc, _ = model_o.evaluate()\n",
        "print(\"\\nPer-class accuracy changes (Oversampling vs Baseline):\")\n",
        "for i, (breed, base_acc, o_acc) in enumerate(zip(breed_names, baseline_per_class_acc, o_per_class_acc)):\n",
        "    diff = o_acc - base_acc\n",
        "    print(f\"{breed}: {base_acc:.2f}% → {o_acc:.2f}% ({diff:+.2f}%)\")\n",
        "\n",
        "# ===== COMPARE ALL APPROACHES =====\n",
        "print(\"\\n==== Overall Comparison of Approaches ====\")\n",
        "print(f\"Baseline Test Accuracy: {base_acc:.2f}%\")\n",
        "print(f\"Weighted CE Test Accuracy: {w_acc:.2f}%\")\n",
        "print(f\"Oversampling Test Accuracy: {o_acc:.2f}%\")\n",
        "\n",
        "# Plot comparison of per-class accuracies across methods\n",
        "plt.figure(figsize=(15, 10))\n",
        "x = np.arange(len(breed_names))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x - width, baseline_per_class_acc, width, label='Baseline')\n",
        "plt.bar(x, w_per_class_acc, width, label='Weighted CE')\n",
        "plt.bar(x + width, o_per_class_acc, width, label='Oversampling')\n",
        "\n",
        "plt.xlabel('Breed')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Per-class Accuracy Comparison Across Methods')\n",
        "plt.xticks(x, breed_names, rotation=90)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('comparison_per_class.png')\n",
        "plt.close()\n",
        "\n",
        "# Calculate average improvement across all classes\n",
        "w_avg_improvement = sum(w - b for w, b in zip(w_per_class_acc, baseline_per_class_acc)) / len(breed_names)\n",
        "o_avg_improvement = sum(o - b for o, b in zip(o_per_class_acc, baseline_per_class_acc)) / len(breed_names)\n",
        "\n",
        "print(f\"\\nAverage per-class improvement with Weighted CE: {w_avg_improvement:.2f}%\")\n",
        "print(f\"Average per-class improvement with Oversampling: {o_avg_improvement:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7346dd-0698-4868-8b3b-4d0b3ba9bb15",
      "metadata": {
        "id": "ae7346dd-0698-4868-8b3b-4d0b3ba9bb15"
      },
      "source": [
        "# Extension"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80eefc3e-2137-4ffe-a2bf-6a0da7ac2eeb",
      "metadata": {
        "id": "80eefc3e-2137-4ffe-a2bf-6a0da7ac2eeb"
      },
      "source": [
        "## Catastrophic Forgetting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86aa66df-6b99-43de-99ae-b63755f44be9",
      "metadata": {
        "id": "86aa66df-6b99-43de-99ae-b63755f44be9",
        "outputId": "d411abc0-4b17-4e3a-f0a5-aec667f97043"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset Flowers102\n",
              "    Number of datapoints: 1020\n",
              "    Root location: data\n",
              "    split=train"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Flowers102(root=\"data\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "392bb337-0e5c-4362-a55f-07cf3262525c",
      "metadata": {
        "id": "392bb337-0e5c-4362-a55f-07cf3262525c"
      },
      "outputs": [],
      "source": [
        "class Flowers102Dataset(Dataset):\n",
        "    def __init__(self, root, split='train', transform=None, download=False):\n",
        "        \"\"\"\n",
        "        Custom Dataset for Flowers102 using torchvision's built-in class.\n",
        "\n",
        "        Args:\n",
        "            root (str): Path to the dataset directory.\n",
        "            split (str): One of 'train', 'val', 'test'.\n",
        "            transform (callable, optional): Transform to apply to the images.\n",
        "            download (bool): If True, downloads the dataset if not found.\n",
        "        \"\"\"\n",
        "        self.dataset = Flowers102(root=root, split=split, transform=transform, download=download)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "dbb7366f-a05c-4262-88a3-ae7cf587615a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbb7366f-a05c-4262-88a3-ae7cf587615a",
        "outputId": "28b1f04e-3f6f-4977-cbac-81027aec42ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 345M/345M [00:13<00:00, 25.2MB/s]\n",
            "100%|██████████| 502/502 [00:00<00:00, 923kB/s]\n",
            "100%|██████████| 15.0k/15.0k [00:00<00:00, 30.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_ds = Flowers102Dataset(\"data\", split='train', download=True, transform=transformIMG)\n",
        "val_ds = Flowers102Dataset(\"data\", split='val', download=True, transform=transformIMG)\n",
        "test_ds = Flowers102Dataset(\"data\", split='test', download=True, transform=transformIMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "85819eb8-928a-4a4f-af05-11d6ca9f1c1c",
      "metadata": {
        "id": "85819eb8-928a-4a4f-af05-11d6ca9f1c1c"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a6ba88d2-dc78-4926-9d7b-d076d93ba1de",
      "metadata": {
        "id": "a6ba88d2-dc78-4926-9d7b-d076d93ba1de"
      },
      "outputs": [],
      "source": [
        "def filter_first_n_classes(dataset, n_classes):\n",
        "\n",
        "    indices = [i for i, (_, label) in enumerate(dataset) if label < n_classes]\n",
        "    return Subset(dataset, indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e852fb42-0b60-4f37-8996-ffff5d9a0a5c",
      "metadata": {
        "id": "e852fb42-0b60-4f37-8996-ffff5d9a0a5c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "# Filter to only first 37 classes\n",
        "train_ds_flower = filter_first_n_classes(train_ds, 37)\n",
        "val_ds_flower = filter_first_n_classes(val_ds, 37)\n",
        "test_ds_flower = filter_first_n_classes(test_ds, 37)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c84fad05-6c7b-444a-b7b5-5eb0a82b2bd3",
      "metadata": {
        "id": "c84fad05-6c7b-444a-b7b5-5eb0a82b2bd3"
      },
      "outputs": [],
      "source": [
        "#False | True      | True | steplr    |  90.24%\n",
        "use_aug = False\n",
        "freeze_bn    = True\n",
        "use_l2       = True\n",
        "sched    = 'steplr'\n",
        "fixed_rate = 2.0\n",
        "breed_names = sorted(set(breeds_map.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f0997d69-6049-45d8-88bc-1911e921c503",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "f0997d69-6049-45d8-88bc-1911e921c503",
        "outputId": "b7e9ff81-6cc1-4e2e-8919-12c3c651acff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> aug=False, freeze_bn=True, L2=True, sched=steplr\n",
            "Epoch  1 | Train: 58.79% | Val: 82.88%\n",
            "Epoch  2 | Train: 88.10% | Val: 88.86%\n",
            "Epoch  3 | Train: 91.52% | Val: 87.50%\n",
            "Epoch  4 | Train: 92.54% | Val: 91.58%\n",
            "Epoch  5 | Train: 93.75% | Val: 90.76%\n",
            "Epoch  6 | Train: 95.35% | Val: 91.85%\n",
            "Epoch  7 | Train: 95.86% | Val: 91.85%\n",
            "Epoch  8 | Train: 95.41% | Val: 91.58%\n",
            "Epoch  9 | Train: 96.20% | Val: 91.30%\n",
            "Epoch 10 | Train: 96.20% | Val: 91.30%\n",
            "Epoch 11 | Train: 96.23% | Val: 91.85%\n",
            "Epoch 12 | Train: 96.20% | Val: 91.03%\n",
            "Epoch 13 | Train: 96.01% | Val: 91.58%\n",
            "Epoch 14 | Train: 96.35% | Val: 91.58%\n",
            "Epoch 15 | Train: 96.20% | Val: 91.03%\n",
            "Epoch 16 | Train: 96.41% | Val: 91.58%\n",
            "Epoch 17 | Train: 96.32% | Val: 91.30%\n",
            "Epoch 18 | Train: 96.65% | Val: 91.85%\n",
            "Epoch 19 | Train: 96.53% | Val: 91.30%\n",
            "Epoch 20 | Train: 96.23% | Val: 92.66%\n",
            "Test Accuracy: 90.19%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4fad2f803c75>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# e) Train & record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_bn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_l2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mbestmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "# Train best model\n",
        "print(f\"\\n>>> aug={use_aug}, freeze_bn={freeze_bn}, L2={use_l2}, sched={sched}\")\n",
        "\n",
        "# a) Instantiate with gradual unfreezing\n",
        "params = {'gradual_unfreezing': True, 'unfreezing_rate': fixed_rate}\n",
        "model = NeuralNetwork(\n",
        "    basemodel,\n",
        "    len(breed_names),\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    unfreeze=1,\n",
        "    parameters=params\n",
        ")\n",
        "model.model.to(device)\n",
        "\n",
        "# b) Optionally freeze BatchNorm layers\n",
        "if freeze_bn:\n",
        "    for m in model.model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            m.eval()\n",
        "            for p in m.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "# c) Build optimizer (head @1e-3, backbone @1e-4), optional L2\n",
        "wd = 1e-2 if use_l2 else 0.0\n",
        "head_p = list(model.model.fc.parameters())\n",
        "back_p = [\n",
        "    p for n,p in model.model.named_parameters()\n",
        "    if p.requires_grad and not n.startswith(\"fc\")\n",
        "]\n",
        "model.optimizer = optim.AdamW([\n",
        "    {'params': head_p, 'lr':1e-3, 'weight_decay':wd},\n",
        "    {'params': back_p, 'lr':1e-4, 'weight_decay':wd},\n",
        "])\n",
        "\n",
        "# d) Attach scheduler if desired\n",
        "if sched == 'steplr':\n",
        "    model.scheduler = optim.lr_scheduler.StepLR(\n",
        "        model.optimizer,\n",
        "        step_size=5,\n",
        "        gamma=0.1\n",
        "    )\n",
        "elif sched == 'onecycle':\n",
        "    total_steps = len(train_loader) * 10\n",
        "    model.scheduler = optim.lr_scheduler.OneCycleLR(\n",
        "        model.optimizer,\n",
        "        max_lr=[1e-3,1e-4],\n",
        "        total_steps=total_steps,\n",
        "        pct_start=0.3,\n",
        "        anneal_strategy='cos'\n",
        "    )\n",
        "else:\n",
        "    model.scheduler = None\n",
        "\n",
        "# e) Train & record\n",
        "acc = model.train2(epochs=20)\n",
        "print(acc)\n",
        "bestmodel = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "036d7ee0-7b43-4361-a341-9fc78e1c84d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "036d7ee0-7b43-4361-a341-9fc78e1c84d0",
        "outputId": "d65d93e2-2835-4156-eb1d-77c68f557e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_ds_flower, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds_flower,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds_flower,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "78bdf852-1e9d-4aa5-979f-37de7ae1d85e",
      "metadata": {
        "id": "78bdf852-1e9d-4aa5-979f-37de7ae1d85e"
      },
      "outputs": [],
      "source": [
        "bestmodel.train_loader = train_loader\n",
        "bestmodel.val_loader = val_loader\n",
        "bestmodel.test_loader = test_loader\n",
        "trained_best = copy.deepcopy(bestmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ed37fd-be71-471d-8f65-55f6c6a6fdbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ed37fd-be71-471d-8f65-55f6c6a6fdbf",
        "outputId": "5291c5ed-8f78-4903-de34-a5ffeb4ff25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train: 0.54% | Val: 1.35%\n",
            "Epoch  2 | Train: 0.54% | Val: 1.35%\n",
            "Epoch  3 | Train: 1.62% | Val: 0.54%\n",
            "Epoch  4 | Train: 2.70% | Val: 0.81%\n",
            "Epoch  5 | Train: 1.35% | Val: 0.54%\n"
          ]
        }
      ],
      "source": [
        "trained_best.train2(epochs=70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6bR5YgSH0d3k"
      },
      "id": "6bR5YgSH0d3k",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}