{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b501857-78ba-481b-ab7a-3f5b4bc144a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import OxfordIIITPet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7479cf3f-4699-4cb4-ab82-010e8ddb2635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset OxfordIIITPet\n",
       "    Number of datapoints: 3680\n",
       "    Root location: data"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OxfordIIITPet(root=\"data\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d431898-55ce-49dc-91f9-7dceed1fec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "annnotations_dir = os.path.join(\"data\", \"oxford-iiit-pet\", \"annotations\")\n",
    "lines_for_files = open(os.path.join(annnotations_dir, \"list.txt\")).read().splitlines()[6:]\n",
    "species_map = {l.split()[0]: int(l.split()[2]) for l in lines_for_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66c852e4-7055-4c82-97c9-3e99e736d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(annnotations_dir, \"trainval.txt\")) as f:\n",
    "    trainval_names = [l.split()[0] for l in f if l.strip()]\n",
    "with open(os.path.join(annnotations_dir, \"test.txt\")) as f:\n",
    "    test_names = [l.split()[0] for l in f if l.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "145827fc-38aa-4e39-8049-e5640ed7cbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryPet(Dataset):\n",
    "    def __init__(self, root, names, species_map, transform=None):\n",
    "        self.root = root\n",
    "        self.names = names\n",
    "        self.species_map = species_map\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "        img_path = os.path.join(\n",
    "            self.root, \"oxford-iiit-pet\", \"images\", name + \".jpg\"\n",
    "        )\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.species_map[name] - 1  # 1→cat→0, 2→dog→1\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2832243b-6442-4bc5-9926-f690647a5658",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformIMG = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "036a6c76-bc3b-44b8-acf1-50893a352c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = BinaryPet(\"data\", trainval_names, species_map, transform=transformIMG)\n",
    "n_val = int(0.1 * len(full))\n",
    "train_ds, val_ds = random_split(full, [len(full)-n_val, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55a8eecd-7f70-4223-9218-6023fff72e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = BinaryPet(\"data\", test_names, species_map, transform=transformIMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d2e5899-3a81-461a-bd4a-b1a5c850cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ed618ac-37af-464d-a735-3223b0dbc071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "# freezing all\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "# changing the fully connected layer\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "# Uunfreeze the last layers and fully connected last layer\n",
    "for name, p in model.named_parameters():\n",
    "    if name.startswith(\"layer4\") or name.startswith(\"fc\"):\n",
    "        p.requires_grad = True\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c32651b9-0f2c-4736-b3db-10fbb6486f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55100d27-1851-43fb-8039-3d1cd7ab6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([\n",
    "    {\"params\": model.layer4.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-4},\n",
    "    {\"params\": model.fc.parameters(),     \"lr\": 1e-3, \"weight_decay\": 1e-4},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1dcabae-3911-4cd2-96ac-52e4c0158183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, labs in loader:\n",
    "        imgs, labs = imgs.to(device), labs.to(device)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss   = criterion(logits, labs)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        preds      = logits.argmax(dim=1)\n",
    "        correct   += (preds == labs).sum().item()\n",
    "        total     += imgs.size(0)\n",
    "    return total_loss/total, correct/total*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "30e5a381-42b4-4676-8d65-1d1a7e8bebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train: 98.22% | Val: 99.46%\n",
      "Epoch  2 | Train: 99.67% | Val: 99.73%\n",
      "Epoch  3 | Train: 99.52% | Val: 100.00%\n",
      "Epoch  4 | Train: 99.91% | Val: 98.37%\n",
      "Epoch  5 | Train: 99.61% | Val: 100.00%\n",
      "Epoch  6 | Train: 99.97% | Val: 100.00%\n",
      "Epoch  7 | Train: 99.94% | Val: 100.00%\n",
      "Epoch  8 | Train: 99.97% | Val: 99.73%\n",
      "Epoch  9 | Train: 100.00% | Val: 100.00%\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "for epoch in range(1, 10):\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_acc = run_epoch(val_loader, train=False)\n",
    "    print(f\"Epoch {epoch:2d} | Train: {tr_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_binary_resnet34.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "32b86600-f7a0-4cc0-afb1-3e954c369c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.59%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_binary_resnet34.pth\"))\n",
    "test_loss, test_acc = run_epoch(test_loader, train=False)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
